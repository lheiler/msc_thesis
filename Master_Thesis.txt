MSc Individual Project
Imperial College London
Department of Computing

Evaluating Whole-Brain Models as
Dimensionality Reduction Frameworks for
EEG

Supervisor:
Dr. Pedro Mediano
Dr. Gregory Scott

Author:
Lorenz Heiler

Second Marker:
Dr. Antoine Cully

August 29, 2025

Abstract
Electroencephalography (EEG) provides high–temporal resolution recordings of brain activity, but
its high dimensionality and noise present significant challenges for analysis. Dimensionality reduction is essential to extract compact, informative representations suitable for downstream tasks
such as classification and regression. This thesis systematically compares two broad approaches:
biophysically–guided whole–brain models (WBMs), which yield interpretable parameters grounded
in neural mechanisms, and data–driven machine learning methods, which produce unconstrained
latent codes.
We group models into three “weight classes” based on latent dimensionality and feature aggregation: (1) small, aggregated representations (5–16 dimensions), (2) small, channel–wise independent
representations, and (3) medium–scale, unconstrained representations. Within each class, we evaluate multiple WBM and data–driven methods on identical EEG datasets and tasks, measuring
classification accuracy, robustness, and stability. Amortised inference and posterior sampling are
compared for WBM parameter estimation, and the fidelity of parameter–to–EEG fits is assessed.
Results show how aggregation, channel–wise independence, and latent size affect the performance gap between WBMs and data–driven models. We identify conditions under which WBMs
approach data–driven accuracy, as well as scenarios where physiological constraints limit expressivity. This analysis informs the trade–offs between interpretability and predictive power, and suggests
pathways for future hybrid methods combining mechanistic insight with statistical flexibility.
NOT DONE

Acknowledgements
I would like to express my sincere gratitude to my supervisors for their guidance, encouragement,
and valuable feedback during the course of this thesis. I am thankful to my fellow students and lab
colleagues for their insights, helpful discussions, and for creating a collaborative and motivating
environment. I also appreciate the support from my university in providing the necessary resources
and facilities for this research. Finally, I am deeply grateful to my family and friends for their
understanding, patience, and continuous support throughout my studies.

Contents
1 Introduction: Whole-Brain Models as Dimensionality Reduction

6

2 Related works
2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Signal Processing Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Pre-processing: referencing, filtering, and epoching . . . . . . . . . . . . . .
2.2.2 Artefact detection and removal . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.3 Time-frequency analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.4 Implementation framework . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Data Driven Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 Principal Component Analysis (PCA). . . . . . . . . . . . . . . . . . . . . .
2.3.2 Spectral autoencoders for EEG (PSD-AE). . . . . . . . . . . . . . . . . . .
2.3.3 EEGNet as an Autoencoder for EEG Representation Learning . . . . . . .
2.3.4 Feature extraction at scale: HCTSA and catch22 . . . . . . . . . . . . . . .
2.4 Computational Brain Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.1 Jansen–Rit Neural Mass Models . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2 Cortico–Thalamic model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.3 The Wong–Wang model (mean-field attractor dynamics) . . . . . . . . . . .
2.4.4 Hopf/Stuart-Landau model . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.5 Model fitting and parameter identifiability . . . . . . . . . . . . . . . . . . . . . . .
2.6 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.6.1 Our setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7
7
7
7
7
7
7
8
8
9
9
10
11
11
12
14
15
16
17
17

3 Pipeline
3.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.1 Problem Statement and Goals . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Preprocessing and Standardization . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Channel canonicalization and montage handling . . . . . . . . . . . . . . .
3.2.2 Filtering, rereferencing, resampling . . . . . . . . . . . . . . . . . . . . . . .
3.2.3 Artifact handling (ICA/EOG/ECG, AutoReject, bad-channel interpolation)
3.2.4 Epoching protocol (length, overlap, masks) . . . . . . . . . . . . . . . . . .
3.2.5 PSD estimation settings (Welch parameters) and normalization . . . . . . .
3.3 Latent extraction methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.1 Cortico–Thalamic Model (CTM) . . . . . . . . . . . . . . . . . . . . . . . .
3.3.2 Cortico–Thalamic Model (CTM), amortized inference . . . . . . . . . . . .
3.3.3 Jansen-Rit Model (JR) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.4 Wong–Wang Model (DMF) . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.5 Hopf (Stuart–Landau) oscillator: methodological specification . . . . . . . .
3.3.6 catch22 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.7 PCA over PSD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.8 PSD Autoencoder (PSD-AE) . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.9 EEGNet Autoencoder (combined time–spectral loss): methodological specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Latent Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4.1 Evaluation protocol and data handling . . . . . . . . . . . . . . . . . . . . .
3.4.2 Intrinsic latent quality (unsupervised) . . . . . . . . . . . . . . . . . . . . .

18
18
18
18
18
19
19
20
20
20
21
21
22
23
23
24
25
25

2

26
27
27
27
27

3.4.3 Geometry preservation under 2D embeddings . . . . . . . . . . . . . . . . .
3.4.4 Label-informed information content . . . . . . . . . . . . . . . . . . . . . .
3.4.5 Downstream heads: task sufficiency and generalisation . . . . . . . . . . . .
3.4.6 Fairness and reproducibility controls . . . . . . . . . . . . . . . . . . . . . .
3.4.7 Outputs and artefacts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4.8 Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Downstream tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5.1 Tasks and label preparation . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5.2 Model class (single-task MLP heads) . . . . . . . . . . . . . . . . . . . . . .
3.5.3 Hyperparameter optimisation (Optuna) . . . . . . . . . . . . . . . . . . . .
3.5.4 Training and validation protocol . . . . . . . . . . . . . . . . . . . . . . . .
3.5.5 Evaluation on held-out latents . . . . . . . . . . . . . . . . . . . . . . . . .
3.5.6 Fairness and reproducibility . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5.7 Outputs and artefacts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5.8 Rationale and scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

28
28
28
29
29
29
29
29
30
30
30
30
30
31
31

4 Results/Analysis
4.1 Individual Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Latent Space comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Weight Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

32
32
32
32
32

5 Conclusion

33

A First Appendix

34

3.5

3

List of Figures
2.1

Schematic of a cortico–thalamic neural field model with corticocortical and thalamo–cortical loops, characteristic delays, and effective gains. . . . . . . . . . . . .

14

3.1

High-level pipeline structure: standardized preprocessing, method-agnostic latent
extraction, unsupervised latent evaluation, and supervised downstream assessment.

19

4

List of Tables

5

Chapter 1

Introduction: Whole-Brain Models
as Dimensionality Reduction
EEG data are high-dimensional, noisy, and difficult to interpret. Reducing this complexity to informative latent variables is essential for extracting meaningful patterns and improving tasks such
as classification. This can lead to the discovery of new drugs, finding cause to illnesses or easy
diagnoses of neurological diseases. This thesis compares two fundamentally different approaches to
latent variable extraction. The first uses biophysically guided whole-brain models, fitted to EEG
to produce interpretable parameters. The second applies data-driven machine learning methods,
such as autoencoders, to learn low-dimensional representations without physiological constraints.
Whole-brain models, including neural mass and neural field formulations, summarize regional
brain activity with a small set of state variables. Fitting these models to EEG yields parameters,
such as coupling strengths, gains, and time constants—that reflect specific biophysical properties.
These parameters are interpretable and physiologically bounded, making them suitable for clinical
and mechanistic analysis. However, they are computationally demanding, limited in flexibility and
expressiveness, and may miss nonlinear structure present in the data.
Data-driven approaches compress EEG directly, capturing nonlinear relationships and often
achieving high predictive performance. Their flexibility allows discovery of patterns absent from
current biophysical theory, but they lack mechanistic grounding and risk overfitting to noise.
This work reframes whole-brain models as dimensionality reduction tools, placing them on the
same conceptual footing as machine learning encoders. Both produce a compact representation of
each recording, but through different constraints and assumptions. The core question is whether
these approaches capture the same information, complementary aspects, or fundamentally different
features of brain dynamics.
The objective is to quantitatively compare the performance, stability, and interpretability of latent representations from whole-brain models and from machine learning, using EEG classification
tasks as a benchmark. The results aim to clarify the trade-offs between mechanistic interpretability
and statistical performance, and to identify opportunities for hybrid approaches that combine the
strengths of both paradigms.

6

Chapter 2

Related works
2.1

Introduction

2.2

Signal Processing Techniques

Rigorous signal-processing methods are essential before any higher-level modelling or classification
can be attempted. The techniques outlined below follow the conventional order of operations
adopted in most modern EEG studies and are compatible with the MNE-Python ecosystem used
throughout this project [1].

2.2.1

Pre-processing: referencing, filtering, and epoching

Ideally, raw EEG is first re-referenced (common average or surface Laplacian) and band-limited
with a zero-phase finite-impulse-response (FIR) filter to remove slow drifts (< 0.5 Hz) and line
noise (50/60 Hz). If necessary, the data is then resampled into the desired sample rate (typically to
128–512 Hz) and/or segmented into epochs relative to task events or into fixed-length windows for
resting-state analyses. MNE-Python provides well-tested defaults for each of these steps, enforcing
reproducibility across distributions [1].

2.2.2

Artefact detection and removal

Eye blinks, cardiac signals, muscle activity and electrode pops can disturb cortical activity. Independent component analysis (ICA) remains the standard for isolating ocular and cardiac artefacts.
Components are identified via topographies and time-courses and then subtracted before backprojection. MNE-Python’s "autoreject" and dedicated channels for blink detection integrate these
methods into a streamlined artefact removal procedure for EEG data.

2.2.3

Time-frequency analysis

EEG signals change in both time and frequency. To see when a rhythm happens and which
frequencies are involved, we need a method that shows both at once. The short-time Fourier
transform can do this, but its fixed window blurs brief events. Most modern studies instead use
Morlet wavelets with logarithmically spaced centre frequencies. Their flexible windows pin down
quick, high-frequency bursts and epileptic spikes much more precisely than STFT. [2][3]

2.2.4

Implementation framework

All aforementioned steps—from filtering and ICA to wavelet analysis are implemented via the
open-source MNE-Python toolkit. MNE-Python is an open-source toolkit which is developed to
streamline the entire MEG/EEG workflow, providing a plethora of methods that are crucial for
EEG data handling/processing/evaluation.
Together, these processing methods convert raw, noisy EEG into clean, information-rich representations that serve as the input for both our deep learning backbones and our computational
brain-model fitting procedures.
7

2.3

Data Driven Methods

Data-driven approaches seek to learn compact, task-agnostic or task-oriented embeddings of EEG
by optimizing statistical criteria directly from data, rather than imposing explicit biophysical priors. Classical statistical pipelines summarize signals using hand-crafted descriptors (e.g., catch22)
that capture distributional, temporal, and nonlinear properties across channels (?). Complementarily, linear spectral embeddings such as principal component analysis (PCA) on power spectral
densities provide orthogonal bases that capture maximal variance and suppress noise (?). Learned
representations extend these ideas by training neural encoders to compress either time-domain signals or spectro-temporal transforms: autoencoders optimize reconstruction objectives to discover
low-dimensional manifolds with regularization inducing smoothness and invariances; convolutional
architectures (e.g., EEGNet-style encoders) exploit spatial–temporal locality and depthwise separability to encode topographic structure efficiently (?). Recent self-supervised frameworks pretrain on
large unlabeled corpora via contrastive or predictive losses, yielding embeddings (e.g., EEG2Replike) that transfer effectively to downstream clinical tasks under label scarcity and domain shift
(?). Across these families, design choices—per-channel versus channel-aggregated inputs, spectral versus time-domain views, and inductive biases (stationarity, locality, invariance)—govern the
trade-offs among expressivity, robustness, and interpretability. Comparative evaluation typically
combines unsupervised criteria (independence, clusterability, geometry preservation) with supervised performance on clinically relevant endpoints, enabling principled assessment of representation
quality independent of any particular classifier head.

2.3.1

Principal Component Analysis (PCA).

Principal Component Analysis (PCA) is a classical, linear technique for constructing low-dimensional
representations by identifying orthogonal directions in feature space that maximize explained variance (???). Formally, PCA computes the eigen-decomposition of the sample covariance (or equivalently, the singular value decomposition of a mean-centered data matrix), yielding an ordered basis
of principal axes and associated eigenvalues that quantify the variance captured by each component.
The method can be interpreted as a maximum-variance encoder, a minimum-reconstruction-error
linear autoencoder, or as a whitening transform when scaled by inverse singular values (?). Owing
to its simplicity, closed-form solution, and lack of tuning hyperparameters beyond dimensionality, PCA has become a widely adopted baseline in neuroimaging and EEG signal processing for
denoising, visualization, and dimensionality reduction before classification.
In the context of EEG, spectral features derived from Welch power spectral densities (PSDs)
provide a stationary, frequency-domain summary of the signal. Applying PCA to PSDs leverages
the typically low intrinsic dimensionality of scalp spectra—dominated by broad-band 1/f structure and a small number of narrow-band peaks (e.g., alpha)—to compress redundant frequency
bins while preserving physiologically salient variance. This study considers two variants: channelaveraged spectra (reducing spatial variability and emphasizing global rhythms) and per-channel
spectra (retaining topographic information at the cost of higher dimensionality). Fitting PCA
exclusively on training data and freezing the projection for evaluation avoids information leakage
and ensures reproducibility across splits and tasks. The resulting low-dimensional latent coordinates serve as task-agnostic embeddings for downstream models, enabling a clean assessment of
how much of the clinically relevant structure is linearly recoverable from spectral variance alone.
Despite its strengths, PCA imposes restrictive assumptions that are important to acknowledge in clinical EEG applications. First, it is constrained to linear subspaces; nonlinear manifolds
that may underlie neurophysiological variability cannot be unfolded without kernel extensions (?).
Second, the variance-maximization criterion is agnostic to label information: directions of large
variance can correspond to nuisance factors (e.g., inter-subject differences, recording conditions)
rather than discriminative structure. Careful preprocessing—standardization across frequencies,
consistent PSD parameterization, and robust handling of channel sets—is therefore crucial to
mitigate confounds. Third, when applied to channel-averaged spectra, PCA sacrifices spatial discriminability, while per-channel PCA can improve spatial specificity but risks overfitting if sample
sizes are modest. These trade-offs position PCA as a strong and transparent baseline rather than
an oracle representation.
Within our comparative framework, PCA occupies an important reference point among datadriven methods: it provides interpretable axes (loadings reveal spectral patterns) and stable performance characteristics, against which more expressive learned encoders (e.g., autoencoders, self8

supervised representations) can be judged. Moreover, PCA-derived latents facilitate unsupervised
quality diagnostics (e.g., explained-variance curves, clusterability) and serve as a bridge for comparing against biophysical latent spaces, where parameter perturbations often express as structured
spectral deformations. In sum, PCA offers a principled, reproducible, and computationally efficient baseline for EEG latent extraction, clarifying the incremental value of more complex models
in capturing clinically meaningful variability.

2.3.2

Spectral autoencoders for EEG (PSD-AE).

A substantial line of data-driven research learns low-dimensional embeddings of electroencephalography (EEG) by modeling the frequency-domain structure of neural activity. Power spectral density (PSD) representations are a long-standing, interpretable summary of oscillatory processes and
background aperiodic components in EEG, typically estimated with Welch’s method (?). Building
on this representation, spectral autoencoders compress PSDs into compact latent codes by optimizing a reconstruction objective, thereby discovering manifold structure that concentrates variance
relevant to downstream tasks while attenuating noise and nuisance variability (????). Compared
to time-domain convolutional networks (??), PSD-based encoders trade temporal-phase sensitivity
for improved robustness to nonstationary waveforms and recording idiosyncrasies, and offer greater
semantic alignment with canonical rhythms (delta–beta) and spectral slope/intercept factors that
are widely reported in clinical neurophysiology.
In the EEG literature, spectral embeddings have traditionally relied on linear techniques such
as principal component analysis (PCA) over per-channel or channel-aggregated PSDs (?). Autoencoders generalize this paradigm by learning nonlinear, potentially sparse and disentangled
bases directly from data, with architectural priors (e.g., bottleneck dimensionality, weight decay,
denoising noise models) shaping the geometry and smoothness of the latent space. When applied
per-channel, the latent captures spatially resolved spectral signatures (e.g., posterior alpha peaks),
whereas channel-averaged inputs emphasize global spectral tone and aperiodic components; both
views appear in prior work and entail complementary robustness–specificity trade-offs. Compared
to spectrogram-based encoders that preserve temporal evolution at the cost of higher dimensionality, PSD-AEs operate on a compact, stationary summary, making them computationally efficient
and less prone to overfitting in low-label regimes (??).
Recent self-supervised frameworks pretrain encoders by predicting or contrasting views of EEG
without labels (?). PSD-AEs occupy a middle ground between fully hand-crafted spectral features
and generic self-supervised encoders: they retain strong inductive bias toward oscillatory structure
while allowing nonlinear compression tuned to the empirical distribution of spectra. This makes
them well-suited as universal feature extractors for heterogeneous clinical cohorts, where phasespecific patterns are less stable across sessions and subjects than band-limited power and aperiodic
slope. At the same time, the spectral summarization discards cross-frequency coupling and transient dynamics that may carry diagnostic information, motivating complementary evaluations with
time-domain and spectro-temporal encoders.
Within this thesis, the PSD autoencoder is positioned as a representative data-driven spectral method that complements mechanistic whole-brain models. By constraining the input to
normalized PSDs and optimizing a reconstruction loss, the model yields a low-dimensional code
that is (i) interpretable through its alignment with spectral components, (ii) efficient to compute at scale, and (iii) amenable to systematic comparison against mechanistic latent parameters.
This placement enables controlled analyses of representation quality using unsupervised criteria
(independence, clusterability, geometry preservation) and downstream clinical endpoints, thereby
elucidating when a learned spectral embedding can rival or augment theory-driven latent spaces.
In sum, PSD-based autoencoding offers a principled, computationally tractable pathway to EEG
representations that balance interpretability, robustness, and task transfer, and thus forms a key
pillar of the data-driven group assessed in this work.

2.3.3

EEGNet as an Autoencoder for EEG Representation Learning

EEGNet is a compact convolutional architecture designed specifically for electroencephalography
(EEG), built on depthwise–separable convolutions to encode domain-informed inductive biases
while maintaining strong parameter efficiency (?). In its canonical form, EEGNet factorizes spatio–temporal processing into (i) temporal convolutions that approximate band-pass filtering and
9

(ii) depthwise spatial filtering that learns channel-wise topographies, followed by separable convolutions that increase representational capacity at low computational cost. This factorization aligns
with established neurophysiological priors—namely that diagnostically informative information is
jointly structured across time (oscillatory rhythms) and space (sensor topographies)—and has
made EEGNet a widely adopted baseline for supervised decoding across diverse EEG paradigms.
In this work, we consider an autoencoder adaptation of EEGNet, repurposing its encoder as
a general-purpose feature extractor and coupling it to a symmetric decoder trained with a reconstruction objective. This design reframes EEGNet from a discriminative classifier to a generative
representation learner: given an input EEG segment (in the time domain or a spectro–temporal
transform), the encoder compresses the signal into a low-dimensional latent code, and the decoder
reconstructs the input from this code. Optimizing reconstruction error (e.g., mean squared error) encourages the latent space to preserve information necessary to explain the observed data
distribution, thereby supporting label-efficient transfer to downstream clinical tasks. Relative to
supervised training, the autoencoder formulation mitigates overfitting to specific labels or acquisition protocols and can exploit large quantities of unlabeled data—properties that are particularly
desirable in clinical EEG where labels are sparse and heterogeneous.
Architecturally, the encoder retains EEGNet’s depthwise–separable blocks to preserve its priors
on temporal band structure and spatial topography, while the decoder mirrors these operations via
transposed or separable convolutions to reconstitute signals. Regularization can be imposed in the
latent space (e.g., sparsity, contractive penalties, or denoising perturbations) to promote robustness
and disentanglement, complementing the inherent inductive biases of depthwise–separable filtering.
When trained on normalized inputs with standardized channel layouts, the resulting latents tend to
exhibit smoothness and invariance to nuisance variability (e.g., mild channel noise), while remaining
expressive enough to capture clinically salient dynamics.
Positioned within the broader literature on representation learning, EEGNet autoencoders instantiate the classic autoencoder principle—nonlinear compression with reconstruction as a selfsupervised target (?)—but instantiated with EEG-specific architectural constraints. They occupy
a middle ground between hand-crafted feature pipelines and large-scale self-supervised pretraining:
compared to handcrafted features, they offer greater expressivity and task-transfer, and compared
to contrastive or predictive pretext tasks, they provide a simpler training signal with fewer engineering dependencies. Importantly, their interpretability is enhanced by the separable design:
first-layer temporal kernels can be inspected as learned band-pass filters, while depthwise spatial
filters reveal channel topographies, facilitating physiological plausibility assessments.
In the context of this thesis, EEGNet-based autoencoders serve as a data-driven latent extractor against which mechanistic, whole-brain latent parametrizations are compared. Because
the objective and inductive biases differ substantially from biophysical models (which encode explicit hypotheses about neural mass dynamics), a side-by-side evaluation elucidates complementary
strengths: autoencoder latents may excel in capturing idiosyncratic, dataset-specific variance and
subtle spectro–temporal regularities, whereas mechanistic latents emphasize parsimonious, physiologically interpretable parameters. Accordingly, we evaluate EEGNet autoencoder latents using
both unsupervised criteria (e.g., independence, clusterability, geometry preservation) and downstream clinical endpoints, providing an empirical basis for assessing whether reconstruction-driven,
separable-convolution embeddings offer robust, transferable structure for clinical EEG analysis.

2.3.4

Feature extraction at scale: HCTSA and catch22

A long-standing challenge in time-series analysis is the principled selection of informative, domainagnostic descriptors from a vast landscape of candidate measures. Fulcher and colleagues addressed
this by introducing a highly comparative framework that systematizes time-series phenotyping
at scale. Their initial study, “Highly comparative time-series analysis: the empirical structure
of time series and their methods,” benchmarked over 9,000 features across diverse datasets to
characterize empirical structure, redundancy, and performance trade-offs among methods (?). This
work motivated a unifying software ecosystem, hctsa, that enables the extraction, quality control,
and statistical comparison of thousands of features in a reproducible, data-driven workflow (?).
Building on these analyses, Lubba et al. distilled the space into catch22 —a curated set of 22
canonical features selected to maximize discriminative utility while minimizing redundancy and
computational burden (?).
The catch22 set spans complementary classes of descriptors, including distributional sum10

maries, linear and nonlinear autocorrelation metrics, measures of stationarity and trend, entropyand complexity-based indices, motif/periodicity indicators, and outlier/transition statistics. Implemented in efficient C with bindings for common scientific environments, catch22 affords near
real-time computation on short segments, facilitating per-channel feature extraction and straightforward concatenation across sensors. Crucially, its hand-crafted design preserves interpretability:
individual coordinates admit meaningful post hoc analysis (e.g., relating autocorrelation decay or
entropy to physiological hypotheses), a property that is often attenuated in high-capacity learned
representations.
Within clinical EEG, catch22 serves as a strong, transparent baseline. When applied per
channel and aggregated, it captures salient temporal regularities and nonstationarities that underlie oscillatory dynamics and event structure, while remaining robust to moderate noise and
limited data regimes. In the context of this thesis, catch22 complements both mechanistic latent parametrizations and deep learned embeddings: it offers a compact, interpretable reference
point for latent-space comparisons, clarifying the trade-offs between expressivity, computational
efficiency, and physiological interpretability across modeling paradigms (???).

2.4

Computational Brain Models

Computational Brain Models (CBMs) provide biophysically grounded abstractions of neural population dynamics that link mesoscopic physiology to macroscopic electrophysiology. By coarsegraining cortical and thalamic populations into interacting neural masses or neural fields, these
mechanistic models yield tractable dynamical systems whose transfer functions predict characteristic features of EEG and related signals. Canonical exemplars include cortico–thalamic neural field
models explicating thalamocortical loops and alpha generation, cortical neural mass models such
as Jansen–Rit capturing excitation–inhibition balance, mean-field decision models of the Wong–
Wang class formalizing slow synaptic integration, and minimal Hopf (Stuart–Landau) oscillators
approximating narrowband spectral peaks via normal forms.
When extended to whole-brain (connectome-coupled) instantiations, CBMs are typically configured by: (1) selecting a local node model (mass or field) to capture mesoscopic dynamics; (2)
embedding one node per parcellated region and coupling them via a structural connectivity matrix
W with axonal delays τ (often scaled by a global gain G); (3) driving the network with stochastic
and/or task-related inputs; and (4) mapping state variables to sensor space through an observation
model (e.g., a linear lead-field for EEG).
In clinical and research contexts, CBMs serve two complementary roles: they expose interpretable latent variables (e.g., synaptic gains, time constants, excitation–inhibition ratios, conduction delays) that can be fitted to data, and they generate synthetic signals for hypothesis testing
and mechanistic falsification. In this thesis, we fit local (single-node or per-channel) CBMs directly
to sensor-space spectra (channel-averaged or per-channel PSDs) and treat the inferred parameter vectors as mechanistic latent representations: compact, physiologically annotated coordinates
spanning gains, time constants, and effective noise drives. This perspective aligns CBMs with dimensionality reduction—compressing dynamics into a low-dimensional, interpretable space—while
reserving the term “whole-brain” for future connectome-coupled extensions.

2.4.1

Jansen–Rit Neural Mass Models

The Jansen–Rit (JR) model is a seminal neural mass formulation that provides a parsimonious,
biophysically grounded account of mesoscopic cortical dynamics measured with EEG (?). In its
canonical form, the model describes the interaction of three coupled neural subpopulations within
a cortical column: pyramidal cells (the primary contributors to scalp EEG) and excitatory and
inhibitory interneurons. Synaptic input is transformed into postsynaptic membrane potentials via
impulse response kernels that approximate excitatory and inhibitory synaptic dynamics, while a
static sigmoidal nonlinearity maps mean membrane potential to mean firing rate. The net effect
is an interpretable, low-dimensional dynamical system whose parameters encode physiologically
meaningful quantities (e.g., synaptic gains, time constants, and global input/noise levels), and
whose outputs reproduce characteristic rhythms, notably in the alpha band, under suitable parameter regimes.
Beyond time-domain simulations, linearization of the JR dynamics around a stable operating point yields a frequency-domain transfer function that permits direct comparison to empirical
11

power spectral densities (PSDs) of EEG (??). This spectral perspective is especially useful for
model inversion on clinical recordings, where the stationary or quasi-stationary assumption is
reasonable over short windows. Fitting the linearized JR model to empirical PSDs provides a
principled means of parameter estimation and thereby latent representation learning in a biophysically interpretable space. At the same time, inference is challenged by non-convexity, parameter
non-identifiability, and the entanglement of physiological mechanisms that can produce similar
spectral signatures (??). To address these issues, prior work has used Bayesian inversion (e.g., Dynamic Causal Modeling), stochastic search, and approximate Bayesian computation; evolutionary
strategies have been particularly attractive for robust black-box optimization in noisy, non-convex
landscapes (??).
The JR family sits within a broader lineage of neural mass and field models used to interpret
EEG/MEG, including the Wendling model for epileptiform activity and continuum neural field theories that incorporate spatial coupling (??). Compared to more recent mean-field approximations
of spiking networks (e.g., Wong–Wang-type models) or field-theoretic cortico–thalamic formulations, JR offers a compact state space, a clear mapping from parameters to synaptic physiology,
and a well-studied bifurcation structure underpinning oscillatory regimes (??). These properties
have motivated extensive applications in parameter estimation, state classification, and mechanistic
hypothesis testing across healthy and pathological EEG.
In this thesis, we employ a reduced, linearized JR variant to derive latent features by fitting the
model to empirical EEG spectra. Specifically, we fit either (i) a channel-averaged PSD to obtain a
global cortical-column summary, or (ii) per-channel PSDs to capture spatially resolved biophysical
heterogeneity. We adopt a compact parameterization (e.g., six effective parameters comprising excitatory/inhibitory gains, synaptic time constants, input drive, and noise scale) and estimate these
via covariance matrix adaptation evolution strategies (CMA-ES), which provide robust, gradientfree optimization under measurement noise and local minima. The resulting parameter vectors
constitute low-dimensional, interpretable latents that can be compared directly with data-driven
representations (e.g., PCA over PSD, catch22, autoencoders) and with alternative mechanistic
embeddings (e.g., Wong–Wang, cortico–thalamic, Hopf), enabling a systematic assessment of the
trade-off between interpretability and task performance.
Positioned within the related-work landscape, our use of the JR model reflects a long tradition of
leveraging neural mass models for EEG interpretation, while aligning with contemporary practices
that evaluate representations by both unsupervised latent quality and downstream task informativeness. By standardizing preprocessing, spectral estimation, and evaluation across methods, we
provide a fair comparison of JR-derived latents against both mechanistic and learned baselines,
clarifying when and how biophysically constrained embeddings confer advantages in clinical EEG
analysis.

2.4.2

Cortico–Thalamic model

Cortico–thalamic models (CTMs) arise from neural field theory and provide a compact, biophysically interpretable account of macroscopic EEG dynamics by explicitly modelling the reciprocally
coupled cortex–thalamus loop (???). In their canonical form, CTMs aggregate interacting neuronal
populations (cortical excitatory and inhibitory populations; thalamic relay and reticular nuclei) and
the long-range corticothalamic projections into a set of linear (or linearised) delay-differential equations that govern population-averaged membrane potentials and firing rates. Linearisation about a
stable fixed point yields frequency-domain transfer functions whose magnitude-squared responses
predict the characteristic shape of resting-state EEG power spectra, including the emergence and
modulation of the alpha peak by corticothalamic gain, synaptic time constants, axonal conduction
velocities, and loop delays (??). Because these parameters correspond to physiological quantities
(e.g., excitatory/inhibitory gains, synaptic time constants, thalamic loop gain), CTMs offer an
attractive mechanism-based latent parameterisation of EEG activity.
Historically, the Robinson–Rennie–Wright family of CTMs established a principled bridge between mesoscopic physiology and scalp spectra, demonstrating that a modest number of global
parameters can reproduce a wide range of spectral phenotypes observed across subjects and states
(??). The analysis is typically posed in (ω, k) space, where ω is angular frequency and k the cortical spatial wave-number; spatial propagation and synaptic filtering produce a rational transfer
function H(ω, k), and the predicted spectrum takes the form S(ω) ∝ |H(ω)|2 Q(ω), with Q encoding effective noise drives. When spatial dispersion is neglected (or averaged), a “zero-dimensional”
12

variant suffices for fitting channel-averaged spectra, a strategy widely adopted in clinical EEG
settings where robust per-channel spatial inversion is impractical.
Inversion of CTMs from empirical EEG is most often formulated as a spectral-fitting problem:
given an empirical power spectral density (PSD), estimate the parameter vector θ that minimises
a frequency-weighted discrepancy between model and data. Because the forward map θ 7→ Sθ (ω)
is nonlinear and can be multimodal, black-box optimisers such as Covariance Matrix Adaptation
Evolution Strategy (CMA–ES) are commonly employed for robust estimation without requiring
gradients (?). Recent work has explored amortised inference in which a neural regressor is trained
to map PSDs directly to CTM parameters, reducing runtime while preserving the mechanistic
semantics of the latent space (??). In both regimes, one may fit either a channel-averaged PSD
(yielding a global latent vector) or per-channel PSDs (yielding spatially resolved but noisier latents).
The former enhances identifiability and stability; the latter provides finer granularity at the cost
of variance.
CTMs occupy a distinctive niche among mesoscopic models used for EEG. Compared with neural mass models such as Jansen–Rit (JR), which capture a canonical cortical microcircuit without
explicit thalamic components (?), CTMs explicitly incorporate thalamocortical loops and conduction delays, making them particularly apt for explaining alpha rhythm phenomenology and its
pharmacological or state-dependent modulation. In contrast to mean-field decision models such
as Wong–Wang (?), CTMs prioritise spectral stationarity and linear response around equilibrium
rather than metastable, stimulus-driven dynamics. Minimal dynamical proxies such as Hopf (Stuart–Landau) oscillators capture narrowband spectral peaks via low-order bifurcation normal forms
(?), but they lack the layered interpretability of CTM parameters. Consequently, CTMs provide
a richer mechanistic latent space than purely statistical features (e.g., Catch22) or unsupervised
embeddings (e.g., PCA, autoencoders), while remaining tractable to invert in large cohorts.
Notwithstanding these advantages, CTM inversion faces familiar challenges. First, parameter identifiability can be limited when distinct parameter combinations induce similar spectral
shapes; careful frequency weighting, priors, and sensitivity analyses are therefore critical. Second, linearisation and approximate stationarity assumptions may underfit transient, non-linear,
or cross-frequency phenomena prevalent in real-world EEG. Third, per-channel fits can be confounded by volume conduction and reference effects, motivating the use of canonical montages,
channel selection, and robust preprocessing. Finally, noise-drive modelling (e.g., coloured cortical
vs thalamic inputs) affects the tail behaviour of spectra and should be treated consistently across
subjects and cohorts (?).
In the present work, CTMs serve as a mechanistic latent extractor: we map empirical PSDs—
computed after a rigorous EEG cleaning pipeline—to a compact parameter vector that constitutes
the latent representation. We evaluate two practical variants aligned with the literature: (i)
CMA–ES fits to channel-averaged PSDs for a stable, global latent; and (ii) amortised (neural)
regression from PSDs to parameters to enable fast, scalable inference suitable for large datasets.
These CTM latents are directly compared to latents derived from JR, Wong–Wang, Hopf, and
several data-driven alternatives (Catch22, PCA, PSD–AE, EEGNet–AE, EEG2Rep), enabling a
principled assessment of the trade-off between interpretability and task performance. By situating
CTMs within a unified evaluation protocol that includes independence (HSIC), clustering structure, manifold preservation, and downstream classification metrics, we quantify not only predictive
utility but also the structural quality of the learned/mechanistic latent spaces.
Overall, CTMs provide a theoretically grounded baseline for mechanistic EEG representation
learning: they encode neurophysiologically meaningful axes of variation, admit efficient spectral
inversion, and facilitate transparent interpretation of latent–behaviour links. Their inclusion in our
comparative framework clarifies when mechanistic sufficiency is achieved and when richer, datadriven representations are warranted, thereby informing future hybrid approaches that combine
neural field priors with flexible inference engines.
13

Figure 2.1: Schematic of a cortico–thalamic neural field model with corticocortical and thalamo–cortical loops, characteristic delays, and effective gains.

2.4.3

The Wong–Wang model (mean-field attractor dynamics)

The Wong–Wang class of dynamic mean-field (DMF) models (??) provides a parsimonious mechanistic account of cortical population dynamics by coarse-graining synaptic and spiking activity
into a low-dimensional, nonlinearly coupled excitatory–inhibitory rate system. In their singlenode form, these models capture noise-driven, nonlinear fluctuations with saturating input–output
transfer, governed by a small number of physiologically interpretable parameters (e.g., effective recurrent coupling, synaptic time constants, external drive, and noise strength). Originally developed
to explain attractor dynamics underlying decision-making, DMF models have since been widely
adopted in whole-brain modeling to reproduce resting-state activity and spectra when coupled
through anatomical connectivity (???).
We employ a single-node stochastic DMF variant as a compact latent parameterization of EEG
dynamics. Let r(t) denote the population firing rate and s(t) a synaptic gating variable with
characteristic time scale τs . The nonlinear transfer function H maps synaptic input current I(t)
to firing rate via a saturating form, for instance
H(I) ≡ ϕ(aI − b) =

aI − b
,
1 − exp{−d (aI − b)}

which regularizes near-threshold behavior and bounds the gain (?). The stochastic synaptic dynamics follow

τs ṡ(t) = −s(t) + γ [1 − s(t)] H I(t) + σ η(t),
with γ a dimensionless gain, σ the noise amplitude, and η(t) standard Gaussian white noise. Effective input I(t) aggregates external drive I0 and recurrent feedback scaled by an effective coupling
J (absorbing inhibitory contributions under a mean-field closure). This minimal specification suffices to generate 1/f-like spectral profiles with band-limited peaks whose position and prominence
are regulated by (τs , γ, J, I0 , σ), thereby inducing an interpretable, low-dimensional manifold of
spectral shapes.
In our pipeline, this single-node DMF is used not as a forward simulator for long-range coupled
networks, but as a spectral proxy whose parameters constitute the latent features. Specifically,
we fit θ = [J, τs , γ, I0 , σ] to empirical power spectral densities (PSDs) estimated from cleaned
EEG using Welch’s method. We consider both channel-averaged PSDs and per-channel PSDs,
trading off robustness against spatial specificity. Because the loss landscape is non-convex and
the likelihood intractable, we adopt black-box optimization via CMA-ES (?), which has proven
effective in related neural mass and field model fitting. Time stepping (when required) uses Euler–
Maruyama discretization to ensure numerically stable stochastic integration in the vicinity of fixed
points.
Positioned within related mechanistic approaches, Wong–Wang models complement classical
neural mass models such as Jansen–Rit (with intrinsic alpha resonances) and linear neural field
14

models such as cortico–thalamic transfer-function formulations (??). Relative to Hopf (Stuart–
Landau) bifurcation models used as spectral surrogates, the DMF retains an explicit, saturating
input–output nonlinearity and physiologically meaningful timescales, offering a richer control of
spectral peak formation and noise shaping. As latent representations, DMF parameters are interpretable and compact, enabling principled comparisons to data-driven embeddings (e.g., PCA
over PSDs, autoencoder latents, and self-supervised encoders). At the same time, they inherit
well-known caveats: potential parameter non-identifiability from spectra alone, sensitivity to preprocessing, and local minima in black-box fitting. Our study situates Wong–Wang latents within a
unified evaluation framework alongside alternative mechanistic and learned representations, quantifying their statistical structure (independence, clusterability, geometry preservation) and downstream task utility on clinical EEG benchmarks.

2.4.4

Hopf/Stuart-Landau model

A large body of work has established the Hopf (Andronov–Hopf) bifurcation as a parsimonious
organizing principle for cortical oscillations, with the Stuart–Landau normal form serving as the
canonical local model of dynamics near the transition from a fixed point to a limit cycle (??).
In complex neural populations, endogenous and stochastic inputs continually drive fluctuations
around such operating points, giving rise to narrowband spectral peaks whose center frequency
and linewidth reflect the intrinsic time constants and distance to bifurcation. This view has been
extensively exploited in neural mass/field modeling and whole-brain simulations to account for the
emergence and modulation of alpha, beta, and related rhythms observed in M/EEG (???).
Formally, the (noisy) Stuart–Landau oscillator,
ż(t) = (µ + iω0 ) z(t) − (1 + ic) |z(t)|2 z(t) + σ ξ(t),
captures, to lowest order, the amplitude–phase dynamics of a local neural population in the vicinity of a Hopf point. Here, z ∈ C (or equivalently R2 ) encodes the latent oscillatory state, ω0 the
natural angular frequency, µ the bifurcation parameter (negative in the noisy focus regime, vanishing at criticality), c a nonlinear frequency-shift coefficient, and σξ(t) an effective noise drive. In
the noise-driven regime (µ < 0), the power spectral density is well approximated by a Lorentzian
peak centered at f0 = ω0 /2π with half-width γ ∝ |µ|, often atop a broadband baseline. This
yields simple, interpretable spectral descriptors—peak amplitude, center frequency, linewidth, and
baseline—that are tightly linked to underlying dynamical parameters.
Within the broader landscape of mechanistic latent representations considered in this work (e.g.,
Jansen–Rit, Wong–Wang, cortico–thalamic models (???)), Hopf-based parametrizations occupy a
useful middle ground: they retain explicit dynamical semantics (proximity to criticality; oscillation frequency; nonlinear frequency pulling) while offering a compact, robust characterization of
spectra that is less over-parameterized than full neural mass models. Consequently, Hopf-inspired
fits have been used as building blocks in whole-brain models to explain resting-state rhythms and
their modulation by coupling and noise (??), and at the regional level to track state-dependent
shifts in oscillatory stability (e.g., arousal and pathology).
Methodologically, two families of approaches dominate related work. The first derives dynamical parameters by directly fitting the normal form (or its linear response) to empirical spectra,
frequently via black-box, derivative-free optimizers such as CMA-ES to handle non-convex objectives and bound constraints (?). The second leverages spectral parameterizations that decouple
background and rhythmic components (e.g., Lorentzian peaks plus broadband) and then interprets the resulting peak parameters through the lens of Hopf dynamics (?). Both strategies aim
to recover a small set of physiologically meaningful latent variables that vary systematically across
channels, subjects, and conditions.
In the context of our thesis, Hopf/Stuart–Landau models serve as one mechanistic latentextraction baseline: we summarize channel-averaged (and, where appropriate, per-channel) power
spectra by band-specific Lorentzian components parameterized by peak amplitude, center frequency, linewidth, and baseline. These latents provide (i) interpretable, low-dimensional descriptors of oscillatory content; (ii) a principled link to dynamical systems theory; and (iii) a complementary counterpoint to data-driven embeddings (e.g., PCA, autoencoders, self-supervised encoders).
15

Limitations noted in the literature include identifiability trade-offs between linewidth and noise
level, sensitivity to non-stationarities, and the reduced expressivity relative to richer neural mass
models; nonetheless, the Stuart–Landau normal form remains a widely used, theoretically grounded
scaffold for characterizing M/EEG oscillations in comparative pipelines such as ours (??).

2.5

Model fitting and parameter identifiability

After embedding the local model on the connectome and specifying the observation model, only
a modest number of free parameters must be tuned (model-specific gains, time constants, global
coupling G, noise levels, and, if required, a small set of regional modifiers). We consider three
optimiser families:
• Variational Laplace (Bayesian). Treats parameters as random variables, alternating
Newton-style updates of the posterior mean with closed-form covariance updates. For smooth
frequency-domain likelihoods (e.g. PSD residuals or cross-spectral densities) this is fast and
yields credible intervals in situ. It also encourages physiologically plausible solutions via
explicit priors.
• Gradient-based methods. With automatic differentiation (or adjoints), optimisers such
as Adam or L-BFGS follow exact gradients and converge quickly on well-behaved objectives.
Performance depends on sensible initialisation and differentiability of the forward/observation
pipeline.
• Evolutionary strategies (e.g. CMA-ES). Population-based search over a mean–covariance
family is robust to local minima and non-smooth losses but requires many forward evaluations
[4]. We use CMA-ES for JR/CTM when exploring hybrid losses or time-domain objectives.
Loss design and observation choices. For CTM we primarily exploit closed-form PSDs, aligning model spectra to empirical EEG (typically 1–45,Hz) to emphasise oscillatory content and 1/f
slope. For JR and Wong–Wang/Hopf we consider (i) frequency-domain losses on PSDs or crossspectra and (ii) time-domain losses for evoked responses, depending on the phenomenon of interest.
Multi-objective formulations (e.g. a weighted sum of spectral shape and bandpower coherence) help
regularise fits and reduce parameter degeneracy.
Identifiability, sloppiness, and degeneracy. As in many nonlinear biophysical models, distinct parameter combinations can yield nearly indistinguishable EEG summaries (“equifinality”).
Typical couplings include (G vs. local gains), (delays vs. synaptic time constants), and (excitatory vs. inhibitory gains) that jointly shape spectral peaks and 1/f slope. To mitigate this, we
(i) impose informative priors and physiological bounds; (ii) reparameterise in log-space and fix
non-identifiable scalings; (iii) perform sensitivity/profile-likelihood analyses; and (iv) use posterior curvature (Laplace) to quantify uncertainty. Where feasible, we incorporate additional data
constraints (e.g. multi-band targets or evoked transients) to break degeneracies.
Amortised inference. For scalability we also evaluate amortised regressors trained on synthetic
simulations to map EEG summaries (e.g. PSDs) directly to parameters (“ctm_nn” in our pipeline).
This yields near-instantaneous predictions at test time and enables large-scale screening, at the
cost of potential simulator–reality mismatch. We therefore pair amortised estimates with targeted
local refinement (e.g. short CMA-ES runs) and retain Bayesian uncertainty quantification when
using variational objectives.
In summary, we treat whole-brain model fitting as physiologically constrained dimensionality
reduction: the inferred parameter vector is a low-dimensional latent code with explicit mechanistic
semantics. The remainder of this work focuses on (i) efficient estimation of JR and cortico-thalamic
parameters from resting-state and task EEG, and (ii) systematic evaluation of these latent codes
against data-driven representations (PCA, CAEs, EEGNet, Catch22) in terms of task performance,
stability, and interpretability, in line with the pipeline outlined in our repository.
16

2.6

Dataset

The Temple University Hospital (TUH) EEG Corpus is the largest publicly available clinical EEG
repository, comprising over 30,000 EEG records from more than 18,000 unique patients, with approximately 75% of sessions labeled as abnormal in accompanying reports (??). Labels and reports
are derived from routine clinical practice, so the notion of “abnormal” reflects the reading neurologist’s impression and can include a wide spectrum of findings (slowing, epileptiform discharges,
ictal or post-ictal patterns, artifacts deemed clinically significant). Importantly, labels are applied
at the file/session level : a file is considered abnormal if any portion contains abnormal activity,
even if that activity occupies only a small fraction of the recording.
A widely used derivative for binary screening tasks is the Temple University Hospital Abnormal
EEG (TUH-AB) corpus, which is carved out of TUH EEG by automatically screening session
reports with natural language processing and then manually verifying the labels. TUH-AB applies
additional filters to improve homogeneity and reproducibility:
• Adult-only records (pediatric EEGs excluded due to distinct patterns).
• Averaged-reference (AR) studies only, to reduce montage heterogeneity and device variability
(??).
• One EDF file (≥15 min) per session to limit within-subject redundancy.
These choices drastically reduce the size of the corpus compared to the full TUH EEG dataset,
but yield a more controlled benchmark for machine learning.
Canonical TUH-AB releases provide demographically balanced patient-wise train/eval partitions. At the version used here, the training set contains 1,398 abnormal and 1,387 normal EEGs
(546.4 and 518.3 hours respectively across 2,138 patients), while the evaluation set contains 130
abnormal and 150 normal EEGs (48.9 and 55.4 hours across 253 patients) (?). A smaller “short”
subset (80 abnormal / 82 normal train; 55 abnormal / 51 normal eval) has been used in pilot
studies for rapid iteration and parameter sweeps.
Early TUH-AB pipelines emphasized compact spectral–cepstral representations inspired by
MFCCs: linear filterbanks, c0 energy, low-order cepstra, deltas and delta-deltas. To limit dimensionality, some approaches confined inputs to a diagnostically informative channel (e.g., T5–O1)
after screening channels for sensitivity, and often applied PCA to further reduce feature size (??).
These designs traded spatial richness for robustness and computational efficiency in the face of
heterogeneous clinical data.

2.6.1

Our setting

We adopt TUH-AB as the common benchmark but enforce method-agnostic fairness via a unified
preprocessing stack and standardized inputs across all latent extractors. Concretely, we:
1. canonicalize channels to a fixed 10–20 subset and ordering;
2. apply consistent cleaning (artifact annotation, ICA-assisted ocular/cardiac removal, badchannel interpolation, rereferencing);
3. resample to a uniform sampling rate; and
4. segment into fixed-length, non-overlapping epochs with identical inclusion masks.
We strictly adhere to the official TUH-AB patient-wise train/eval partitions and avoid label
usage during representation learning to prevent task-specific leakage. This protocol yields identical
subjects, windows, and splits for all methods, enabling principled cross-family comparisons that
are not confounded by dataset handling. See Chapter ?? for full details.

17

Chapter 3

Pipeline
3.1

Overview

This thesis investigates how different latent extraction paradigms encode clinically relevant EEG
structure. We construct a unified pipeline that (i) standardizes clinical EEG (TUH-AB) via a rigorous preprocessing stack, (ii) derives latent representations using both mechanistic, biophysically
motivated computational brain models and data-driven encoders, and (iii) evaluates these latents
with unsupervised criteria and supervised downstream tasks. By holding data handling and evaluation constant, we obtain a principled comparison of interpretability, robustness, and task utility
across modeling families. Figure 3.1 illustrates the high-level structure of our pipeline.

3.1.1

Problem Statement and Goals

Problem. Given clinical EEG, how do mechanistic and data-driven methods differ in the structure,
information content, and downstream utility of their latent representations?
Goals.
1. Design a method-agnostic pipeline that standardizes preprocessing, inputs, and splits.
2. Extract latents from (a) computational brain models (e.g., CTM, Jansen–Rit, Wong–Wang,
Hopf) and (b) data-driven methods (e.g., catch22, PCA over PSD, EEGNet/PSD autoencoders, EEG2Rep).
3. Assess latent quality via unsupervised metrics (independence, clusterability, geometry) and
information-theoretic analyses.
4. Quantify task relevance using fixed classifier/regressor heads on clinical endpoints (abnormality, sex, age), with controlled hyperparameter search.

3.2

Preprocessing and Standardization

Robust latent representation learning from clinical EEG hinges on a carefully standardized signal
preparation pipeline. Heterogeneity in montages, hardware, and acquisition protocols introduces
substantial nuisance variability that can dominate downstream models if not controlled. We adopt
a unified preprocessing stack that enforces a common channel space and sampling lattice, attenuates
artifacts while preserving neurophysiological structure, and produces fixed-length epochs suitable
for fair, method-agnostic comparison across all extractors.

3.2.1

Channel canonicalization and montage handling

Clinical EEGs vary in channel naming conventions, auxiliary sensors, and referencing schemes.
We first harmonize channel labels to the international 10–20 system, applying legacy renamings
(e.g., T3→T7, T4→T8) and case normalization. We then select a fixed canonical subset (e.g.,
19-channel 10–20) and impose a deterministic ordering to yield a consistent sensor vector space.
18

Data
TUH-AB EEG

Preprocessing
montage selection, filtering, ICA/AutoReject, rereferencing, epoching, PSD normalization

Latent Extraction
CBMs: CTM / Jansen–Rit / Wong–Wang / Hopf
Data-driven: catch22 / PCA(PSD) / PSD-AE / EEGNet-AE

Latent Evaluation
HSIC, clustering (Silhouette/DB/CH), geometry (trustworthiness/continuity/dist. corr.), PCA EVR, MI

Downstream Tasks
Labels: abnormality and sex
fixed heads with Optuna search
Figure 3.1: High-level pipeline structure: standardized preprocessing, method-agnostic latent extraction, unsupervised latent evaluation, and supervised downstream assessment.
Recordings missing any canonical channel are excluded or repaired via spherical-spline interpolation from neighboring sensors, after which a standard 10–20 head model montage is assigned for
spatial consistency. This canonicalization removes montage-induced confounds and ensures that
per-channel methods receive commensurate inputs.

3.2.2

Filtering, rereferencing, resampling

To reduce slow drifts and high-frequency noise while preserving conventional EEG rhythm bands,
we apply a high-pass filter (e.g., 0.5 Hz) and a low-pass filter (e.g., 45 Hz). Power-line contamination
is mitigated with narrow notch filters at mains frequency and harmonics when required. Signals
are rereferenced to a common average reference to suppress global offsets and improve topographic
interpretability. Finally, all recordings are resampled to a common sampling rate fs (e.g., fs =
128 Hz), which standardizes temporal resolution, reduces computational cost, and harmonizes the
frequency grid for spectral analysis.

3.2.3

Artifact handling (ICA/EOG/ECG, AutoReject, bad-channel interpolation)

Ocular and cardiac artifacts are addressed using an ICA-based procedure: we fit an independent
component decomposition on band-limited data with robust amplitude clipping to stabilize the
unmixing, identify artifact components via correlations with EOG/ECG channels and stereotyped
time–frequency signatures, and remove them from the data. Muscle bursts and other transient
artifacts are annotated using automated detectors (e.g., muscle-zscore heuristics) to mark segments
for exclusion. Bad channels are detected via robust dispersion criteria and spatial inconsistency,
then interpolated using spherical splines to avoid systematic topographic bias. At the epoch level,
we employ automated rejection with data-driven thresholds (e.g., AutoReject) to exclude or repair
windows exhibiting extreme amplitudes or local discontinuities. This layered strategy targets
distinct artifact classes while minimizing distortion of intact neural activity.
19

3.2.4

Epoching protocol (length, overlap, masks)

Preprocessed continuous recordings are segmented into fixed-length, non-overlapping windows of
duration L seconds (e.g., L = 10 s). Fixed-length segmentation ensures comparable input statistics
across subjects and facilitates batching on constrained hardware. For each recording, we construct
binary masks that exclude windows intersecting annotated artifact segments or containing a fraction of missing/interpolated data above a predefined threshold. The resulting set of eligible epochs
defines the training and evaluation inputs for all latent extractors. By fixing epoch length, overlap (here, none), inclusion masks, and split membership a priori, we guarantee that cross-method
comparisons are not confounded by differences in data selection.

3.2.5

PSD estimation settings (Welch parameters) and normalization

When spectral features are required (either as direct inputs or as intermediate statistics), we estimate power spectral densities (PSDs) using Welch’s method with a globally fixed configuration to
ensure commensurability across subjects and methods. Concretely, spectra are computed on each
epoch with Hanning windows of length Nseg samples, 50% overlap, FFT size NFFT , and frequency
range restricted to [fmin , fmax ] (e.g., fmin = 1 Hz, fmax = 45 Hz). The frequency grid is thereby
identical across all analyses. To reduce heteroscedasticity and inter-subject scale variation, PSDs
are log-transformed when appropriate and normalized by total power within [fmin , fmax ] (unit-area
normalization), followed by cohort-level standardization (per-frequency z-scoring) computed on the
training split only. For per-channel methods, PSDs are computed channel-wise and concatenated
in canonical order; for channel-averaged variants, spectra are averaged across the canonical set before normalization. These choices produce well-conditioned inputs whose variance is concentrated
in physiologically relevant bands while preserving relative spectral shape, a key determinant of
downstream parameter fits and learned embeddings.

3.3

Latent extraction methods

The central objective of this thesis is to compare representations that compress multichannel EEG
into low-dimensional latent variables Z ∈ Rd while preserving task-relevant neurophysiological information. We operationalize latent quality along four desiderata: (i) sufficiency for downstream
clinical endpoints; (ii) robustness to nuisance variability (montage, mild artifacts, acquisition heterogeneity); (iii) interpretability or physiological plausibility; and (iv) computational tractability
and reproducibility at cohort scale. To this end, we benchmark complementary families of latent
extractors spanning mechanistic and data-driven paradigms under a unified preprocessing and evaluation protocol.
Mechanistic extractors instantiate biophysically grounded computational brain models (CBMs)
at the neural mass/mean-field level. In this setting, latents are explicit model parameters—e.g.,
synaptic gains and time constants (Jansen–Rit), cortico–thalamic coupling and propagation scales
(CTM), effective excitation and input drive (Wong–Wang), or normal-form coefficients capturing
narrowband oscillations (Hopf). Parameters are fitted to empirical spectra either by black-box
optimization (CMA-ES) or via an amortized mechanistic regressor that maps normalised PSDs
to CBM parameters in a single forward pass. To our knowledge, this adaptation of synthetic
amortized (simulation-based) inference to CBM spectral fitting for EEG spectra has not been
previously introduced for computation brain models which possess a closed-form PSD estimation.
Data-driven extractors learn or select statistical summaries from the data with minimal biophysical priors. We include (i) hand-crafted time-series descriptors (catch22 ) that yield interpretable,
per-channel features; (ii) linear subspace models (PCA on PSDs) that capture variance along
orthogonal spectral axes with frozen, cohort-fitted transforms; and (iii) learned encoders, comprising reconstruction-driven autoencoders in the spectral and time domains (including an EEGNetinspired autoencoder that encodes temporal–spatial inductive biases) and a pretrained/self-supervised
encoder (EEG2Rep) for label-efficient transfer. These methods differ in capacity, invariances, and
interpretability, thereby offering complementary baselines to the mechanistic family.
All extractors operate on identically preprocessed inputs (canonical channels, standardized
sampling, fixed-length epochs), and produce 1D latent vectors with consistent serialization for
20

downstream analysis. Subsequent sections detail the extractor architectures, fitting criteria, and
hyperparameters—including the amortized CBM variant—followed by a common suite of unsupervised latent diagnostics and supervised head evaluations that enable like-for-like comparisons
across families and quantify the empirical gains from amortization.

3.3.1

Cortico–Thalamic Model (CTM)

Input and preprocessing. We fit CTM parameters to sensor-space power spectral densities
(PSDs) computed from identically preprocessed EEG (canonical 10–20 channels, rereferenced,
artifact-attenuated, resampled). PSDs are estimated with Welch’s method and z-normalized per
recording; fitting frequencies are restricted to 1–45 Hz and aligned exactly to the Welch grid to
avoid interpolation.
Model and parameters. CTM coarse-grains cortical and thalamic populations into a coupled
linear (or weakly nonlinear) neural field whose frequency response HCTM (f ; θ) maps stochastic
population drives η to mesoscopic field potentials. The model PSD is
2

Smodel (f ; θ) = HCTM (f ; θ) Sη (θ) + Sbase (f ),
where θ encodes physiologically interpretable quantities (loop gains, synaptic time constants, spatial propagation/decay scale, effective noise amplitude). We consider two variants: (i) channelaveraged PSDs (ctm_cma_avg) for robustness; (ii) per-channel PSDs (ctm_cma_pc) for spatial
specificity.
Objective and constraints. Parameters are estimated by minimizing a log-spectral discrepancy
L(θ) =

X

h
i2
w(f ) log Semp (f ) − log Smodel (f ; θ) ,

f ∈F

with nonnegativity and physiologically motivated box constraints on gains, time constants, and
propagation scale. We use uniform w(f ) (optionally w(f ) ∝ 1/f in sensitivity checks).
Estimation. We employ CMA-ES for black-box, nonconvex optimization with bounded domains.
The initial step size σ0 and population size follow default CMA heuristics; termination occurs on
fitness plateau or a fixed evaluation budget. Frequencies, normalization, and bounds are identical
across subjects to ensure comparability.
Representation. For ctm_cma_avg, the fitted θ ∈ Rp forms the latent vector. For ctm_cma_pc,
per-channel fits θ (c) are concatenated in canonical order. These latents are serialized as 1D float
vectors and passed unchanged to the common latent diagnostics and downstream heads, enabling
like-for-like evaluation against data-driven extractors under identical inputs and splits.

3.3.2

Cortico–Thalamic Model (CTM), amortized inference

Inputs and featurization. We infer CTM parameters from sensor-space power spectral densities (PSDs) computed on identically preprocessed EEG (canonical 10–20 channels, rereferenced,
resampled, artifact-attenuated upstream). PSDs are estimated with Welch’s method and log–z
score normalised per recording. The CTM forward model is evaluated on the exact Welch frequency grid (derived from the same settings) to avoid interpolation.
Parameterization. The latent vector is the 8-dimensional CTM parameter vector


θ = Gee , Gei , Gese , Gesre , Gsrs , α, β, t0 ,
encoding loop gains, dendritic rate constants, and cortico–thalamic delay. We report two regimes:
channel-averaged (ctm_nn_avg) and per-channel (ctm_nn_pc); in the latter, a separate θ (c) is
inferred per canonical channel and concatenated in fixed order.
21

Amortized regressor and training data. We train a feedforward network gϕ : RK → R8 that
maps a normalised PSD vector x ∈ RK to θ̂ = gϕ (x). Training data are generated synthetically by
sampling θ from physiologically bounded uniform priors and computing the corresponding analytic
CTM PSD on the shared grid; targets are normalised identically to empirical PSDs. No teacher
fits from empirical data are used.
Objective. Learning minimises a spectral reconstruction loss: predicted parameters are passed
through the analytic CTM to produce a PSD, which is normalised and compared to the target
PSD on the same grid,


L(ϕ) = MSE norm SCTM (f ; gϕ (x)) , norm(x) ,
optionally restricted to a configured band (default 3–45 Hz). No parameter-space loss or auxiliary
regularisers are used. Optimisation uses Adam with an early-stopping heuristic on reconstruction
loss.
Inference and representation. At test time, we compute the Welch PSD from an empirical epoch, apply the same normalisation, and evaluate θ̂ = gϕ (x) in a single forward pass (no
projection/clamping). For ctm_nn_avg, θ̂ is used directly as the latent vector; for ctm_nn_pc,
(c)

per-channel predictions {θ̂ }c are concatenated. These 1D latents are then fed unchanged into
the shared latent diagnostics and downstream heads under identical splits and preprocessing.

3.3.3

Jansen-Rit Model (JR)

Input and preprocessing. We estimate JR parameters from sensor-space power spectral densities (PSDs) computed on identically preprocessed EEG (canonical 10–20 channels, rereferenced,
artifact-attenuated, resampled). PSDs are obtained with Welch’s method, z-normalized per recording, and evaluated on a fixed 1–45 Hz grid aligned to the Welch frequencies to avoid interpolation.
Model and parameters. The JR model coarse-grains a cortical column into three interacting neural masses (pyramidal, excitatory interneurons, inhibitory interneurons). In its linearized
frequency-domain form, the population dynamics induce a transfer function HJR (f ; θ) from stochastic synaptic input η to the pyramidal output (proxy for mesoscopic field potentials). The model
PSD is
2

Smodel (f ; θ) = HJR (f ; θ) Sη (θ) + Sbase (f ),
where θ is a reduced, physiologically interpretable set (six parameters in our implementation)
comprising synaptic gains and time constants for excitatory and inhibitory pathways, effective
coupling, and input/noise amplitude. This parameterization governs resonance structure (e.g.,
alpha) and broadband roll-off.
Objective and constraints.
L(θ) =

We fit θ by minimizing a log-spectral discrepancy
X

h
i2
w(f ) log Semp (f ) − log Smodel (f ; θ) ,

f ∈F

subject to nonnegativity and physiologically motivated box bounds on gains and time constants.
We use uniform weights w(f ) = 1 (with 1/f reweighting examined in sensitivity checks).
Estimation. Optimization is performed with CMA-ES to handle nonconvexity and weak parameter couplings. Population size and initial step σ0 follow standard CMA heuristics; termination is
triggered by fitness plateau or a fixed evaluation budget. PSD normalization, frequency grid, and
bounds are held constant across subjects for comparability.
22

Variants and representation. We consider (i) channel-averaged fitting (jr_avg), where
Welch PSDs are averaged across canonical channels to yield a robust target spectrum, and (ii)
per-channel fitting (jr_pc), where parameters are estimated independently for each channel to
retain spatial specificity. The fitted vectors θ (concatenated across channels for jr_pc) define
1D mechanistic latent representations passed unchanged to the common latent diagnostics and
downstream heads, enabling like-for-like comparison with data-driven extractors under identical
inputs and splits.

3.3.4

Wong–Wang Model (DMF)

Input and preprocessing. We fit Wong–Wang (dynamic mean-field; DMF) parameters to
sensor-space power spectral densities (PSDs) computed from identically preprocessed EEG (canonical 10–20 channels, rereferenced, artifact-attenuated, resampled). PSDs are estimated with Welch’s
method, z-normalized per recording, and evaluated on a fixed 1–45 Hz grid aligned to Welch frequencies to avoid interpolation.
Model and parameters. The single-node Wong–Wang model captures slow synaptic integration and recurrent excitation with a sigmoidal transfer, yielding a stochastic mean-field description of cortical activity. Linearization around the operating point induces a frequency response
HWW (f ; θ) from effective input noise η to the mesoscopic output proxy y. The model PSD is
2

Smodel (f ; θ) = HWW (f ; θ) Sη (θ) + Sbase (f ),
with parameter vector θ comprising recurrent coupling J, synaptic time constant τs , gain (slope)
γ, tonic input I0 , and noise amplitude σ (our implementation returns [J, τs (ms), γ, I0 , σ]). These
parameters shape low-frequency power, spectral peak breadth, and overall roll-off characteristic of
resting EEG.
Objective and constraints.
L(θ) =

We estimate θ by minimizing a log-spectral discrepancy
X

h
i2
w(f ) log Semp (f ) − log Smodel (f ; θ) ,

f ∈F

subject to physiologically motivated box bounds (nonnegativity of time scales and noise; restricted
ranges for J, γ, I0 ). We use uniform weights w(f ) = 1 (with 1/f reweighting examined in sensitivity
checks).
Estimation. Optimization uses CMA-ES to accommodate nonconvexity and parameter couplings. Population size and initial step σ0 follow standard heuristics; termination occurs on fitness
plateau or evaluation budget. Frequency grid, normalization, and bounds are held constant across
subjects for comparability.
Variants and representation. We consider (i) channel-averaged fitting (wong_wang_avg),
where Welch PSDs are averaged across canonical channels for robustness, and (ii) per-channel
fitting (wong_wang_pc), estimating parameters independently to retain spatial specificity. The
fitted vectors θ (concatenated across channels for wong_wang_pc) define 1D mechanistic latent
representations used unchanged in the common latent diagnostics and downstream heads, enabling
like-for-like comparison with data-driven extractors under identical inputs and splits.

3.3.5

Hopf (Stuart–Landau) oscillator: methodological specification

Input and preprocessing. We estimate Hopf-based spectral parameters from sensor-space
power spectral densities (PSDs) computed on identically preprocessed EEG (canonical 10–20 channels, rereferenced, artifact-attenuated, resampled). PSDs are obtained with Welch’s method, znormalized per recording, and evaluated on a fixed 1–45 Hz grid aligned to the Welch frequencies
to avoid interpolation.
23

Model and parameters. As a normal-form approximation to oscillatory dynamics near a supercritical Hopf bifurcation, the Stuart–Landau oscillator yields a narrowband spectral peak whose
linearized spectrum is well-approximated by a Lorentzian. We model the EEG PSD as a sum of
band-limited Lorentzians atop local baselines,
Smodel (f ; θ) =

X
b∈B

Ab
+ bb ,
(f − f0,b )2 + γb2

where B = {δ(1 − 4), θ(4 − 8), α(8 − 13), β(13 − 30)} denotes canonical bands. The parameter
vector θ = {Ab , f0,b , γb , bb }b∈B comprises amplitude Ab ≥ 0, center frequency f0,b ∈ [fmin,b , fmax,b ],
bandwidth γb > 0 (inverse damping), and a local baseline bb ≥ 0. This representation captures peak
height, location, sharpness, and residual broadband power per band.
Objective and constraints.
L(θ) =

Parameters are fitted by minimizing a log-spectral discrepancy,
X

h
i2
w(f ) log Semp (f ) − log Smodel (f ; θ) ,

f ∈F

subject to box constraints Ab ≥ 0, bb ≥ 0, γb ∈ [γmin , γmax ], and f0,b ∈ [fmin,b , fmax,b ] for each band b.
We use uniform weights w(f ) = 1; alternative 1/f reweighting is examined in sensitivity checks.
Estimation. We solve the bounded nonlinear least-squares problem with multiple randomized
initializations per band to avoid local minima, selecting the best-fit solution by L. Frequency grid,
normalization, and bounds are kept identical across subjects for comparability.
Variants and representation. We consider (i) channel-averaged fitting (hopf_avg), where
Welch PSDs are averaged across canonical channels for robustness, and (ii) per-channel fitting
(hopf_pc), estimating parameters independently to retain spatial specificity. The fitted parameters
{Ab , f0,b , γb , bb }b∈B (concatenated across bands and channels in hopf_pc) define 1D mechanistic
latent vectors that are passed unchanged to the common latent diagnostics and downstream heads,
enabling like-for-like comparison with other mechanistic and data-driven extractors under identical
inputs and splits.

3.3.6

catch22

Input and preprocessing. We extract catch22 features from identically preprocessed, artifactattenuated, rereferenced, and resampled EEG epochs with canonical 10–20 channel ordering. Inputs are time-domain segments (fixed length, standardized sampling) that have been z-scored per
epoch to remove scale variability.
Feature mapping. For each canonical channel c ∈ C (19-channel set), we compute the 22 canonical time-series characteristics using the reference catch22 implementation, yielding a per-channel
vector z(c) ∈ R22 that summarizes distributional shape, linear and nonlinear autocorrelation structure, stationarity/trend, entropy/complexity, motifs/periodicity, and transition/outlier statistics.
The subject-level latent is the concatenation

z = concat z(c) c∈C ∈ R22×|C| ,
preserving channel topology through a fixed ordering. To maintain a consistent dimensionality
under occasional channel omissions, we insert a zero vector in place of missing channels (rare after
canonicalization).
Normalization and stability. Because catch22 includes heterogeneous functionals (with distinct units and ranges), we operate on standardized inputs and retain raw feature values to preserve
interpretability; downstream models may apply per-coordinate standardization within the training split. The mapping is deterministic and parameter-free, ensuring exact reproducibility given
identical inputs.
24

Variants and representation. We use a single, per-channel variant (no averaging), prioritizing
spatial specificity and post hoc interpretability. The resulting 1D latent vectors (length 22 × 19)
are serialized without further transformation and forwarded unchanged to the common latent diagnostics (independence, clusterability, geometry) and supervised heads. This positions catch22 as a
transparent, computationally efficient baseline against which mechanistic and learned embeddings
can be compared under identical inputs, masks, and splits.

3.3.7

PCA over PSD

Input and preprocessing. We derive principal-component latents from sensor-space power
spectral densities (PSDs) computed on identically preprocessed EEG (canonical 10–20 channels,
rereferenced, artifact-attenuated, resampled). PSDs are estimated with Welch’s method on a fixed
1–45 Hz grid and log–z normalized per vector to stabilize scale.
Training and freezing. We fit a StandardScaler + PCA on the training split only. Training
data consist of per-channel PSD vectors stacked across all canonical channels and recordings,
yielding a design matrix X ∈ Rn×d (one row per channel instance; d frequency bins). After
standardization Xs = (X − µ)/σ, PCA is trained to obtain the top k components V ∈ Rk×d
(whitening optional; we use non-whitened components). The frozen artifact stores µ, σ, V (and
eigenvalues) for deterministic reuse across subjects.
Runtime extraction. Given an input PSD vector x ∈ Rd , we compute the latent

z = V

x−µ
σ



∈ Rk .

Two variants are supported: (i) per-channel (pca_pc), where the transform is applied to each
channel PSD and the k-dimensional codes are concatenated in canonical order (latent length k×|C|);
and (ii) channel-averaged (pca_avg), where channel PSDs are averaged prior to transformation
(latent length k).
Dimensionality and parameters. We fix k a priori (e.g., k=8) to balance variance capture
and compactness; k is chosen on the training split (explained-variance curves reported). No label
information is used during fitting. Frequency grid, normalization, and component matrices are
identical across subjects to ensure comparability.
Representation and reproducibility. Latents are 1D float vectors serialized without further
processing and passed unchanged to the common latent diagnostics and downstream heads. Using
a frozen scaler and projection guarantees exact reproducibility and prevents train–test contamination, enabling like-for-like comparison with mechanistic and learned extractors under identical
inputs and splits.

3.3.8

PSD Autoencoder (PSD-AE)

Input and preprocessing. We learn latents from sensor-space power spectral densities (PSDs)
computed on identically preprocessed EEG (canonical 10–20 channels, rereferenced, artifact-attenuated,
resampled). PSDs are estimated with Welch’s method on a fixed 1–45 Hz frequency grid and log–z
normalized per vector to stabilize scale and dynamic range; the model operates directly on these
normalized PSD vectors.
Architecture. The PSD-AE is a lightweight encoder–decoder operating on PSD feature space.
The encoder maps a d-dimensional PSD vector to a k-dimensional bottleneck z ∈ Rk via stacked
affine layers with nonlinearities; the decoder mirrors this mapping to reconstruct the input PSD.
This design trades raw time-domain invariances for a compact spectral representation that can
capture band structure, roll-off, and peak sharpness with few parameters.
25

Objective and training protocol. The autoencoder is trained on the training split only to
minimize mean squared reconstruction error (MSE) between input and output PSDs:
LAE = ∥x̂ − x∥22 ,
optionally with weight decay. Optimization uses minibatch Adam with early stopping on a heldout validation subset (fixed random split, patience-based criterion). Frequency grid, normalization,
batch size, and seeds are held constant for reproducibility. Once converged, weights are frozen and
used only for feature extraction.
Variants and runtime extraction. Two variants are supported: (i) channel-averaged (psd_ae_avg),
where we average channel PSDs prior to encoding to obtain a robust k-dimensional latent; and (ii)
per-channel (psd_ae_pc), where the encoder is applied to each channel PSD and the resulting
k-dimensional codes are concatenated in canonical order (latent length k × |C|). At inference,
the latent is the encoder’s bottleneck activation z, without any downstream task supervision or
fine-tuning.
Representation and comparability. Latents are serialized as 1D float vectors and passed unchanged to the common latent diagnostics (independence, clusterability, geometry) and supervised
heads. Using a frozen encoder, a shared Welch grid, and identical normalization guarantees likefor-like comparisons with mechanistic and other data-driven extractors under the same inputs,
masks, and splits. The bottleneck dimensionality k is fixed a priori (reported in the experimental
setup) to balance compactness and reconstruction fidelity.

3.3.9

EEGNet Autoencoder (combined time–spectral loss): methodological specification

Input and preprocessing. We learn latents from multichannel time-domain EEG epochs that
share the common preprocessing stack (canonical 10–20 channels, rereferenced, artifact-attenuated,
resampled) and per-epoch z-scoring. Let x ∈ RC×T denote a standardized segment (channels C,
samples T ).
Architecture. The encoder follows an EEGNet-style design with depthwise–separable convolutions: an initial temporal convolution (band-pass–like filtering), a depthwise spatial convolution
(channel-wise topographies), and a separable convolution block that increases capacity at low
parameter cost. The encoder maps x 7→ z ∈ Rk . The decoder mirrors this structure via transposed/separable convolutions to reconstruct x̂.
Combined objective. Training minimizes a composite reconstruction loss that couples timedomain fidelity with spectral and time–frequency consistency:
2

2

L = α ∥x̂ − x∥22 + β logPSD(x̂) − logPSD(x) 2 + γ Φ(x̂) − Φ(x) 2 + λ Ω(θ),
where PSD(·) denotes Welch spectra computed on the shared frequency grid (1–45 Hz, identical parameters across subjects), Φ(·) is a fixed time–frequency embedding (e.g., multi-resolution
STFT magnitude “image”), Ω is weight decay, and α, β, γ, λ ≥ 0 weight the terms. The spectral
terms (log–PSD and time–frequency) encourage preservation of band power, peak sharpness, and
spectro–temporal structure beyond pointwise waveform fidelity.
Training protocol. Optimization uses Adam on the training split only with a fixed batch size,
early stopping on a held-out validation subset, and deterministic seeds. Input shapes, Welch
parameters, and STFT settings are held constant for comparability. After convergence, the encoder
is frozen and used solely for feature extraction.
Runtime extraction and representation. At inference, the latent vector is the encoder bottleneck z ∈ Rk (no label supervision or fine-tuning). We operate on full multichannel inputs
(no channel averaging); the latent length k is fixed a priori and reported alongside reconstruction
metrics. Latents are serialized as 1D float vectors and passed unchanged to the common latent
26

diagnostics (independence, clusterability, geometry) and downstream heads, enabling like-for-like
comparison with mechanistic and other data-driven extractors under identical inputs, masks, and
splits.

3.3.10

Summary

The latent extraction module operationalizes two complementary paradigms: mechanistic, biophysically parameterized models (CTM, Jansen–Rit, Wong–Wang, Hopf) that yield interpretable
parameter vectors, and data-driven extractors (catch22, PCA over PSD, autoencoders, EEG2Rep)
that learn or select statistical structure with minimal priors. All methods consume identically
preprocessed inputs (canonical channels, fixed PSD grid or time-domain segments) and produce
standardized 1D latents (per-channel concatenated or channel-averaged), enabling like-for-like comparisons independent of model family. Where relevant, we provide both optimization-based and
amortized variants to separate inference speed from representational content. These design choices
ensure that downstream analyses reflect differences in representation quality rather than confounds
of data handling or training protocol. We now turn to the methodology for evaluating latent spaces,
covering unsupervised structure, geometric fidelity, and supervised task relevance.

3.4

Latent Evaluation

We evaluate latent representations Z ∈ Rd produced by all extractors under a single protocol
that controls for inputs, frequency grids, and splits. Unless stated, all computations are performed separately on train and eval splits; we report both numerical summaries and standardized
visualizations. Latent files are cached per method and re-used across runs if dataset counts are
unchanged.

3.4.1

Evaluation protocol and data handling

All extractors operate on identically preprocessed EEG (canonical 10–20 channels, artifact handling, rereferencing, resampling) segmented into fixed-length epochs. For each method and split,
we construct datasets of tuples
N

split
Zsplit = {(zi , yigender , yiage , yiabn )}i=1
.

Latents are 1D float vectors; labels are carried alongside without being used during representation
learning. Frequency-domain methods (mechanistic forward models and Welch PSDs) are aligned
to the same discrete grid to eliminate interpolation artefacts. All stochastic choices (initialisation,
subsampling) are seeded.

3.4.2

Intrinsic latent quality (unsupervised)

Variance and active units. For each split we compute per-dimension variance vj = Var[Zj ].
Active units are coordinates with vj > 10−3 , summarising effective dimensionality and dead units.
We plot variance histograms.
Inter-dimension independence (HSIC). We estimate pairwise dependence via a biased Hilbert–Schmidt
Independence Criterion (HSIC). Concretely: q
(i) z-score each coordinate independently; (ii) build

1
2
2 median{(zi − zk ) | i ̸= k} (median over non-zero
squared distances); (iii) centre with H = I − n1 11⊤ and K̃j = HKj H; (iv) define

Gaussian kernels Kj with bandwidth σj =

HSIC(i, j) =

1
⟨K̃i , K̃j ⟩F ,
(n − 1)2

i ̸= j,

setting the diagonal to 0. We report the full HSIC matrix and a global score (mean off-diagonal
HSIC; lower is better), with heatmaps saved per split.
Clusterability. On each split we fit KMeans (k=5, n_init=10, random_state=42) and report:
Silhouette (higher is better), Davies–Bouldin (lower), and Calinski–Harabasz (higher). Metrics are
skipped for degenerate cases (e.g., N ≤ k or single cluster).
27

Explained-variance structure. On Zall = [Ztrain ; Zeval ] we fit PCA and report the cumulative
explained-variance curve and the sum of the top-5 explained variance ratios. The curve is exported
as a figure.

3.4.3

Geometry preservation under 2D embeddings

We assess whether neighbourhoods and global distances in Z are preserved by a fixed 2D PCA
projection. For each split:
• Trustworthiness T ∈ [0, 1]: fractionally penalises intrusions of points that are not among
the k = 10 nearest neighbours in Z but appear as neighbours in 2D; higher is better.
• Continuity C ∈ [0, 1]: penalises exclusions of true high-dimensional neighbours from the
2D neighbourhoods; higher is better.
• Distance correlation: Pearson correlation between vectorised upper-triangular pairwise
distance matrices in Z and in PCA(2) (after excluding the diagonal); higher is better.
We provide PCA(2) scatter plots. Additionally, we render optional t-SNE(2) maps with perplexity
∈ [5, 30] adapted to sample count (subsample to 2,000 if needed), and Shepard plots relating
pairwise distances in Z vs. 2D (subsample to 20,000 pairs for efficiency).

3.4.4

Label-informed information content

When labels are present and non-degenerate, we estimate dimensionwise mutual information
I(Zj ; Y ) using standard estimators:
• Gender and abnormal (binary): mutual_information_classif on {0, 1} targets; we binarize
any {1, 2} encodings.
• Age (continuous): mutual_information_regression.
We report the mean MI across dimensions and retain per-dimension MI vectors. Metrics are
skipped when a label is constant or missing (e.g., age placeholders).

3.4.5

Downstream heads: task sufficiency and generalisation

To quantify task sufficiency independent of feature learning, we fit lightweight MLP heads to latents
with hyperparameters selected by Bayesian optimisation.
Tasks. In the TUH path we evaluate two binary endpoints: (i) abnormal vs. normal; (ii) gender.
The age head is omitted because age labels are placeholders (the pipeline supports MAE/RMSE/R2
when valid labels exist). For consistency with TUH metadata, gender labels {1, 2} are mapped to
{0, 1}.
Model class. A single-task MLP with ReLU blocks and dropout, ending in a scalar output:
Linear+BN+ReLU+Dropout×L

MLP : Rd −−−−−−−−−−−−−−−−−−−−→ R.
Classification uses logits with BCE-with-logits; regression uses MSE. For classification, probabilities
are σ(logit) and the decision threshold is 0.5.
Hyperparameter search (Optuna).

We run seeded TPE-based optimisation over:

• Depth L ∈ {2, 3, 4} with a geometric width schedule (base width ∈ {64, . . . , 512}, halved per
layer, min 16).
• Learning rate [10−5 , 10−3 ] (log-uniform), dropout [0, 0.5], weight decay [10−6 , 10−2 ] (loguniform).
• Scheduler ∈ {Reduce-on-Plateau, Cosine, None}.
Each trial trains up to 100 epochs with early stopping (patience=10; min 5 epochs before selection).
Determinism is enforced (fixed seeds; deterministic cuDNN where applicable). We split the training
latents once into train/validation subsets (random_state=42); the best model per task/minimal
validation loss is re-instantiated from its weights for evaluation.
28

Metrics and plots. On the held-out eval split we report, for classification: accuracy, F1, ROCAUC (if both classes present), PR-AUC, and prediction counts; for regression: MAE, RMSE,
and R2 (when label variance permits). We export confusion matrices, ROC and PR curves for
classification tasks.

3.4.6

Fairness and reproducibility controls

We enforce method-agnostic fairness by:
1. Holding preprocessing, channel order, sampling rate, epoch length, and inclusion masks fixed
across methods.
2. Using a shared Welch grid for all spectral computations; mechanistic forward PSDs and
empirical PSDs are evaluated on identical bins.
3. Normalising spectra consistently (log10 + per-vector z-score) to stabilise scale across subjects.
4. Caching per-method latents in JSONL; counts are validated against dataset size to prevent
stale evaluations.
5. Fixing random seeds for subsampling (t-SNE, Shepard), KMeans, and hyperparameter search.

3.4.7

Outputs and artefacts

For each method we save:
• Numerical: a machine-readable JSON and a human-readable Markdown report containing:
active units; HSIC global score; cluster metrics; geometry (trustworthiness, continuity, distance correlation); PCA variance summaries; and downstream head metrics per task with
chosen hyperparameters.
• Figures: HSIC heatmaps (train/eval), variance histograms (train/eval), PCA(2) scatter
(train/eval), optional t-SNE(2) scatter (train/eval), Shepard plots (train/eval), PCA explainedvariance curve, and per-task plots (confusion matrix; ROC/PR curves when applicable).

3.4.8

Interpretation

The suite separates complementary desiderata: (i) capacity and redundancy (variance, active
units); (ii) statistical independence (HSIC); (iii) unsupervised separability (cluster metrics); (iv)
manifold fidelity under dimensionality reduction (trustworthiness, continuity, distance correlation); (v) label alignment without training (mutual information); and (vi) end-task utility (supervised heads). Reporting all six axes enables like-for-like comparisons across mechanistic latents—including the amortized mechanistic regressor trained on synthetic (θ, SCBM (f ; θ)) pairs—and
data-driven latents, quantifying trade-offs among interpretability, robustness, and task performance.

3.5

Downstream tasks

We quantify the task sufficiency and transfer utility of each latent representation by training
lightweight prediction heads on top of fixed latents. All heads are trained on the training latents
only, with early-stopped hyperparameter search on an internal validation subset, and final reporting
on the held-out evaluation latents. Unless stated, all procedures and random seeds are identical
across methods to ensure like-for-like comparisons.

3.5.1

Tasks and label preparation

We consider two binary endpoints available in our TUH setting:
• Abnormal EEG (binary). Target derived from the TUH-AB protocol (normal vs. abnormal).
• Gender (binary). TUH encodes sex as {1, 2}; we remap to {0, 1}.
29

Age is present as a placeholder in our TUH path and is therefore omitted from supervised evaluation
(the pipeline supports regression metrics when valid labels exist). All labels are carried alongside
latents during extraction but are not used by the extractors themselves.

3.5.2

Model class (single-task MLP heads)

For each task we train an independent feedforward network with a ReLU trunk and a single scalar
head:
Linear+BN+ReLU+Dropout ×L
MLP : Rd −−−−−−−−−−−−−−−−−−−→ R.
Classification uses logits with BCEWithLogitsLoss and a fixed 0.5 threshold at inference; no explicit
class weighting is applied. Regression (when enabled) uses MSELoss. The input dimension d equals
the latent vector size of the method under test; the output is a single logit (classification) or scalar
(regression).

3.5.3

Hyperparameter optimisation (Optuna)

We perform seeded Bayesian optimisation (TPE) per task and method. The search space comprises:
• Depth: L ∈ {2, 3, 4}.
• Width schedule: base width b ∈ {64, 128, . . . , 512}, with geometric decay across layers
(halving per layer, minimum 16 units).
• Optimisation: learning rate ∈ [10−5 , 10−3 ] (log-uniform), dropout ∈ [0, 0.5], weight decay
∈ [10−6 , 10−2 ] (log-uniform).
• Schedulers: cosine annealing with warm restarts, reduce-on-plateau, or none.
Each trial trains up to 100 epochs with early stopping (patience = 10); validation loss is the optimisation objective. The sampler, data shuffling, and library back-ends are seeded for determinism.

3.5.4

Training and validation protocol

Let Dtrain be the set of training latents with labels for a task. We create a fixed global split once
per run: a stratified random partition into train and validation subsets with validation fraction set
in configuration (default 0.2); indices are reused across all trials. Mini-batches are shuffled, and the
best model snapshot is selected by minimal validation loss (a minimum of five epochs is required
before selection). No data from the held-out evaluation latents is used during model selection.

3.5.5

Evaluation on held-out latents

After the search, we re-instantiate the architecture with the best weights and evaluate on the
evaluation latents only. For classification tasks, we report:
• Primary: accuracy and F1 (binary).
• Secondary (when feasible): macro-F1, ROC-AUC, and PR-AUC (computed when both
classes are present and probability variation exists).
For regression (when enabled): MAE, RMSE, and R2 (if label variance permits). We export
diagnostic figures: confusion matrix, ROC curve, and precision–recall curve. Prediction count
summaries (positives/negatives) are logged to monitor threshold effects.

3.5.6

Fairness and reproducibility

To isolate the contribution of the latent representation:
1. The same head class, search space, seeds, and early-stopping policy are applied across all
methods and tasks.
2. A single global train/validation split is fixed for the training latents and reused across all
trials within a method.
30

3. Device selection follows CUDA → MPS → CPU fallback; batch sizes and frequency grids are
kept constant across methods.
4. No task-specific feature engineering or augmentation is applied to latents; they are consumed
exactly as produced by the extractors.

3.5.7

Outputs and artefacts

Per method and task, we save: (i) numerical metrics (JSON) and a human-readable summary
(Markdown); (ii) plots (confusion matrix, ROC, PR); and (iii) the Optuna study object and
selected architectural specification for transparency. Artefacts are written under a per-method
directory, with per-task subfolders.

3.5.8

Rationale and scope

This design measures how much task signal resides in the latents under a controlled, low-capacity
decoder. By fixing the head family and selection protocol, improvements in downstream performance can be attributed to the representation rather than to model capacity or tuning. In
particular, this enables a principled comparison between mechanistic latents (including amortized
CBM parameters) and data-driven latents along a common axis of end-task utility, complementing
the unsupervised diagnostics reported in the previous section.

31

Chapter 4

Results/Analysis
Aim and scope. We evaluate latent representations under a unified protocol that controls preprocessing, inputs, and splits. Our goal is to compare mechanistic whole–brain models (CTM, Jansen–Rit, Wong–Wang, Hopf) and data–driven methods (catch22, PCA over PSD, PSD–AE, EEGNet–AE, EEG2Rep) on common ground, attributing observed differences to the representations rather than to data handling or decoder capacity.

Unsupervised latent structure. We quantify per–dimension variance and active units (capacity and redundancy), pairwise dependence via HSIC (full heatmaps and mean off–diagonal score), clusterability (Silhouette, Davies–Bouldin, Calinski–Harabasz), and geometry preservation under a fixed 2D PCA projection (trustworthiness, continuity, distance correlation). We also report PCA explained–variance curves on the combined latent set.

Label–informed alignment. We estimate mutual information between latent dimensions and endpoints (abnormality, gender) to assess task–relevant signal prior to any supervised modelling.

Downstream task sufficiency. We train seeded, lightweight MLP heads on training latents only and evaluate on held–out latents, reporting accuracy, F1, ROC–AUC, and PR–AUC with confusion matrices and curves. This controlled decoder isolates representational differences from classifier complexity.

Fairness, reproducibility, and artefacts. All spectral computations share the same Welch frequency grid and normalisation; channel canonicalisation, sampling, epoching, masks, seeds, and train/validation splits are fixed across methods. We cache per–method latents and export HSIC heatmaps, variance histograms, PCA(2) scatter plots, optional t–SNE maps, Shepard plots, explained–variance curves, and per–task diagnostics.

Chapter roadmap. Section 4.1 presents per–method results; Section 4.2 compares latent spaces across metrics; Section 4.3 aggregates findings by weight class (small aggregated, small per–channel, medium–scale); Section 4.4 summarises key implications for hybrid mechanistic–data–driven approaches.

4.1

Individual Results

4.2

Latent Space comparison

4.3

Weight Classes

4.4

Summary

32

Chapter 5

Conclusion

33

Appendix A

First Appendix

34

Bibliography
1.

Gramfort A et al. MEG and EEG data analysis with MNE-Python. Frontiers in Neuroscience
2013; Volume 7 - 2013. doi: 10.3389/fnins.2013.00267. Available from: https://www.
frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2013.00267

2.

Tallon-Baudry C, Bertrand O, Delpuech C, and Pernier J. Oscillatory -Band (30–70 Hz) Activity Induced by a Visual Search Task in Humans. Journal of Neuroscience 1997; 17:722–34. doi:
10.1523/JNEUROSCI.17- 02- 00722.1997. eprint: https://www.jneurosci.org/content/
17/2/722.full.pdf. Available from: https://www.jneurosci.org/content/17/2/722

3.

Bruns A. Fourier-, Hilbert- and wavelet-based signal analysis: are they really different approaches? Journal of Neuroscience Methods 2004; 137:321–32. doi: https://doi.org/10.
1016 / j . jneumeth . 2004 . 03 . 002. Available from: https : / / www . sciencedirect . com /
science/article/pii/S0165027004001098

4.

Hansen N and Ostermeier A. Completely Derandomized Self-Adaptation in Evolution Strategies. Evolutionary Computation 2001; 9:159–95. doi: 10.1162/106365601750190398

35

