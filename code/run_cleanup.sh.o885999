Results will be saved to: Results/tuh-ctm_cma_avg
Loading raw EEG data ‚Ä¶
Loading train data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train_epochs.pkl...
Loaded 53622 samples from train split
Loading eval data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval_epochs.pkl...
Loaded 5459 samples from eval split
Loaded 53622 training samples and 5459 evaluation samples from tuh dataset
Extracting latent features ‚Ä¶
Evaluating latent features ‚Ä¶
Training models for each task
üîπ Task 3: hardcoded as classification ‚Üí 'abnormal'
   ‚Üí Optuna search (n_trials=2) for classification ‚Ä¶
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6850, acc = 0.58 | val_loss = 0.6537, val_acc = 0.63
[Task-specific] Epoch 002: loss = 0.6669, acc = 0.61 | val_loss = 0.6464, val_acc = 0.64
[Task-specific] Epoch 003: loss = 0.6601, acc = 0.62 | val_loss = 0.6438, val_acc = 0.64
[Task-specific] Epoch 004: loss = 0.6561, acc = 0.62 | val_loss = 0.6422, val_acc = 0.64
[Task-specific] Epoch 005: loss = 0.6523, acc = 0.63 | val_loss = 0.6410, val_acc = 0.64
[Task-specific] Epoch 006: loss = 0.6507, acc = 0.63 | val_loss = 0.6406, val_acc = 0.64
[Task-specific] Epoch 007: loss = 0.6499, acc = 0.63 | val_loss = 0.6397, val_acc = 0.64
[Task-specific] Epoch 008: loss = 0.6502, acc = 0.63 | val_loss = 0.6386, val_acc = 0.64
[Task-specific] Epoch 009: loss = 0.6466, acc = 0.63 | val_loss = 0.6391, val_acc = 0.64
[Task-specific] Epoch 010: loss = 0.6461, acc = 0.64 | val_loss = 0.6393, val_acc = 0.64
[Task-specific] Epoch 011: loss = 0.6447, acc = 0.64 | val_loss = 0.6385, val_acc = 0.64
[Task-specific] Epoch 012: loss = 0.6421, acc = 0.64 | val_loss = 0.6383, val_acc = 0.64
[Task-specific] Epoch 013: loss = 0.6423, acc = 0.64 | val_loss = 0.6370, val_acc = 0.64
[Task-specific] Epoch 014: loss = 0.6418, acc = 0.64 | val_loss = 0.6372, val_acc = 0.64
[Task-specific] Epoch 015: loss = 0.6412, acc = 0.64 | val_loss = 0.6370, val_acc = 0.64
[Task-specific] Epoch 016: loss = 0.6395, acc = 0.64 | val_loss = 0.6365, val_acc = 0.64
[Task-specific] Epoch 017: loss = 0.6409, acc = 0.64 | val_loss = 0.6364, val_acc = 0.64
[Task-specific] Epoch 018: loss = 0.6385, acc = 0.64 | val_loss = 0.6373, val_acc = 0.64
[Task-specific] Epoch 019: loss = 0.6382, acc = 0.64 | val_loss = 0.6366, val_acc = 0.64
[Task-specific] Epoch 020: loss = 0.6387, acc = 0.64 | val_loss = 0.6355, val_acc = 0.64
[Task-specific] Epoch 021: loss = 0.6371, acc = 0.65 | val_loss = 0.6350, val_acc = 0.64
[Task-specific] Epoch 022: loss = 0.6364, acc = 0.65 | val_loss = 0.6352, val_acc = 0.64
[Task-specific] Epoch 023: loss = 0.6372, acc = 0.64 | val_loss = 0.6348, val_acc = 0.64
[Task-specific] Epoch 024: loss = 0.6355, acc = 0.64 | val_loss = 0.6342, val_acc = 0.64
[Task-specific] Epoch 025: loss = 0.6357, acc = 0.64 | val_loss = 0.6348, val_acc = 0.64
[Task-specific] Epoch 026: loss = 0.6345, acc = 0.65 | val_loss = 0.6344, val_acc = 0.64
[Task-specific] Epoch 027: loss = 0.6362, acc = 0.65 | val_loss = 0.6337, val_acc = 0.64
[Task-specific] Epoch 028: loss = 0.6348, acc = 0.65 | val_loss = 0.6337, val_acc = 0.64
[Task-specific] Epoch 029: loss = 0.6326, acc = 0.65 | val_loss = 0.6336, val_acc = 0.64
[Task-specific] Epoch 030: loss = 0.6326, acc = 0.65 | val_loss = 0.6342, val_acc = 0.64
[Task-specific] Epoch 031: loss = 0.6319, acc = 0.65 | val_loss = 0.6342, val_acc = 0.64
[Task-specific] Epoch 032: loss = 0.6336, acc = 0.65 | val_loss = 0.6336, val_acc = 0.64
[Task-specific] Epoch 033: loss = 0.6319, acc = 0.65 | val_loss = 0.6330, val_acc = 0.64
[Task-specific] Epoch 034: loss = 0.6320, acc = 0.65 | val_loss = 0.6321, val_acc = 0.64
[Task-specific] Epoch 035: loss = 0.6310, acc = 0.65 | val_loss = 0.6331, val_acc = 0.64
[Task-specific] Epoch 036: loss = 0.6319, acc = 0.65 | val_loss = 0.6325, val_acc = 0.65
[Task-specific] Epoch 037: loss = 0.6314, acc = 0.65 | val_loss = 0.6321, val_acc = 0.65
[Task-specific] Epoch 038: loss = 0.6320, acc = 0.65 | val_loss = 0.6323, val_acc = 0.65
[Task-specific] Epoch 039: loss = 0.6294, acc = 0.65 | val_loss = 0.6315, val_acc = 0.65
[Task-specific] Epoch 040: loss = 0.6299, acc = 0.65 | val_loss = 0.6316, val_acc = 0.65
[Task-specific] Epoch 041: loss = 0.6290, acc = 0.65 | val_loss = 0.6317, val_acc = 0.64
[Task-specific] Epoch 042: loss = 0.6288, acc = 0.66 | val_loss = 0.6308, val_acc = 0.65
[Task-specific] Epoch 043: loss = 0.6298, acc = 0.65 | val_loss = 0.6310, val_acc = 0.65
[Task-specific] Epoch 044: loss = 0.6292, acc = 0.65 | val_loss = 0.6306, val_acc = 0.65
[Task-specific] Epoch 045: loss = 0.6295, acc = 0.65 | val_loss = 0.6308, val_acc = 0.65
[Task-specific] Epoch 046: loss = 0.6284, acc = 0.65 | val_loss = 0.6312, val_acc = 0.65
[Task-specific] Epoch 047: loss = 0.6279, acc = 0.65 | val_loss = 0.6309, val_acc = 0.65
[Task-specific] Epoch 048: loss = 0.6279, acc = 0.66 | val_loss = 0.6305, val_acc = 0.65
[Task-specific] Epoch 049: loss = 0.6268, acc = 0.65 | val_loss = 0.6300, val_acc = 0.65
[Task-specific] Epoch 050: loss = 0.6278, acc = 0.65 | val_loss = 0.6304, val_acc = 0.65
[Task-specific] Epoch 051: loss = 0.6276, acc = 0.66 | val_loss = 0.6296, val_acc = 0.65
[Task-specific] Epoch 052: loss = 0.6275, acc = 0.65 | val_loss = 0.6295, val_acc = 0.65
[Task-specific] Epoch 053: loss = 0.6270, acc = 0.66 | val_loss = 0.6296, val_acc = 0.65
[Task-specific] Epoch 054: loss = 0.6266, acc = 0.66 | val_loss = 0.6296, val_acc = 0.65
[Task-specific] Epoch 055: loss = 0.6267, acc = 0.65 | val_loss = 0.6298, val_acc = 0.65
[Task-specific] Epoch 056: loss = 0.6259, acc = 0.66 | val_loss = 0.6302, val_acc = 0.65
[Task-specific] Epoch 057: loss = 0.6264, acc = 0.65 | val_loss = 0.6296, val_acc = 0.65
[Task-specific] Epoch 058: loss = 0.6263, acc = 0.66 | val_loss = 0.6301, val_acc = 0.65
[Task-specific] Epoch 059: loss = 0.6260, acc = 0.66 | val_loss = 0.6293, val_acc = 0.65
[Task-specific] Epoch 060: loss = 0.6249, acc = 0.66 | val_loss = 0.6290, val_acc = 0.65
[Task-specific] Epoch 061: loss = 0.6257, acc = 0.66 | val_loss = 0.6286, val_acc = 0.65
[Task-specific] Epoch 062: loss = 0.6253, acc = 0.66 | val_loss = 0.6282, val_acc = 0.65
[Task-specific] Epoch 063: loss = 0.6248, acc = 0.66 | val_loss = 0.6299, val_acc = 0.65
[Task-specific] Epoch 064: loss = 0.6245, acc = 0.66 | val_loss = 0.6291, val_acc = 0.65
[Task-specific] Epoch 065: loss = 0.6247, acc = 0.66 | val_loss = 0.6287, val_acc = 0.65
[Task-specific] Epoch 066: loss = 0.6240, acc = 0.66 | val_loss = 0.6283, val_acc = 0.65
[Task-specific] Epoch 067: loss = 0.6251, acc = 0.66 | val_loss = 0.6282, val_acc = 0.65
[Task-specific] Epoch 068: loss = 0.6248, acc = 0.66 | val_loss = 0.6280, val_acc = 0.65
[Task-specific] Epoch 069: loss = 0.6238, acc = 0.66 | val_loss = 0.6279, val_acc = 0.65
[Task-specific] Epoch 070: loss = 0.6233, acc = 0.66 | val_loss = 0.6278, val_acc = 0.65
[Task-specific] Epoch 071: loss = 0.6241, acc = 0.66 | val_loss = 0.6275, val_acc = 0.65
[Task-specific] Epoch 072: loss = 0.6241, acc = 0.66 | val_loss = 0.6273, val_acc = 0.65
[Task-specific] Epoch 073: loss = 0.6238, acc = 0.66 | val_loss = 0.6280, val_acc = 0.65
[Task-specific] Epoch 074: loss = 0.6238, acc = 0.66 | val_loss = 0.6271, val_acc = 0.65
[Task-specific] Epoch 075: loss = 0.6234, acc = 0.66 | val_loss = 0.6274, val_acc = 0.65
[Task-specific] Epoch 076: loss = 0.6238, acc = 0.66 | val_loss = 0.6272, val_acc = 0.65
[Task-specific] Epoch 077: loss = 0.6239, acc = 0.66 | val_loss = 0.6278, val_acc = 0.65
[Task-specific] Epoch 078: loss = 0.6226, acc = 0.66 | val_loss = 0.6281, val_acc = 0.65
[Task-specific] Epoch 079: loss = 0.6219, acc = 0.66 | val_loss = 0.6267, val_acc = 0.65
[Task-specific] Epoch 080: loss = 0.6228, acc = 0.66 | val_loss = 0.6271, val_acc = 0.65
[Task-specific] Epoch 081: loss = 0.6229, acc = 0.66 | val_loss = 0.6266, val_acc = 0.65
[Task-specific] Epoch 082: loss = 0.6217, acc = 0.66 | val_loss = 0.6266, val_acc = 0.65
[Task-specific] Epoch 083: loss = 0.6220, acc = 0.66 | val_loss = 0.6267, val_acc = 0.65
[Task-specific] Epoch 084: loss = 0.6215, acc = 0.66 | val_loss = 0.6268, val_acc = 0.65
[Task-specific] Epoch 085: loss = 0.6225, acc = 0.66 | val_loss = 0.6271, val_acc = 0.65
[Task-specific] Epoch 086: loss = 0.6214, acc = 0.66 | val_loss = 0.6268, val_acc = 0.65
[Task-specific] Epoch 087: loss = 0.6224, acc = 0.66 | val_loss = 0.6268, val_acc = 0.65
[Task-specific] Epoch 088: loss = 0.6214, acc = 0.66 | val_loss = 0.6285, val_acc = 0.65
[Task-specific] Epoch 089: loss = 0.6216, acc = 0.66 | val_loss = 0.6262, val_acc = 0.65
[Task-specific] Epoch 090: loss = 0.6215, acc = 0.66 | val_loss = 0.6270, val_acc = 0.65
[Task-specific] Epoch 091: loss = 0.6216, acc = 0.66 | val_loss = 0.6259, val_acc = 0.65
[Task-specific] Epoch 092: loss = 0.6216, acc = 0.66 | val_loss = 0.6272, val_acc = 0.65
[Task-specific] Epoch 093: loss = 0.6208, acc = 0.66 | val_loss = 0.6260, val_acc = 0.65
[Task-specific] Epoch 094: loss = 0.6220, acc = 0.66 | val_loss = 0.6270, val_acc = 0.65
[Task-specific] Epoch 095: loss = 0.6220, acc = 0.66 | val_loss = 0.6266, val_acc = 0.65
[Task-specific] Epoch 096: loss = 0.6207, acc = 0.66 | val_loss = 0.6261, val_acc = 0.65
[Task-specific] Epoch 097: loss = 0.6206, acc = 0.66 | val_loss = 0.6256, val_acc = 0.65
[Task-specific] Epoch 098: loss = 0.6215, acc = 0.66 | val_loss = 0.6259, val_acc = 0.65
[Task-specific] Epoch 099: loss = 0.6208, acc = 0.66 | val_loss = 0.6258, val_acc = 0.65
[Task-specific] Epoch 100: loss = 0.6198, acc = 0.66 | val_loss = 0.6263, val_acc = 0.65
[Trial 0] Params: lr=0.00006, dropout=0.48, weight_decay=0.000847, scheduler=plateau, hidden_dims=(448, 224)
üèÖ New global best found (val_loss=0.6256) ‚Äì tracked in memory (no files written)
[I 2025-08-27 01:46:09,952] Trial 0 finished with value: 0.6255994583764876 and parameters: {'lr': 5.6115164153345e-05, 'dropout': 0.4753571532049581, 'weight_decay': 0.0008471801418819979, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 448}. Best is trial 0 with value: 0.6255994583764876.
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6916, acc = 0.56 | val_loss = 0.6576, val_acc = 0.62
[Task-specific] Epoch 002: loss = 0.6668, acc = 0.61 | val_loss = 0.6501, val_acc = 0.63
[Task-specific] Epoch 003: loss = 0.6615, acc = 0.62 | val_loss = 0.6461, val_acc = 0.63
[Task-specific] Epoch 004: loss = 0.6553, acc = 0.62 | val_loss = 0.6440, val_acc = 0.64
[Task-specific] Epoch 005: loss = 0.6540, acc = 0.63 | val_loss = 0.6431, val_acc = 0.64
[Task-specific] Epoch 006: loss = 0.6505, acc = 0.63 | val_loss = 0.6411, val_acc = 0.64
[Task-specific] Epoch 007: loss = 0.6483, acc = 0.63 | val_loss = 0.6403, val_acc = 0.64
[Task-specific] Epoch 008: loss = 0.6475, acc = 0.63 | val_loss = 0.6398, val_acc = 0.64
[Task-specific] Epoch 009: loss = 0.6457, acc = 0.63 | val_loss = 0.6385, val_acc = 0.64
[Task-specific] Epoch 010: loss = 0.6456, acc = 0.63 | val_loss = 0.6379, val_acc = 0.64
[Task-specific] Epoch 011: loss = 0.6427, acc = 0.64 | val_loss = 0.6376, val_acc = 0.64
[Task-specific] Epoch 012: loss = 0.6438, acc = 0.64 | val_loss = 0.6371, val_acc = 0.64
[Task-specific] Epoch 013: loss = 0.6429, acc = 0.64 | val_loss = 0.6366, val_acc = 0.64
[Task-specific] Epoch 014: loss = 0.6401, acc = 0.64 | val_loss = 0.6359, val_acc = 0.64
[Task-specific] Epoch 015: loss = 0.6396, acc = 0.64 | val_loss = 0.6354, val_acc = 0.64
[Task-specific] Epoch 016: loss = 0.6391, acc = 0.64 | val_loss = 0.6353, val_acc = 0.64
[Task-specific] Epoch 017: loss = 0.6380, acc = 0.64 | val_loss = 0.6359, val_acc = 0.64
[Task-specific] Epoch 018: loss = 0.6386, acc = 0.64 | val_loss = 0.6349, val_acc = 0.64
[Task-specific] Epoch 019: loss = 0.6378, acc = 0.64 | val_loss = 0.6349, val_acc = 0.64
[Task-specific] Epoch 020: loss = 0.6382, acc = 0.64 | val_loss = 0.6349, val_acc = 0.65
[Task-specific] Epoch 021: loss = 0.6359, acc = 0.64 | val_loss = 0.6334, val_acc = 0.64
[Task-specific] Epoch 022: loss = 0.6358, acc = 0.65 | val_loss = 0.6332, val_acc = 0.65
[Task-specific] Epoch 023: loss = 0.6351, acc = 0.65 | val_loss = 0.6337, val_acc = 0.65
[Task-specific] Epoch 024: loss = 0.6354, acc = 0.64 | val_loss = 0.6331, val_acc = 0.65
[Task-specific] Epoch 025: loss = 0.6359, acc = 0.65 | val_loss = 0.6327, val_acc = 0.64
[Task-specific] Epoch 026: loss = 0.6340, acc = 0.64 | val_loss = 0.6323, val_acc = 0.65
[Task-specific] Epoch 027: loss = 0.6338, acc = 0.65 | val_loss = 0.6323, val_acc = 0.65
[Task-specific] Epoch 028: loss = 0.6336, acc = 0.65 | val_loss = 0.6325, val_acc = 0.65
[Task-specific] Epoch 029: loss = 0.6323, acc = 0.65 | val_loss = 0.6315, val_acc = 0.65
[Task-specific] Epoch 030: loss = 0.6320, acc = 0.65 | val_loss = 0.6316, val_acc = 0.65
[Task-specific] Epoch 031: loss = 0.6317, acc = 0.65 | val_loss = 0.6312, val_acc = 0.65
[Task-specific] Epoch 032: loss = 0.6319, acc = 0.65 | val_loss = 0.6306, val_acc = 0.65
[Task-specific] Epoch 033: loss = 0.6315, acc = 0.65 | val_loss = 0.6313, val_acc = 0.65
[Task-specific] Epoch 034: loss = 0.6312, acc = 0.65 | val_loss = 0.6304, val_acc = 0.65
[Task-specific] Epoch 035: loss = 0.6311, acc = 0.65 | val_loss = 0.6303, val_acc = 0.65
[Task-specific] Epoch 036: loss = 0.6296, acc = 0.65 | val_loss = 0.6308, val_acc = 0.65
[Task-specific] Epoch 037: loss = 0.6299, acc = 0.65 | val_loss = 0.6303, val_acc = 0.65
[Task-specific] Epoch 038: loss = 0.6297, acc = 0.65 | val_loss = 0.6300, val_acc = 0.65
[Task-specific] Epoch 039: loss = 0.6297, acc = 0.65 | val_loss = 0.6296, val_acc = 0.65
[Task-specific] Epoch 040: loss = 0.6284, acc = 0.65 | val_loss = 0.6297, val_acc = 0.65
[Task-specific] Epoch 041: loss = 0.6294, acc = 0.65 | val_loss = 0.6294, val_acc = 0.65
[Task-specific] Epoch 042: loss = 0.6296, acc = 0.65 | val_loss = 0.6294, val_acc = 0.65
[Task-specific] Epoch 043: loss = 0.6287, acc = 0.65 | val_loss = 0.6293, val_acc = 0.65
[Task-specific] Epoch 044: loss = 0.6284, acc = 0.65 | val_loss = 0.6296, val_acc = 0.65
[Task-specific] Epoch 045: loss = 0.6284, acc = 0.65 | val_loss = 0.6294, val_acc = 0.65
[Task-specific] Epoch 046: loss = 0.6274, acc = 0.65 | val_loss = 0.6283, val_acc = 0.65
[Task-specific] Epoch 047: loss = 0.6278, acc = 0.65 | val_loss = 0.6289, val_acc = 0.65
[Task-specific] Epoch 048: loss = 0.6276, acc = 0.65 | val_loss = 0.6282, val_acc = 0.65
[Task-specific] Epoch 049: loss = 0.6280, acc = 0.65 | val_loss = 0.6288, val_acc = 0.65
[Task-specific] Epoch 050: loss = 0.6258, acc = 0.66 | val_loss = 0.6277, val_acc = 0.65
[Task-specific] Epoch 051: loss = 0.6263, acc = 0.66 | val_loss = 0.6283, val_acc = 0.65
[Task-specific] Epoch 052: loss = 0.6271, acc = 0.65 | val_loss = 0.6276, val_acc = 0.65
[Task-specific] Epoch 053: loss = 0.6270, acc = 0.66 | val_loss = 0.6273, val_acc = 0.65
[Task-specific] Epoch 054: loss = 0.6264, acc = 0.65 | val_loss = 0.6275, val_acc = 0.65
[Task-specific] Epoch 055: loss = 0.6266, acc = 0.65 | val_loss = 0.6275, val_acc = 0.65
[Task-specific] Epoch 056: loss = 0.6269, acc = 0.65 | val_loss = 0.6291, val_acc = 0.65
[Task-specific] Epoch 057: loss = 0.6261, acc = 0.66 | val_loss = 0.6272, val_acc = 0.65
[Task-specific] Epoch 058: loss = 0.6254, acc = 0.66 | val_loss = 0.6278, val_acc = 0.65
[Task-specific] Epoch 059: loss = 0.6257, acc = 0.66 | val_loss = 0.6267, val_acc = 0.65
[Task-specific] Epoch 060: loss = 0.6255, acc = 0.66 | val_loss = 0.6270, val_acc = 0.65
[Task-specific] Epoch 061: loss = 0.6242, acc = 0.66 | val_loss = 0.6270, val_acc = 0.65
[Task-specific] Epoch 062: loss = 0.6251, acc = 0.66 | val_loss = 0.6271, val_acc = 0.65
[Task-specific] Epoch 063: loss = 0.6249, acc = 0.66 | val_loss = 0.6290, val_acc = 0.65
[Task-specific] Epoch 064: loss = 0.6246, acc = 0.66 | val_loss = 0.6270, val_acc = 0.65
[Task-specific] Epoch 065: loss = 0.6248, acc = 0.66 | val_loss = 0.6263, val_acc = 0.65
[Task-specific] Epoch 066: loss = 0.6239, acc = 0.66 | val_loss = 0.6271, val_acc = 0.65
[Task-specific] Epoch 067: loss = 0.6249, acc = 0.66 | val_loss = 0.6264, val_acc = 0.65
[Task-specific] Epoch 068: loss = 0.6248, acc = 0.66 | val_loss = 0.6261, val_acc = 0.65
[Task-specific] Epoch 069: loss = 0.6229, acc = 0.66 | val_loss = 0.6259, val_acc = 0.65
[Task-specific] Epoch 070: loss = 0.6244, acc = 0.66 | val_loss = 0.6264, val_acc = 0.65
[Task-specific] Epoch 071: loss = 0.6238, acc = 0.66 | val_loss = 0.6262, val_acc = 0.65
[Task-specific] Epoch 072: loss = 0.6236, acc = 0.66 | val_loss = 0.6266, val_acc = 0.65
[Task-specific] Epoch 073: loss = 0.6234, acc = 0.66 | val_loss = 0.6261, val_acc = 0.65
[Task-specific] Epoch 074: loss = 0.6230, acc = 0.66 | val_loss = 0.6263, val_acc = 0.65
[Task-specific] Epoch 075: loss = 0.6229, acc = 0.66 | val_loss = 0.6255, val_acc = 0.65
[Task-specific] Epoch 076: loss = 0.6226, acc = 0.66 | val_loss = 0.6257, val_acc = 0.65
[Task-specific] Epoch 077: loss = 0.6230, acc = 0.66 | val_loss = 0.6257, val_acc = 0.65
[Task-specific] Epoch 078: loss = 0.6226, acc = 0.66 | val_loss = 0.6258, val_acc = 0.65
[Task-specific] Epoch 079: loss = 0.6234, acc = 0.66 | val_loss = 0.6258, val_acc = 0.65
[Task-specific] Epoch 080: loss = 0.6234, acc = 0.66 | val_loss = 0.6255, val_acc = 0.65
[Task-specific] Epoch 081: loss = 0.6235, acc = 0.66 | val_loss = 0.6262, val_acc = 0.65
[Task-specific] Epoch 082: loss = 0.6232, acc = 0.66 | val_loss = 0.6264, val_acc = 0.65
[Task-specific] Epoch 083: loss = 0.6215, acc = 0.66 | val_loss = 0.6254, val_acc = 0.65
[Task-specific] Epoch 084: loss = 0.6216, acc = 0.66 | val_loss = 0.6255, val_acc = 0.65
[Task-specific] Epoch 085: loss = 0.6223, acc = 0.66 | val_loss = 0.6253, val_acc = 0.65
[Task-specific] Epoch 086: loss = 0.6217, acc = 0.66 | val_loss = 0.6246, val_acc = 0.65
[Task-specific] Epoch 087: loss = 0.6212, acc = 0.66 | val_loss = 0.6251, val_acc = 0.65
[Task-specific] Epoch 088: loss = 0.6218, acc = 0.66 | val_loss = 0.6253, val_acc = 0.65
[Task-specific] Epoch 089: loss = 0.6207, acc = 0.66 | val_loss = 0.6249, val_acc = 0.65
[Task-specific] Epoch 090: loss = 0.6221, acc = 0.66 | val_loss = 0.6244, val_acc = 0.65
[Task-specific] Epoch 091: loss = 0.6210, acc = 0.66 | val_loss = 0.6251, val_acc = 0.65
[Task-specific] Epoch 092: loss = 0.6223, acc = 0.66 | val_loss = 0.6246, val_acc = 0.65
[Task-specific] Epoch 093: loss = 0.6212, acc = 0.66 | val_loss = 0.6244, val_acc = 0.65
[Task-specific] Epoch 094: loss = 0.6209, acc = 0.66 | val_loss = 0.6250, val_acc = 0.65
[Task-specific] Epoch 095: loss = 0.6213, acc = 0.66 | val_loss = 0.6244, val_acc = 0.65
[Task-specific] Epoch 096: loss = 0.6210, acc = 0.66 | val_loss = 0.6242, val_acc = 0.65
[Task-specific] Epoch 097: loss = 0.6199, acc = 0.66 | val_loss = 0.6245, val_acc = 0.65
[Task-specific] Epoch 098: loss = 0.6210, acc = 0.66 | val_loss = 0.6240, val_acc = 0.65
[Task-specific] Epoch 099: loss = 0.6200, acc = 0.66 | val_loss = 0.6242, val_acc = 0.65
[Task-specific] Epoch 100: loss = 0.6202, acc = 0.66 | val_loss = 0.6254, val_acc = 0.65
[Trial 1] Params: lr=0.00016, dropout=0.35, weight_decay=0.000001, scheduler=plateau, hidden_dims=(128, 64)
üèÖ New global best found (val_loss=0.6240) ‚Äì tracked in memory (no files written)
[I 2025-08-27 01:48:20,420] Trial 1 finished with value: 0.624007853241716 and parameters: {'lr': 0.00015930522616241006, 'dropout': 0.35403628889802274, 'weight_decay': 1.2087541473056965e-06, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 128}. Best is trial 1 with value: 0.624007853241716.
‚úÖ Optuna search finished ‚Äì best val_loss=0.6240. Best model kept in memory.
üîç Prediction counts: {'label_0': 2743, 'label_1': 2716}
Saving results ‚Ä¶
‚úÖ Pipeline completed successfully to the path Results/tuh-ctm_cma_avg!
Results will be saved to: Results/tuh-c22
Loading raw EEG data ‚Ä¶
Loading train data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train_epochs.pkl...
Loaded 53622 samples from train split
Loading eval data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval_epochs.pkl...
Loaded 5459 samples from eval split
Loaded 53622 training samples and 5459 evaluation samples from tuh dataset
Extracting latent features ‚Ä¶
Evaluating latent features ‚Ä¶
Training models for each task
üîπ Task 3: hardcoded as classification ‚Üí 'abnormal'
   ‚Üí Optuna search (n_trials=2) for classification ‚Ä¶
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.5780, acc = 0.68 | val_loss = 0.5319, val_acc = 0.73
[Task-specific] Epoch 002: loss = 0.5310, acc = 0.73 | val_loss = 0.5125, val_acc = 0.74
[Task-specific] Epoch 003: loss = 0.5152, acc = 0.75 | val_loss = 0.4986, val_acc = 0.75
[Task-specific] Epoch 004: loss = 0.5041, acc = 0.75 | val_loss = 0.4884, val_acc = 0.76
[Task-specific] Epoch 005: loss = 0.4943, acc = 0.76 | val_loss = 0.4808, val_acc = 0.77
[Task-specific] Epoch 006: loss = 0.4843, acc = 0.77 | val_loss = 0.4758, val_acc = 0.77
[Task-specific] Epoch 007: loss = 0.4773, acc = 0.77 | val_loss = 0.4687, val_acc = 0.78
[Task-specific] Epoch 008: loss = 0.4728, acc = 0.77 | val_loss = 0.4645, val_acc = 0.78
[Task-specific] Epoch 009: loss = 0.4681, acc = 0.78 | val_loss = 0.4604, val_acc = 0.79
[Task-specific] Epoch 010: loss = 0.4628, acc = 0.78 | val_loss = 0.4569, val_acc = 0.79
[Task-specific] Epoch 011: loss = 0.4598, acc = 0.78 | val_loss = 0.4545, val_acc = 0.79
[Task-specific] Epoch 012: loss = 0.4533, acc = 0.79 | val_loss = 0.4498, val_acc = 0.79
[Task-specific] Epoch 013: loss = 0.4526, acc = 0.79 | val_loss = 0.4482, val_acc = 0.79
[Task-specific] Epoch 014: loss = 0.4477, acc = 0.79 | val_loss = 0.4451, val_acc = 0.80
[Task-specific] Epoch 015: loss = 0.4449, acc = 0.79 | val_loss = 0.4434, val_acc = 0.80
[Task-specific] Epoch 016: loss = 0.4406, acc = 0.80 | val_loss = 0.4412, val_acc = 0.80
[Task-specific] Epoch 017: loss = 0.4388, acc = 0.80 | val_loss = 0.4397, val_acc = 0.80
[Task-specific] Epoch 018: loss = 0.4370, acc = 0.80 | val_loss = 0.4375, val_acc = 0.80
[Task-specific] Epoch 019: loss = 0.4336, acc = 0.80 | val_loss = 0.4363, val_acc = 0.80
[Task-specific] Epoch 020: loss = 0.4311, acc = 0.80 | val_loss = 0.4343, val_acc = 0.80
[Task-specific] Epoch 021: loss = 0.4283, acc = 0.80 | val_loss = 0.4321, val_acc = 0.80
[Task-specific] Epoch 022: loss = 0.4250, acc = 0.80 | val_loss = 0.4306, val_acc = 0.80
[Task-specific] Epoch 023: loss = 0.4229, acc = 0.81 | val_loss = 0.4298, val_acc = 0.80
[Task-specific] Epoch 024: loss = 0.4204, acc = 0.81 | val_loss = 0.4282, val_acc = 0.80
[Task-specific] Epoch 025: loss = 0.4207, acc = 0.81 | val_loss = 0.4277, val_acc = 0.81
[Task-specific] Epoch 026: loss = 0.4174, acc = 0.81 | val_loss = 0.4248, val_acc = 0.81
[Task-specific] Epoch 027: loss = 0.4156, acc = 0.81 | val_loss = 0.4234, val_acc = 0.81
[Task-specific] Epoch 028: loss = 0.4133, acc = 0.81 | val_loss = 0.4217, val_acc = 0.81
[Task-specific] Epoch 029: loss = 0.4089, acc = 0.81 | val_loss = 0.4202, val_acc = 0.81
[Task-specific] Epoch 030: loss = 0.4094, acc = 0.81 | val_loss = 0.4190, val_acc = 0.81
[Task-specific] Epoch 031: loss = 0.4059, acc = 0.82 | val_loss = 0.4193, val_acc = 0.81
[Task-specific] Epoch 032: loss = 0.4031, acc = 0.82 | val_loss = 0.4172, val_acc = 0.81
[Task-specific] Epoch 033: loss = 0.4029, acc = 0.82 | val_loss = 0.4169, val_acc = 0.81
[Task-specific] Epoch 034: loss = 0.3994, acc = 0.82 | val_loss = 0.4154, val_acc = 0.81
[Task-specific] Epoch 035: loss = 0.3976, acc = 0.82 | val_loss = 0.4152, val_acc = 0.81
[Task-specific] Epoch 036: loss = 0.3965, acc = 0.82 | val_loss = 0.4254, val_acc = 0.81
[Task-specific] Epoch 037: loss = 0.3949, acc = 0.82 | val_loss = 0.4118, val_acc = 0.81
[Task-specific] Epoch 038: loss = 0.3910, acc = 0.82 | val_loss = 0.4104, val_acc = 0.82
[Task-specific] Epoch 039: loss = 0.3881, acc = 0.82 | val_loss = 0.4098, val_acc = 0.82
[Task-specific] Epoch 040: loss = 0.3902, acc = 0.82 | val_loss = 0.4097, val_acc = 0.82
[Task-specific] Epoch 041: loss = 0.3876, acc = 0.82 | val_loss = 0.4079, val_acc = 0.82
[Task-specific] Epoch 042: loss = 0.3853, acc = 0.83 | val_loss = 0.4094, val_acc = 0.82
[Task-specific] Epoch 043: loss = 0.3855, acc = 0.83 | val_loss = 0.4097, val_acc = 0.82
[Task-specific] Epoch 044: loss = 0.3848, acc = 0.83 | val_loss = 0.4060, val_acc = 0.82
[Task-specific] Epoch 045: loss = 0.3798, acc = 0.83 | val_loss = 0.4042, val_acc = 0.82
[Task-specific] Epoch 046: loss = 0.3813, acc = 0.83 | val_loss = 0.4034, val_acc = 0.82
[Task-specific] Epoch 047: loss = 0.3771, acc = 0.83 | val_loss = 0.4049, val_acc = 0.82
[Task-specific] Epoch 048: loss = 0.3737, acc = 0.83 | val_loss = 0.4012, val_acc = 0.82
[Task-specific] Epoch 049: loss = 0.3726, acc = 0.83 | val_loss = 0.4009, val_acc = 0.82
[Task-specific] Epoch 050: loss = 0.3711, acc = 0.83 | val_loss = 0.3994, val_acc = 0.82
[Task-specific] Epoch 051: loss = 0.3711, acc = 0.83 | val_loss = 0.4005, val_acc = 0.82
[Task-specific] Epoch 052: loss = 0.3696, acc = 0.84 | val_loss = 0.3992, val_acc = 0.82
[Task-specific] Epoch 053: loss = 0.3652, acc = 0.83 | val_loss = 0.3976, val_acc = 0.82
[Task-specific] Epoch 054: loss = 0.3658, acc = 0.84 | val_loss = 0.3965, val_acc = 0.82
[Task-specific] Epoch 055: loss = 0.3645, acc = 0.84 | val_loss = 0.3975, val_acc = 0.82
[Task-specific] Epoch 056: loss = 0.3616, acc = 0.84 | val_loss = 0.4017, val_acc = 0.82
[Task-specific] Epoch 057: loss = 0.3588, acc = 0.84 | val_loss = 0.3958, val_acc = 0.82
[Task-specific] Epoch 058: loss = 0.3596, acc = 0.84 | val_loss = 0.3956, val_acc = 0.82
[Task-specific] Epoch 059: loss = 0.3572, acc = 0.84 | val_loss = 0.3975, val_acc = 0.82
[Task-specific] Epoch 060: loss = 0.3579, acc = 0.84 | val_loss = 0.3938, val_acc = 0.82
[Task-specific] Epoch 061: loss = 0.3554, acc = 0.84 | val_loss = 0.3945, val_acc = 0.82
[Task-specific] Epoch 062: loss = 0.3504, acc = 0.84 | val_loss = 0.3925, val_acc = 0.82
[Task-specific] Epoch 063: loss = 0.3480, acc = 0.85 | val_loss = 0.3947, val_acc = 0.82
[Task-specific] Epoch 064: loss = 0.3476, acc = 0.85 | val_loss = 0.3934, val_acc = 0.82
[Task-specific] Epoch 065: loss = 0.3469, acc = 0.85 | val_loss = 0.3913, val_acc = 0.82
[Task-specific] Epoch 066: loss = 0.3450, acc = 0.85 | val_loss = 0.3909, val_acc = 0.82
[Task-specific] Epoch 067: loss = 0.3446, acc = 0.85 | val_loss = 0.3901, val_acc = 0.83
[Task-specific] Epoch 068: loss = 0.3440, acc = 0.85 | val_loss = 0.3924, val_acc = 0.82
[Task-specific] Epoch 069: loss = 0.3435, acc = 0.85 | val_loss = 0.3892, val_acc = 0.82
[Task-specific] Epoch 070: loss = 0.3416, acc = 0.85 | val_loss = 0.3880, val_acc = 0.83
[Task-specific] Epoch 071: loss = 0.3379, acc = 0.85 | val_loss = 0.3887, val_acc = 0.82
[Task-specific] Epoch 072: loss = 0.3341, acc = 0.85 | val_loss = 0.3893, val_acc = 0.82
[Task-specific] Epoch 073: loss = 0.3330, acc = 0.85 | val_loss = 0.3885, val_acc = 0.83
[Task-specific] Epoch 074: loss = 0.3309, acc = 0.85 | val_loss = 0.3936, val_acc = 0.82
[Task-specific] Epoch 075: loss = 0.3333, acc = 0.85 | val_loss = 0.3892, val_acc = 0.83
[Task-specific] Epoch 076: loss = 0.3291, acc = 0.86 | val_loss = 0.3881, val_acc = 0.82
[Task-specific] Epoch 077: loss = 0.3280, acc = 0.85 | val_loss = 0.3858, val_acc = 0.83
[Task-specific] Epoch 078: loss = 0.3271, acc = 0.85 | val_loss = 0.3869, val_acc = 0.83
[Task-specific] Epoch 079: loss = 0.3285, acc = 0.85 | val_loss = 0.3868, val_acc = 0.83
[Task-specific] Epoch 080: loss = 0.3253, acc = 0.86 | val_loss = 0.3846, val_acc = 0.83
[Task-specific] Epoch 081: loss = 0.3236, acc = 0.86 | val_loss = 0.3847, val_acc = 0.83
[Task-specific] Epoch 082: loss = 0.3208, acc = 0.86 | val_loss = 0.3883, val_acc = 0.83
[Task-specific] Epoch 083: loss = 0.3256, acc = 0.86 | val_loss = 0.3843, val_acc = 0.83
[Task-specific] Epoch 084: loss = 0.3204, acc = 0.86 | val_loss = 0.3838, val_acc = 0.83
[Task-specific] Epoch 085: loss = 0.3159, acc = 0.86 | val_loss = 0.3893, val_acc = 0.83
[Task-specific] Epoch 086: loss = 0.3162, acc = 0.86 | val_loss = 0.3838, val_acc = 0.83
[Task-specific] Epoch 087: loss = 0.3164, acc = 0.86 | val_loss = 0.3851, val_acc = 0.83
[Task-specific] Epoch 088: loss = 0.3125, acc = 0.86 | val_loss = 0.3849, val_acc = 0.83
[Task-specific] Epoch 089: loss = 0.3127, acc = 0.86 | val_loss = 0.3878, val_acc = 0.83
[Task-specific] Epoch 090: loss = 0.3094, acc = 0.87 | val_loss = 0.3829, val_acc = 0.83
[Task-specific] Epoch 091: loss = 0.3065, acc = 0.87 | val_loss = 0.3833, val_acc = 0.83
[Task-specific] Epoch 092: loss = 0.3089, acc = 0.87 | val_loss = 0.3811, val_acc = 0.83
[Task-specific] Epoch 093: loss = 0.3043, acc = 0.87 | val_loss = 0.3850, val_acc = 0.83
[Task-specific] Epoch 094: loss = 0.3048, acc = 0.87 | val_loss = 0.3828, val_acc = 0.83
[Task-specific] Epoch 095: loss = 0.3055, acc = 0.87 | val_loss = 0.3829, val_acc = 0.83
[Task-specific] Epoch 096: loss = 0.3045, acc = 0.87 | val_loss = 0.3827, val_acc = 0.83
[Task-specific] Epoch 097: loss = 0.3002, acc = 0.87 | val_loss = 0.3853, val_acc = 0.83
[Task-specific] Epoch 098: loss = 0.3009, acc = 0.87 | val_loss = 0.3847, val_acc = 0.83
[Task-specific] Epoch 099: loss = 0.3009, acc = 0.87 | val_loss = 0.3832, val_acc = 0.83
‚èπÔ∏è  Early stopping after 99 epochs (best epoch 92, best_val_loss=0.3811).
[Trial 0] Params: lr=0.00006, dropout=0.48, weight_decay=0.000847, scheduler=plateau, hidden_dims=(448, 224)
üèÖ New global best found (val_loss=0.3811) ‚Äì tracked in memory (no files written)
[I 2025-08-27 01:59:48,963] Trial 0 finished with value: 0.38110737521099486 and parameters: {'lr': 5.6115164153345e-05, 'dropout': 0.4753571532049581, 'weight_decay': 0.0008471801418819979, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 448}. Best is trial 0 with value: 0.38110737521099486.
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.5642, acc = 0.71 | val_loss = 0.5243, val_acc = 0.73
[Task-specific] Epoch 002: loss = 0.5162, acc = 0.75 | val_loss = 0.4971, val_acc = 0.76
[Task-specific] Epoch 003: loss = 0.4956, acc = 0.76 | val_loss = 0.4820, val_acc = 0.77
[Task-specific] Epoch 004: loss = 0.4797, acc = 0.77 | val_loss = 0.4696, val_acc = 0.78
[Task-specific] Epoch 005: loss = 0.4690, acc = 0.78 | val_loss = 0.4603, val_acc = 0.79
[Task-specific] Epoch 006: loss = 0.4597, acc = 0.78 | val_loss = 0.4527, val_acc = 0.79
[Task-specific] Epoch 007: loss = 0.4531, acc = 0.79 | val_loss = 0.4474, val_acc = 0.79
[Task-specific] Epoch 008: loss = 0.4460, acc = 0.79 | val_loss = 0.4424, val_acc = 0.80
[Task-specific] Epoch 009: loss = 0.4398, acc = 0.80 | val_loss = 0.4383, val_acc = 0.80
[Task-specific] Epoch 010: loss = 0.4343, acc = 0.80 | val_loss = 0.4362, val_acc = 0.80
[Task-specific] Epoch 011: loss = 0.4333, acc = 0.80 | val_loss = 0.4325, val_acc = 0.80
[Task-specific] Epoch 012: loss = 0.4267, acc = 0.81 | val_loss = 0.4300, val_acc = 0.80
[Task-specific] Epoch 013: loss = 0.4228, acc = 0.81 | val_loss = 0.4282, val_acc = 0.81
[Task-specific] Epoch 014: loss = 0.4174, acc = 0.81 | val_loss = 0.4267, val_acc = 0.81
[Task-specific] Epoch 015: loss = 0.4160, acc = 0.81 | val_loss = 0.4216, val_acc = 0.81
[Task-specific] Epoch 016: loss = 0.4116, acc = 0.81 | val_loss = 0.4200, val_acc = 0.81
[Task-specific] Epoch 017: loss = 0.4101, acc = 0.81 | val_loss = 0.4180, val_acc = 0.81
[Task-specific] Epoch 018: loss = 0.4075, acc = 0.82 | val_loss = 0.4159, val_acc = 0.81
[Task-specific] Epoch 019: loss = 0.4054, acc = 0.82 | val_loss = 0.4135, val_acc = 0.82
[Task-specific] Epoch 020: loss = 0.4000, acc = 0.82 | val_loss = 0.4142, val_acc = 0.81
[Task-specific] Epoch 021: loss = 0.3975, acc = 0.82 | val_loss = 0.4131, val_acc = 0.81
[Task-specific] Epoch 022: loss = 0.3939, acc = 0.82 | val_loss = 0.4099, val_acc = 0.82
[Task-specific] Epoch 023: loss = 0.3933, acc = 0.82 | val_loss = 0.4093, val_acc = 0.82
[Task-specific] Epoch 024: loss = 0.3895, acc = 0.83 | val_loss = 0.4074, val_acc = 0.82
[Task-specific] Epoch 025: loss = 0.3865, acc = 0.83 | val_loss = 0.4084, val_acc = 0.82
[Task-specific] Epoch 026: loss = 0.3869, acc = 0.83 | val_loss = 0.4078, val_acc = 0.82
[Task-specific] Epoch 027: loss = 0.3809, acc = 0.83 | val_loss = 0.4062, val_acc = 0.82
[Task-specific] Epoch 028: loss = 0.3802, acc = 0.83 | val_loss = 0.4045, val_acc = 0.82
[Task-specific] Epoch 029: loss = 0.3793, acc = 0.83 | val_loss = 0.4023, val_acc = 0.82
[Task-specific] Epoch 030: loss = 0.3742, acc = 0.83 | val_loss = 0.3985, val_acc = 0.82
[Task-specific] Epoch 031: loss = 0.3737, acc = 0.83 | val_loss = 0.4001, val_acc = 0.82
[Task-specific] Epoch 032: loss = 0.3700, acc = 0.83 | val_loss = 0.3998, val_acc = 0.82
[Task-specific] Epoch 033: loss = 0.3681, acc = 0.84 | val_loss = 0.3984, val_acc = 0.82
[Task-specific] Epoch 034: loss = 0.3680, acc = 0.84 | val_loss = 0.4035, val_acc = 0.82
[Task-specific] Epoch 035: loss = 0.3661, acc = 0.84 | val_loss = 0.3981, val_acc = 0.82
[Task-specific] Epoch 036: loss = 0.3626, acc = 0.84 | val_loss = 0.3952, val_acc = 0.82
[Task-specific] Epoch 037: loss = 0.3583, acc = 0.84 | val_loss = 0.3969, val_acc = 0.82
[Task-specific] Epoch 038: loss = 0.3569, acc = 0.84 | val_loss = 0.3939, val_acc = 0.82
[Task-specific] Epoch 039: loss = 0.3574, acc = 0.84 | val_loss = 0.3965, val_acc = 0.82
[Task-specific] Epoch 040: loss = 0.3528, acc = 0.84 | val_loss = 0.3943, val_acc = 0.82
[Task-specific] Epoch 041: loss = 0.3513, acc = 0.84 | val_loss = 0.3921, val_acc = 0.83
[Task-specific] Epoch 042: loss = 0.3477, acc = 0.85 | val_loss = 0.3888, val_acc = 0.83
[Task-specific] Epoch 043: loss = 0.3516, acc = 0.84 | val_loss = 0.3897, val_acc = 0.83
[Task-specific] Epoch 044: loss = 0.3508, acc = 0.84 | val_loss = 0.3880, val_acc = 0.82
[Task-specific] Epoch 045: loss = 0.3455, acc = 0.85 | val_loss = 0.3881, val_acc = 0.83
[Task-specific] Epoch 046: loss = 0.3490, acc = 0.85 | val_loss = 0.4155, val_acc = 0.81
[Task-specific] Epoch 047: loss = 0.3440, acc = 0.85 | val_loss = 0.3853, val_acc = 0.83
[Task-specific] Epoch 048: loss = 0.3402, acc = 0.85 | val_loss = 0.3871, val_acc = 0.82
[Task-specific] Epoch 049: loss = 0.3378, acc = 0.85 | val_loss = 0.3844, val_acc = 0.83
[Task-specific] Epoch 050: loss = 0.3363, acc = 0.85 | val_loss = 0.3869, val_acc = 0.82
[Task-specific] Epoch 051: loss = 0.3367, acc = 0.85 | val_loss = 0.3852, val_acc = 0.82
[Task-specific] Epoch 052: loss = 0.3310, acc = 0.85 | val_loss = 0.3886, val_acc = 0.83
[Task-specific] Epoch 053: loss = 0.3297, acc = 0.85 | val_loss = 0.3882, val_acc = 0.82
[Task-specific] Epoch 054: loss = 0.3419, acc = 0.85 | val_loss = 0.3863, val_acc = 0.83
[Task-specific] Epoch 055: loss = 0.3327, acc = 0.85 | val_loss = 0.3851, val_acc = 0.82
[Task-specific] Epoch 056: loss = 0.3261, acc = 0.85 | val_loss = 0.3841, val_acc = 0.83
[Task-specific] Epoch 057: loss = 0.3248, acc = 0.86 | val_loss = 0.3891, val_acc = 0.83
[Task-specific] Epoch 058: loss = 0.3238, acc = 0.86 | val_loss = 0.3853, val_acc = 0.83
[Task-specific] Epoch 059: loss = 0.3212, acc = 0.86 | val_loss = 0.3838, val_acc = 0.83
[Task-specific] Epoch 060: loss = 0.3225, acc = 0.86 | val_loss = 0.3862, val_acc = 0.83
[Task-specific] Epoch 061: loss = 0.3175, acc = 0.86 | val_loss = 0.3811, val_acc = 0.83
[Task-specific] Epoch 062: loss = 0.3194, acc = 0.86 | val_loss = 0.3837, val_acc = 0.83
[Task-specific] Epoch 063: loss = 0.3210, acc = 0.86 | val_loss = 0.3801, val_acc = 0.83
[Task-specific] Epoch 064: loss = 0.3173, acc = 0.86 | val_loss = 0.3850, val_acc = 0.83
[Task-specific] Epoch 065: loss = 0.3130, acc = 0.86 | val_loss = 0.3837, val_acc = 0.83
[Task-specific] Epoch 066: loss = 0.3168, acc = 0.86 | val_loss = 0.3818, val_acc = 0.83
[Task-specific] Epoch 067: loss = 0.3126, acc = 0.86 | val_loss = 0.3821, val_acc = 0.83
[Task-specific] Epoch 068: loss = 0.3120, acc = 0.86 | val_loss = 0.3821, val_acc = 0.83
[Task-specific] Epoch 069: loss = 0.3105, acc = 0.86 | val_loss = 0.3843, val_acc = 0.83
[Task-specific] Epoch 070: loss = 0.3078, acc = 0.87 | val_loss = 0.3832, val_acc = 0.83
‚èπÔ∏è  Early stopping after 70 epochs (best epoch 63, best_val_loss=0.3801).
[Trial 1] Params: lr=0.00016, dropout=0.35, weight_decay=0.000001, scheduler=plateau, hidden_dims=(128, 64)
üèÖ New global best found (val_loss=0.3801) ‚Äì tracked in memory (no files written)
[I 2025-08-27 02:01:26,517] Trial 1 finished with value: 0.38005977606725955 and parameters: {'lr': 0.00015930522616241006, 'dropout': 0.35403628889802274, 'weight_decay': 1.2087541473056965e-06, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 128}. Best is trial 1 with value: 0.38005977606725955.
‚úÖ Optuna search finished ‚Äì best val_loss=0.3801. Best model kept in memory.
üîç Prediction counts: {'label_0': 3260, 'label_1': 2199}
Saving results ‚Ä¶
‚úÖ Pipeline completed successfully to the path Results/tuh-c22!
Results will be saved to: Results/tuh-jr_avg
Loading raw EEG data ‚Ä¶
Loading train data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train_epochs.pkl...
Loaded 53622 samples from train split
Loading eval data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval_epochs.pkl...
Loaded 5459 samples from eval split
Loaded 53622 training samples and 5459 evaluation samples from tuh dataset
Extracting latent features ‚Ä¶
Evaluating latent features ‚Ä¶
Training models for each task
üîπ Task 3: hardcoded as classification ‚Üí 'abnormal'
   ‚Üí Optuna search (n_trials=2) for classification ‚Ä¶
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.7035, acc = 0.57 | val_loss = 0.6528, val_acc = 0.62
[Task-specific] Epoch 002: loss = 0.6716, acc = 0.60 | val_loss = 0.6451, val_acc = 0.63
[Task-specific] Epoch 003: loss = 0.6642, acc = 0.61 | val_loss = 0.6405, val_acc = 0.63
[Task-specific] Epoch 004: loss = 0.6576, acc = 0.62 | val_loss = 0.6387, val_acc = 0.63
[Task-specific] Epoch 005: loss = 0.6560, acc = 0.62 | val_loss = 0.6352, val_acc = 0.64
[Task-specific] Epoch 006: loss = 0.6544, acc = 0.62 | val_loss = 0.6353, val_acc = 0.64
[Task-specific] Epoch 007: loss = 0.6500, acc = 0.63 | val_loss = 0.6330, val_acc = 0.64
[Task-specific] Epoch 008: loss = 0.6500, acc = 0.63 | val_loss = 0.6339, val_acc = 0.64
[Task-specific] Epoch 009: loss = 0.6486, acc = 0.63 | val_loss = 0.6340, val_acc = 0.64
[Task-specific] Epoch 010: loss = 0.6471, acc = 0.63 | val_loss = 0.6320, val_acc = 0.64
[Task-specific] Epoch 011: loss = 0.6458, acc = 0.63 | val_loss = 0.6307, val_acc = 0.65
[Task-specific] Epoch 012: loss = 0.6450, acc = 0.63 | val_loss = 0.6317, val_acc = 0.64
[Task-specific] Epoch 013: loss = 0.6435, acc = 0.63 | val_loss = 0.6295, val_acc = 0.64
[Task-specific] Epoch 014: loss = 0.6426, acc = 0.63 | val_loss = 0.6308, val_acc = 0.64
[Task-specific] Epoch 015: loss = 0.6425, acc = 0.63 | val_loss = 0.6293, val_acc = 0.64
[Task-specific] Epoch 016: loss = 0.6417, acc = 0.63 | val_loss = 0.6282, val_acc = 0.65
[Task-specific] Epoch 017: loss = 0.6410, acc = 0.63 | val_loss = 0.6291, val_acc = 0.65
[Task-specific] Epoch 018: loss = 0.6404, acc = 0.64 | val_loss = 0.6283, val_acc = 0.65
[Task-specific] Epoch 019: loss = 0.6407, acc = 0.64 | val_loss = 0.6279, val_acc = 0.64
[Task-specific] Epoch 020: loss = 0.6380, acc = 0.64 | val_loss = 0.6262, val_acc = 0.65
[Task-specific] Epoch 021: loss = 0.6388, acc = 0.64 | val_loss = 0.6276, val_acc = 0.64
[Task-specific] Epoch 022: loss = 0.6372, acc = 0.64 | val_loss = 0.6266, val_acc = 0.65
[Task-specific] Epoch 023: loss = 0.6378, acc = 0.64 | val_loss = 0.6263, val_acc = 0.64
[Task-specific] Epoch 024: loss = 0.6369, acc = 0.64 | val_loss = 0.6271, val_acc = 0.64
[Task-specific] Epoch 025: loss = 0.6366, acc = 0.64 | val_loss = 0.6260, val_acc = 0.65
[Task-specific] Epoch 026: loss = 0.6364, acc = 0.64 | val_loss = 0.6258, val_acc = 0.66
[Task-specific] Epoch 027: loss = 0.6362, acc = 0.64 | val_loss = 0.6265, val_acc = 0.65
[Task-specific] Epoch 028: loss = 0.6360, acc = 0.65 | val_loss = 0.6251, val_acc = 0.65
[Task-specific] Epoch 029: loss = 0.6346, acc = 0.64 | val_loss = 0.6258, val_acc = 0.65
[Task-specific] Epoch 030: loss = 0.6339, acc = 0.65 | val_loss = 0.6247, val_acc = 0.65
[Task-specific] Epoch 031: loss = 0.6365, acc = 0.64 | val_loss = 0.6252, val_acc = 0.65
[Task-specific] Epoch 032: loss = 0.6327, acc = 0.65 | val_loss = 0.6246, val_acc = 0.65
[Task-specific] Epoch 033: loss = 0.6332, acc = 0.65 | val_loss = 0.6243, val_acc = 0.65
[Task-specific] Epoch 034: loss = 0.6338, acc = 0.65 | val_loss = 0.6243, val_acc = 0.65
[Task-specific] Epoch 035: loss = 0.6334, acc = 0.65 | val_loss = 0.6240, val_acc = 0.65
[Task-specific] Epoch 036: loss = 0.6330, acc = 0.65 | val_loss = 0.6230, val_acc = 0.66
[Task-specific] Epoch 037: loss = 0.6327, acc = 0.65 | val_loss = 0.6238, val_acc = 0.65
[Task-specific] Epoch 038: loss = 0.6327, acc = 0.65 | val_loss = 0.6235, val_acc = 0.65
[Task-specific] Epoch 039: loss = 0.6313, acc = 0.65 | val_loss = 0.6229, val_acc = 0.65
[Task-specific] Epoch 040: loss = 0.6318, acc = 0.65 | val_loss = 0.6233, val_acc = 0.65
[Task-specific] Epoch 041: loss = 0.6314, acc = 0.65 | val_loss = 0.6229, val_acc = 0.65
[Task-specific] Epoch 042: loss = 0.6309, acc = 0.65 | val_loss = 0.6250, val_acc = 0.64
[Task-specific] Epoch 043: loss = 0.6305, acc = 0.65 | val_loss = 0.6222, val_acc = 0.65
[Task-specific] Epoch 044: loss = 0.6308, acc = 0.65 | val_loss = 0.6220, val_acc = 0.65
[Task-specific] Epoch 045: loss = 0.6296, acc = 0.65 | val_loss = 0.6218, val_acc = 0.66
[Task-specific] Epoch 046: loss = 0.6307, acc = 0.65 | val_loss = 0.6211, val_acc = 0.65
[Task-specific] Epoch 047: loss = 0.6300, acc = 0.65 | val_loss = 0.6213, val_acc = 0.65
[Task-specific] Epoch 048: loss = 0.6298, acc = 0.65 | val_loss = 0.6216, val_acc = 0.66
[Task-specific] Epoch 049: loss = 0.6297, acc = 0.65 | val_loss = 0.6221, val_acc = 0.65
[Task-specific] Epoch 050: loss = 0.6298, acc = 0.65 | val_loss = 0.6219, val_acc = 0.65
[Task-specific] Epoch 051: loss = 0.6295, acc = 0.65 | val_loss = 0.6206, val_acc = 0.66
[Task-specific] Epoch 052: loss = 0.6297, acc = 0.65 | val_loss = 0.6212, val_acc = 0.65
[Task-specific] Epoch 053: loss = 0.6290, acc = 0.65 | val_loss = 0.6210, val_acc = 0.66
[Task-specific] Epoch 054: loss = 0.6285, acc = 0.65 | val_loss = 0.6214, val_acc = 0.65
[Task-specific] Epoch 055: loss = 0.6285, acc = 0.65 | val_loss = 0.6204, val_acc = 0.65
[Task-specific] Epoch 056: loss = 0.6280, acc = 0.65 | val_loss = 0.6198, val_acc = 0.66
[Task-specific] Epoch 057: loss = 0.6284, acc = 0.65 | val_loss = 0.6202, val_acc = 0.66
[Task-specific] Epoch 058: loss = 0.6282, acc = 0.65 | val_loss = 0.6198, val_acc = 0.66
[Task-specific] Epoch 059: loss = 0.6272, acc = 0.65 | val_loss = 0.6210, val_acc = 0.65
[Task-specific] Epoch 060: loss = 0.6262, acc = 0.65 | val_loss = 0.6195, val_acc = 0.66
[Task-specific] Epoch 061: loss = 0.6258, acc = 0.65 | val_loss = 0.6189, val_acc = 0.66
[Task-specific] Epoch 062: loss = 0.6271, acc = 0.65 | val_loss = 0.6199, val_acc = 0.65
[Task-specific] Epoch 063: loss = 0.6275, acc = 0.65 | val_loss = 0.6190, val_acc = 0.66
[Task-specific] Epoch 064: loss = 0.6259, acc = 0.66 | val_loss = 0.6192, val_acc = 0.66
[Task-specific] Epoch 065: loss = 0.6268, acc = 0.65 | val_loss = 0.6194, val_acc = 0.66
[Task-specific] Epoch 066: loss = 0.6261, acc = 0.65 | val_loss = 0.6190, val_acc = 0.65
[Task-specific] Epoch 067: loss = 0.6268, acc = 0.65 | val_loss = 0.6192, val_acc = 0.66
[Task-specific] Epoch 068: loss = 0.6256, acc = 0.66 | val_loss = 0.6198, val_acc = 0.65
‚èπÔ∏è  Early stopping after 68 epochs (best epoch 61, best_val_loss=0.6189).
[Trial 0] Params: lr=0.00006, dropout=0.48, weight_decay=0.000847, scheduler=plateau, hidden_dims=(448, 224)
üèÖ New global best found (val_loss=0.6189) ‚Äì tracked in memory (no files written)
[I 2025-08-27 02:49:43,328] Trial 0 finished with value: 0.6189352354856346 and parameters: {'lr': 5.6115164153345e-05, 'dropout': 0.4753571532049581, 'weight_decay': 0.0008471801418819979, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 448}. Best is trial 0 with value: 0.6189352354856346.
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6856, acc = 0.57 | val_loss = 0.6551, val_acc = 0.61
[Task-specific] Epoch 002: loss = 0.6667, acc = 0.60 | val_loss = 0.6487, val_acc = 0.61
[Task-specific] Epoch 003: loss = 0.6613, acc = 0.61 | val_loss = 0.6441, val_acc = 0.62
[Task-specific] Epoch 004: loss = 0.6570, acc = 0.61 | val_loss = 0.6415, val_acc = 0.62
[Task-specific] Epoch 005: loss = 0.6539, acc = 0.62 | val_loss = 0.6395, val_acc = 0.63
[Task-specific] Epoch 006: loss = 0.6518, acc = 0.62 | val_loss = 0.6385, val_acc = 0.63
[Task-specific] Epoch 007: loss = 0.6500, acc = 0.62 | val_loss = 0.6368, val_acc = 0.63
[Task-specific] Epoch 008: loss = 0.6486, acc = 0.62 | val_loss = 0.6358, val_acc = 0.63
[Task-specific] Epoch 009: loss = 0.6462, acc = 0.63 | val_loss = 0.6346, val_acc = 0.64
[Task-specific] Epoch 010: loss = 0.6458, acc = 0.63 | val_loss = 0.6335, val_acc = 0.64
[Task-specific] Epoch 011: loss = 0.6438, acc = 0.63 | val_loss = 0.6333, val_acc = 0.63
[Task-specific] Epoch 012: loss = 0.6425, acc = 0.63 | val_loss = 0.6320, val_acc = 0.64
[Task-specific] Epoch 013: loss = 0.6433, acc = 0.63 | val_loss = 0.6317, val_acc = 0.64
[Task-specific] Epoch 014: loss = 0.6414, acc = 0.63 | val_loss = 0.6301, val_acc = 0.65
[Task-specific] Epoch 015: loss = 0.6416, acc = 0.63 | val_loss = 0.6303, val_acc = 0.64
[Task-specific] Epoch 016: loss = 0.6397, acc = 0.64 | val_loss = 0.6292, val_acc = 0.65
[Task-specific] Epoch 017: loss = 0.6395, acc = 0.64 | val_loss = 0.6284, val_acc = 0.64
[Task-specific] Epoch 018: loss = 0.6397, acc = 0.64 | val_loss = 0.6281, val_acc = 0.65
[Task-specific] Epoch 019: loss = 0.6377, acc = 0.64 | val_loss = 0.6273, val_acc = 0.65
[Task-specific] Epoch 020: loss = 0.6373, acc = 0.64 | val_loss = 0.6295, val_acc = 0.64
[Task-specific] Epoch 021: loss = 0.6370, acc = 0.64 | val_loss = 0.6266, val_acc = 0.65
[Task-specific] Epoch 022: loss = 0.6368, acc = 0.64 | val_loss = 0.6274, val_acc = 0.65
[Task-specific] Epoch 023: loss = 0.6369, acc = 0.64 | val_loss = 0.6266, val_acc = 0.64
[Task-specific] Epoch 024: loss = 0.6359, acc = 0.64 | val_loss = 0.6262, val_acc = 0.65
[Task-specific] Epoch 025: loss = 0.6353, acc = 0.65 | val_loss = 0.6258, val_acc = 0.65
[Task-specific] Epoch 026: loss = 0.6341, acc = 0.65 | val_loss = 0.6250, val_acc = 0.65
[Task-specific] Epoch 027: loss = 0.6359, acc = 0.64 | val_loss = 0.6253, val_acc = 0.65
[Task-specific] Epoch 028: loss = 0.6352, acc = 0.65 | val_loss = 0.6241, val_acc = 0.65
[Task-specific] Epoch 029: loss = 0.6339, acc = 0.65 | val_loss = 0.6242, val_acc = 0.65
[Task-specific] Epoch 030: loss = 0.6327, acc = 0.65 | val_loss = 0.6242, val_acc = 0.65
[Task-specific] Epoch 031: loss = 0.6338, acc = 0.65 | val_loss = 0.6243, val_acc = 0.65
[Task-specific] Epoch 032: loss = 0.6328, acc = 0.65 | val_loss = 0.6230, val_acc = 0.65
[Task-specific] Epoch 033: loss = 0.6327, acc = 0.65 | val_loss = 0.6233, val_acc = 0.65
[Task-specific] Epoch 034: loss = 0.6307, acc = 0.65 | val_loss = 0.6240, val_acc = 0.64
[Task-specific] Epoch 035: loss = 0.6319, acc = 0.65 | val_loss = 0.6245, val_acc = 0.65
[Task-specific] Epoch 036: loss = 0.6318, acc = 0.65 | val_loss = 0.6228, val_acc = 0.65
[Task-specific] Epoch 037: loss = 0.6314, acc = 0.65 | val_loss = 0.6216, val_acc = 0.66
[Task-specific] Epoch 038: loss = 0.6319, acc = 0.65 | val_loss = 0.6216, val_acc = 0.65
[Task-specific] Epoch 039: loss = 0.6311, acc = 0.65 | val_loss = 0.6210, val_acc = 0.66
[Task-specific] Epoch 040: loss = 0.6310, acc = 0.65 | val_loss = 0.6216, val_acc = 0.65
[Task-specific] Epoch 041: loss = 0.6306, acc = 0.65 | val_loss = 0.6210, val_acc = 0.66
[Task-specific] Epoch 042: loss = 0.6302, acc = 0.65 | val_loss = 0.6211, val_acc = 0.66
[Task-specific] Epoch 043: loss = 0.6299, acc = 0.65 | val_loss = 0.6202, val_acc = 0.66
[Task-specific] Epoch 044: loss = 0.6305, acc = 0.65 | val_loss = 0.6195, val_acc = 0.66
[Task-specific] Epoch 045: loss = 0.6287, acc = 0.65 | val_loss = 0.6229, val_acc = 0.65
[Task-specific] Epoch 046: loss = 0.6293, acc = 0.65 | val_loss = 0.6194, val_acc = 0.66
[Task-specific] Epoch 047: loss = 0.6290, acc = 0.65 | val_loss = 0.6193, val_acc = 0.66
[Task-specific] Epoch 048: loss = 0.6284, acc = 0.65 | val_loss = 0.6189, val_acc = 0.66
[Task-specific] Epoch 049: loss = 0.6284, acc = 0.65 | val_loss = 0.6190, val_acc = 0.66
[Task-specific] Epoch 050: loss = 0.6275, acc = 0.65 | val_loss = 0.6190, val_acc = 0.66
[Task-specific] Epoch 051: loss = 0.6282, acc = 0.65 | val_loss = 0.6205, val_acc = 0.65
[Task-specific] Epoch 052: loss = 0.6279, acc = 0.65 | val_loss = 0.6182, val_acc = 0.66
[Task-specific] Epoch 053: loss = 0.6277, acc = 0.65 | val_loss = 0.6176, val_acc = 0.66
[Task-specific] Epoch 054: loss = 0.6283, acc = 0.65 | val_loss = 0.6188, val_acc = 0.66
[Task-specific] Epoch 055: loss = 0.6270, acc = 0.65 | val_loss = 0.6184, val_acc = 0.66
[Task-specific] Epoch 056: loss = 0.6264, acc = 0.65 | val_loss = 0.6177, val_acc = 0.66
[Task-specific] Epoch 057: loss = 0.6265, acc = 0.65 | val_loss = 0.6177, val_acc = 0.66
[Task-specific] Epoch 058: loss = 0.6271, acc = 0.65 | val_loss = 0.6180, val_acc = 0.66
[Task-specific] Epoch 059: loss = 0.6275, acc = 0.65 | val_loss = 0.6190, val_acc = 0.66
[Task-specific] Epoch 060: loss = 0.6257, acc = 0.66 | val_loss = 0.6178, val_acc = 0.66
‚èπÔ∏è  Early stopping after 60 epochs (best epoch 53, best_val_loss=0.6176).
[Trial 1] Params: lr=0.00016, dropout=0.35, weight_decay=0.000001, scheduler=plateau, hidden_dims=(128, 64)
üèÖ New global best found (val_loss=0.6176) ‚Äì tracked in memory (no files written)
[I 2025-08-27 02:50:52,637] Trial 1 finished with value: 0.617620594995879 and parameters: {'lr': 0.00015930522616241006, 'dropout': 0.35403628889802274, 'weight_decay': 1.2087541473056965e-06, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 128}. Best is trial 1 with value: 0.617620594995879.
‚úÖ Optuna search finished ‚Äì best val_loss=0.6176. Best model kept in memory.
üîç Prediction counts: {'label_0': 3003, 'label_1': 2456}
Saving results ‚Ä¶
‚úÖ Pipeline completed successfully to the path Results/tuh-jr_avg!
Results will be saved to: Results/tuh-hopf_avg
Loading raw EEG data ‚Ä¶
Loading train data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train_epochs.pkl...
Loaded 53622 samples from train split
Loading eval data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval_epochs.pkl...
Loaded 5459 samples from eval split
Loaded 53622 training samples and 5459 evaluation samples from tuh dataset
Extracting latent features ‚Ä¶
Evaluating latent features ‚Ä¶
Training models for each task
üîπ Task 3: hardcoded as classification ‚Üí 'abnormal'
   ‚Üí Optuna search (n_trials=2) for classification ‚Ä¶
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6455, acc = 0.64 | val_loss = 0.5949, val_acc = 0.69
[Task-specific] Epoch 002: loss = 0.6085, acc = 0.69 | val_loss = 0.5828, val_acc = 0.70
[Task-specific] Epoch 003: loss = 0.5986, acc = 0.69 | val_loss = 0.5780, val_acc = 0.71
[Task-specific] Epoch 004: loss = 0.5957, acc = 0.70 | val_loss = 0.5749, val_acc = 0.71
[Task-specific] Epoch 005: loss = 0.5908, acc = 0.70 | val_loss = 0.5723, val_acc = 0.71
[Task-specific] Epoch 006: loss = 0.5883, acc = 0.70 | val_loss = 0.5706, val_acc = 0.71
[Task-specific] Epoch 007: loss = 0.5849, acc = 0.70 | val_loss = 0.5698, val_acc = 0.71
[Task-specific] Epoch 008: loss = 0.5843, acc = 0.70 | val_loss = 0.5690, val_acc = 0.71
[Task-specific] Epoch 009: loss = 0.5835, acc = 0.70 | val_loss = 0.5681, val_acc = 0.71
[Task-specific] Epoch 010: loss = 0.5827, acc = 0.70 | val_loss = 0.5680, val_acc = 0.71
[Task-specific] Epoch 011: loss = 0.5811, acc = 0.70 | val_loss = 0.5668, val_acc = 0.71
[Task-specific] Epoch 012: loss = 0.5799, acc = 0.70 | val_loss = 0.5662, val_acc = 0.71
[Task-specific] Epoch 013: loss = 0.5770, acc = 0.71 | val_loss = 0.5657, val_acc = 0.71
[Task-specific] Epoch 014: loss = 0.5763, acc = 0.71 | val_loss = 0.5653, val_acc = 0.71
[Task-specific] Epoch 015: loss = 0.5760, acc = 0.71 | val_loss = 0.5650, val_acc = 0.71
[Task-specific] Epoch 016: loss = 0.5746, acc = 0.71 | val_loss = 0.5648, val_acc = 0.71
[Task-specific] Epoch 017: loss = 0.5727, acc = 0.71 | val_loss = 0.5650, val_acc = 0.71
[Task-specific] Epoch 018: loss = 0.5727, acc = 0.71 | val_loss = 0.5643, val_acc = 0.71
[Task-specific] Epoch 019: loss = 0.5740, acc = 0.71 | val_loss = 0.5639, val_acc = 0.72
[Task-specific] Epoch 020: loss = 0.5723, acc = 0.71 | val_loss = 0.5637, val_acc = 0.71
[Task-specific] Epoch 021: loss = 0.5709, acc = 0.71 | val_loss = 0.5637, val_acc = 0.71
[Task-specific] Epoch 022: loss = 0.5703, acc = 0.71 | val_loss = 0.5637, val_acc = 0.72
[Task-specific] Epoch 023: loss = 0.5714, acc = 0.71 | val_loss = 0.5640, val_acc = 0.71
[Task-specific] Epoch 024: loss = 0.5696, acc = 0.71 | val_loss = 0.5633, val_acc = 0.72
[Task-specific] Epoch 025: loss = 0.5697, acc = 0.71 | val_loss = 0.5623, val_acc = 0.72
[Task-specific] Epoch 026: loss = 0.5693, acc = 0.71 | val_loss = 0.5623, val_acc = 0.71
[Task-specific] Epoch 027: loss = 0.5669, acc = 0.71 | val_loss = 0.5620, val_acc = 0.72
[Task-specific] Epoch 028: loss = 0.5656, acc = 0.71 | val_loss = 0.5621, val_acc = 0.72
[Task-specific] Epoch 029: loss = 0.5675, acc = 0.71 | val_loss = 0.5618, val_acc = 0.71
[Task-specific] Epoch 030: loss = 0.5675, acc = 0.71 | val_loss = 0.5655, val_acc = 0.71
[Task-specific] Epoch 031: loss = 0.5668, acc = 0.71 | val_loss = 0.5610, val_acc = 0.72
[Task-specific] Epoch 032: loss = 0.5644, acc = 0.71 | val_loss = 0.5610, val_acc = 0.72
[Task-specific] Epoch 033: loss = 0.5656, acc = 0.71 | val_loss = 0.5614, val_acc = 0.72
[Task-specific] Epoch 034: loss = 0.5670, acc = 0.71 | val_loss = 0.5602, val_acc = 0.72
[Task-specific] Epoch 035: loss = 0.5655, acc = 0.71 | val_loss = 0.5610, val_acc = 0.72
[Task-specific] Epoch 036: loss = 0.5625, acc = 0.72 | val_loss = 0.5597, val_acc = 0.72
[Task-specific] Epoch 037: loss = 0.5644, acc = 0.71 | val_loss = 0.5599, val_acc = 0.72
[Task-specific] Epoch 038: loss = 0.5632, acc = 0.72 | val_loss = 0.5595, val_acc = 0.72
[Task-specific] Epoch 039: loss = 0.5637, acc = 0.72 | val_loss = 0.5594, val_acc = 0.72
[Task-specific] Epoch 040: loss = 0.5620, acc = 0.72 | val_loss = 0.5597, val_acc = 0.72
[Task-specific] Epoch 041: loss = 0.5622, acc = 0.72 | val_loss = 0.5594, val_acc = 0.72
[Task-specific] Epoch 042: loss = 0.5620, acc = 0.72 | val_loss = 0.5586, val_acc = 0.72
[Task-specific] Epoch 043: loss = 0.5620, acc = 0.72 | val_loss = 0.5584, val_acc = 0.72
[Task-specific] Epoch 044: loss = 0.5617, acc = 0.72 | val_loss = 0.5586, val_acc = 0.72
[Task-specific] Epoch 045: loss = 0.5625, acc = 0.72 | val_loss = 0.5595, val_acc = 0.72
[Task-specific] Epoch 046: loss = 0.5616, acc = 0.72 | val_loss = 0.5584, val_acc = 0.72
[Task-specific] Epoch 047: loss = 0.5605, acc = 0.72 | val_loss = 0.5578, val_acc = 0.72
[Task-specific] Epoch 048: loss = 0.5614, acc = 0.72 | val_loss = 0.5580, val_acc = 0.72
[Task-specific] Epoch 049: loss = 0.5598, acc = 0.72 | val_loss = 0.5578, val_acc = 0.72
[Task-specific] Epoch 050: loss = 0.5604, acc = 0.72 | val_loss = 0.5590, val_acc = 0.72
[Task-specific] Epoch 051: loss = 0.5592, acc = 0.72 | val_loss = 0.5574, val_acc = 0.72
[Task-specific] Epoch 052: loss = 0.5608, acc = 0.72 | val_loss = 0.5574, val_acc = 0.72
[Task-specific] Epoch 053: loss = 0.5593, acc = 0.72 | val_loss = 0.5567, val_acc = 0.72
[Task-specific] Epoch 054: loss = 0.5592, acc = 0.72 | val_loss = 0.5578, val_acc = 0.72
[Task-specific] Epoch 055: loss = 0.5599, acc = 0.72 | val_loss = 0.5571, val_acc = 0.72
[Task-specific] Epoch 056: loss = 0.5584, acc = 0.72 | val_loss = 0.5575, val_acc = 0.72
[Task-specific] Epoch 057: loss = 0.5584, acc = 0.72 | val_loss = 0.5569, val_acc = 0.72
[Task-specific] Epoch 058: loss = 0.5586, acc = 0.72 | val_loss = 0.5582, val_acc = 0.72
[Task-specific] Epoch 059: loss = 0.5579, acc = 0.72 | val_loss = 0.5564, val_acc = 0.72
[Task-specific] Epoch 060: loss = 0.5581, acc = 0.72 | val_loss = 0.5561, val_acc = 0.72
[Task-specific] Epoch 061: loss = 0.5585, acc = 0.72 | val_loss = 0.5559, val_acc = 0.72
[Task-specific] Epoch 062: loss = 0.5573, acc = 0.72 | val_loss = 0.5567, val_acc = 0.72
[Task-specific] Epoch 063: loss = 0.5575, acc = 0.72 | val_loss = 0.5565, val_acc = 0.72
[Task-specific] Epoch 064: loss = 0.5568, acc = 0.72 | val_loss = 0.5559, val_acc = 0.72
[Task-specific] Epoch 065: loss = 0.5573, acc = 0.72 | val_loss = 0.5560, val_acc = 0.72
[Task-specific] Epoch 066: loss = 0.5570, acc = 0.72 | val_loss = 0.5560, val_acc = 0.72
[Task-specific] Epoch 067: loss = 0.5576, acc = 0.72 | val_loss = 0.5566, val_acc = 0.72
[Task-specific] Epoch 068: loss = 0.5563, acc = 0.72 | val_loss = 0.5560, val_acc = 0.72
‚èπÔ∏è  Early stopping after 68 epochs (best epoch 61, best_val_loss=0.5559).
[Trial 0] Params: lr=0.00006, dropout=0.48, weight_decay=0.000847, scheduler=plateau, hidden_dims=(448, 224)
üèÖ New global best found (val_loss=0.5559) ‚Äì tracked in memory (no files written)
[I 2025-08-27 03:01:18,177] Trial 0 finished with value: 0.5558809583487053 and parameters: {'lr': 5.6115164153345e-05, 'dropout': 0.4753571532049581, 'weight_decay': 0.0008471801418819979, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 448}. Best is trial 0 with value: 0.5558809583487053.
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6409, acc = 0.65 | val_loss = 0.6050, val_acc = 0.68
[Task-specific] Epoch 002: loss = 0.6075, acc = 0.69 | val_loss = 0.5907, val_acc = 0.69
[Task-specific] Epoch 003: loss = 0.5974, acc = 0.69 | val_loss = 0.5842, val_acc = 0.70
[Task-specific] Epoch 004: loss = 0.5904, acc = 0.70 | val_loss = 0.5802, val_acc = 0.70
[Task-specific] Epoch 005: loss = 0.5873, acc = 0.70 | val_loss = 0.5766, val_acc = 0.70
[Task-specific] Epoch 006: loss = 0.5850, acc = 0.70 | val_loss = 0.5751, val_acc = 0.71
[Task-specific] Epoch 007: loss = 0.5826, acc = 0.70 | val_loss = 0.5735, val_acc = 0.71
[Task-specific] Epoch 008: loss = 0.5802, acc = 0.70 | val_loss = 0.5718, val_acc = 0.71
[Task-specific] Epoch 009: loss = 0.5800, acc = 0.71 | val_loss = 0.5715, val_acc = 0.71
[Task-specific] Epoch 010: loss = 0.5780, acc = 0.71 | val_loss = 0.5718, val_acc = 0.71
[Task-specific] Epoch 011: loss = 0.5762, acc = 0.71 | val_loss = 0.5694, val_acc = 0.71
[Task-specific] Epoch 012: loss = 0.5738, acc = 0.71 | val_loss = 0.5681, val_acc = 0.71
[Task-specific] Epoch 013: loss = 0.5751, acc = 0.71 | val_loss = 0.5688, val_acc = 0.71
[Task-specific] Epoch 014: loss = 0.5745, acc = 0.71 | val_loss = 0.5676, val_acc = 0.71
[Task-specific] Epoch 015: loss = 0.5718, acc = 0.71 | val_loss = 0.5665, val_acc = 0.71
[Task-specific] Epoch 016: loss = 0.5720, acc = 0.71 | val_loss = 0.5666, val_acc = 0.71
[Task-specific] Epoch 017: loss = 0.5692, acc = 0.71 | val_loss = 0.5667, val_acc = 0.71
[Task-specific] Epoch 018: loss = 0.5692, acc = 0.71 | val_loss = 0.5659, val_acc = 0.71
[Task-specific] Epoch 019: loss = 0.5677, acc = 0.71 | val_loss = 0.5648, val_acc = 0.71
[Task-specific] Epoch 020: loss = 0.5684, acc = 0.71 | val_loss = 0.5647, val_acc = 0.72
[Task-specific] Epoch 021: loss = 0.5676, acc = 0.71 | val_loss = 0.5642, val_acc = 0.71
[Task-specific] Epoch 022: loss = 0.5676, acc = 0.71 | val_loss = 0.5645, val_acc = 0.72
[Task-specific] Epoch 023: loss = 0.5656, acc = 0.71 | val_loss = 0.5636, val_acc = 0.72
[Task-specific] Epoch 024: loss = 0.5655, acc = 0.72 | val_loss = 0.5633, val_acc = 0.72
[Task-specific] Epoch 025: loss = 0.5657, acc = 0.71 | val_loss = 0.5640, val_acc = 0.72
[Task-specific] Epoch 026: loss = 0.5649, acc = 0.71 | val_loss = 0.5636, val_acc = 0.72
[Task-specific] Epoch 027: loss = 0.5651, acc = 0.71 | val_loss = 0.5626, val_acc = 0.72
[Task-specific] Epoch 028: loss = 0.5634, acc = 0.72 | val_loss = 0.5623, val_acc = 0.72
[Task-specific] Epoch 029: loss = 0.5643, acc = 0.72 | val_loss = 0.5622, val_acc = 0.72
[Task-specific] Epoch 030: loss = 0.5640, acc = 0.72 | val_loss = 0.5618, val_acc = 0.72
[Task-specific] Epoch 031: loss = 0.5643, acc = 0.72 | val_loss = 0.5621, val_acc = 0.72
[Task-specific] Epoch 032: loss = 0.5626, acc = 0.72 | val_loss = 0.5618, val_acc = 0.72
[Task-specific] Epoch 033: loss = 0.5621, acc = 0.72 | val_loss = 0.5619, val_acc = 0.72
[Task-specific] Epoch 034: loss = 0.5626, acc = 0.72 | val_loss = 0.5634, val_acc = 0.72
[Task-specific] Epoch 035: loss = 0.5618, acc = 0.72 | val_loss = 0.5616, val_acc = 0.72
[Task-specific] Epoch 036: loss = 0.5606, acc = 0.72 | val_loss = 0.5612, val_acc = 0.72
[Task-specific] Epoch 037: loss = 0.5612, acc = 0.72 | val_loss = 0.5604, val_acc = 0.72
[Task-specific] Epoch 038: loss = 0.5606, acc = 0.72 | val_loss = 0.5598, val_acc = 0.72
[Task-specific] Epoch 039: loss = 0.5606, acc = 0.72 | val_loss = 0.5596, val_acc = 0.72
[Task-specific] Epoch 040: loss = 0.5599, acc = 0.72 | val_loss = 0.5597, val_acc = 0.72
[Task-specific] Epoch 041: loss = 0.5604, acc = 0.72 | val_loss = 0.5593, val_acc = 0.72
[Task-specific] Epoch 042: loss = 0.5605, acc = 0.72 | val_loss = 0.5594, val_acc = 0.72
[Task-specific] Epoch 043: loss = 0.5595, acc = 0.72 | val_loss = 0.5593, val_acc = 0.72
[Task-specific] Epoch 044: loss = 0.5581, acc = 0.72 | val_loss = 0.5597, val_acc = 0.72
[Task-specific] Epoch 045: loss = 0.5605, acc = 0.72 | val_loss = 0.5586, val_acc = 0.72
[Task-specific] Epoch 046: loss = 0.5597, acc = 0.72 | val_loss = 0.5584, val_acc = 0.72
[Task-specific] Epoch 047: loss = 0.5597, acc = 0.72 | val_loss = 0.5586, val_acc = 0.72
[Task-specific] Epoch 048: loss = 0.5587, acc = 0.72 | val_loss = 0.5585, val_acc = 0.72
[Task-specific] Epoch 049: loss = 0.5594, acc = 0.72 | val_loss = 0.5607, val_acc = 0.72
[Task-specific] Epoch 050: loss = 0.5585, acc = 0.72 | val_loss = 0.5580, val_acc = 0.72
[Task-specific] Epoch 051: loss = 0.5594, acc = 0.72 | val_loss = 0.5580, val_acc = 0.72
[Task-specific] Epoch 052: loss = 0.5572, acc = 0.72 | val_loss = 0.5577, val_acc = 0.72
[Task-specific] Epoch 053: loss = 0.5584, acc = 0.72 | val_loss = 0.5581, val_acc = 0.72
[Task-specific] Epoch 054: loss = 0.5567, acc = 0.72 | val_loss = 0.5579, val_acc = 0.72
[Task-specific] Epoch 055: loss = 0.5561, acc = 0.72 | val_loss = 0.5574, val_acc = 0.72
[Task-specific] Epoch 056: loss = 0.5565, acc = 0.72 | val_loss = 0.5572, val_acc = 0.72
[Task-specific] Epoch 057: loss = 0.5571, acc = 0.72 | val_loss = 0.5567, val_acc = 0.72
[Task-specific] Epoch 058: loss = 0.5565, acc = 0.72 | val_loss = 0.5574, val_acc = 0.72
[Task-specific] Epoch 059: loss = 0.5565, acc = 0.72 | val_loss = 0.5579, val_acc = 0.72
[Task-specific] Epoch 060: loss = 0.5569, acc = 0.72 | val_loss = 0.5563, val_acc = 0.72
[Task-specific] Epoch 061: loss = 0.5560, acc = 0.72 | val_loss = 0.5559, val_acc = 0.72
[Task-specific] Epoch 062: loss = 0.5559, acc = 0.72 | val_loss = 0.5573, val_acc = 0.72
[Task-specific] Epoch 063: loss = 0.5571, acc = 0.72 | val_loss = 0.5564, val_acc = 0.72
[Task-specific] Epoch 064: loss = 0.5568, acc = 0.72 | val_loss = 0.5562, val_acc = 0.72
[Task-specific] Epoch 065: loss = 0.5566, acc = 0.72 | val_loss = 0.5563, val_acc = 0.72
[Task-specific] Epoch 066: loss = 0.5560, acc = 0.72 | val_loss = 0.5558, val_acc = 0.72
[Task-specific] Epoch 067: loss = 0.5534, acc = 0.72 | val_loss = 0.5558, val_acc = 0.72
[Task-specific] Epoch 068: loss = 0.5563, acc = 0.72 | val_loss = 0.5558, val_acc = 0.72
[Task-specific] Epoch 069: loss = 0.5557, acc = 0.72 | val_loss = 0.5557, val_acc = 0.72
[Task-specific] Epoch 070: loss = 0.5552, acc = 0.72 | val_loss = 0.5556, val_acc = 0.72
[Task-specific] Epoch 071: loss = 0.5537, acc = 0.72 | val_loss = 0.5557, val_acc = 0.72
[Task-specific] Epoch 072: loss = 0.5537, acc = 0.72 | val_loss = 0.5548, val_acc = 0.72
[Task-specific] Epoch 073: loss = 0.5539, acc = 0.72 | val_loss = 0.5548, val_acc = 0.72
[Task-specific] Epoch 074: loss = 0.5541, acc = 0.72 | val_loss = 0.5550, val_acc = 0.72
[Task-specific] Epoch 075: loss = 0.5539, acc = 0.72 | val_loss = 0.5547, val_acc = 0.72
[Task-specific] Epoch 076: loss = 0.5525, acc = 0.72 | val_loss = 0.5547, val_acc = 0.72
[Task-specific] Epoch 077: loss = 0.5538, acc = 0.72 | val_loss = 0.5549, val_acc = 0.72
[Task-specific] Epoch 078: loss = 0.5537, acc = 0.72 | val_loss = 0.5549, val_acc = 0.72
[Task-specific] Epoch 079: loss = 0.5521, acc = 0.72 | val_loss = 0.5541, val_acc = 0.72
[Task-specific] Epoch 080: loss = 0.5541, acc = 0.72 | val_loss = 0.5541, val_acc = 0.72
[Task-specific] Epoch 081: loss = 0.5528, acc = 0.72 | val_loss = 0.5537, val_acc = 0.72
[Task-specific] Epoch 082: loss = 0.5533, acc = 0.72 | val_loss = 0.5546, val_acc = 0.72
[Task-specific] Epoch 083: loss = 0.5535, acc = 0.72 | val_loss = 0.5543, val_acc = 0.72
[Task-specific] Epoch 084: loss = 0.5528, acc = 0.72 | val_loss = 0.5544, val_acc = 0.72
[Task-specific] Epoch 085: loss = 0.5537, acc = 0.72 | val_loss = 0.5539, val_acc = 0.72
[Task-specific] Epoch 086: loss = 0.5530, acc = 0.72 | val_loss = 0.5539, val_acc = 0.72
[Task-specific] Epoch 087: loss = 0.5509, acc = 0.72 | val_loss = 0.5537, val_acc = 0.72
[Task-specific] Epoch 088: loss = 0.5519, acc = 0.73 | val_loss = 0.5540, val_acc = 0.72
[Task-specific] Epoch 089: loss = 0.5532, acc = 0.72 | val_loss = 0.5535, val_acc = 0.72
[Task-specific] Epoch 090: loss = 0.5517, acc = 0.72 | val_loss = 0.5539, val_acc = 0.72
[Task-specific] Epoch 091: loss = 0.5523, acc = 0.72 | val_loss = 0.5532, val_acc = 0.72
[Task-specific] Epoch 092: loss = 0.5503, acc = 0.72 | val_loss = 0.5542, val_acc = 0.72
[Task-specific] Epoch 093: loss = 0.5518, acc = 0.73 | val_loss = 0.5538, val_acc = 0.72
[Task-specific] Epoch 094: loss = 0.5518, acc = 0.72 | val_loss = 0.5529, val_acc = 0.72
[Task-specific] Epoch 095: loss = 0.5513, acc = 0.72 | val_loss = 0.5529, val_acc = 0.72
[Task-specific] Epoch 096: loss = 0.5521, acc = 0.72 | val_loss = 0.5528, val_acc = 0.72
[Task-specific] Epoch 097: loss = 0.5500, acc = 0.73 | val_loss = 0.5529, val_acc = 0.72
[Task-specific] Epoch 098: loss = 0.5526, acc = 0.72 | val_loss = 0.5531, val_acc = 0.72
[Task-specific] Epoch 099: loss = 0.5513, acc = 0.73 | val_loss = 0.5545, val_acc = 0.72
[Task-specific] Epoch 100: loss = 0.5518, acc = 0.72 | val_loss = 0.5526, val_acc = 0.72
[Trial 1] Params: lr=0.00016, dropout=0.35, weight_decay=0.000001, scheduler=plateau, hidden_dims=(128, 64)
üèÖ New global best found (val_loss=0.5526) ‚Äì tracked in memory (no files written)
[I 2025-08-27 03:03:10,841] Trial 1 finished with value: 0.5526422133557184 and parameters: {'lr': 0.00015930522616241006, 'dropout': 0.35403628889802274, 'weight_decay': 1.2087541473056965e-06, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 128}. Best is trial 1 with value: 0.5526422133557184.
‚úÖ Optuna search finished ‚Äì best val_loss=0.5526. Best model kept in memory.
üîç Prediction counts: {'label_0': 2786, 'label_1': 2673}
Saving results ‚Ä¶
‚úÖ Pipeline completed successfully to the path Results/tuh-hopf_avg!
Results will be saved to: Results/tuh-wong_wang_avg
Loading raw EEG data ‚Ä¶
Loading train data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train_epochs.pkl...
Loaded 53622 samples from train split
Loading eval data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval_epochs.pkl...
Loaded 5459 samples from eval split
Loaded 53622 training samples and 5459 evaluation samples from tuh dataset
Extracting latent features ‚Ä¶
Evaluating latent features ‚Ä¶
Training models for each task
üîπ Task 3: hardcoded as classification ‚Üí 'abnormal'
   ‚Üí Optuna search (n_trials=2) for classification ‚Ä¶
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.7039, acc = 0.54 | val_loss = 0.6763, val_acc = 0.58
[Task-specific] Epoch 002: loss = 0.6926, acc = 0.56 | val_loss = 0.6759, val_acc = 0.58
[Task-specific] Epoch 003: loss = 0.6927, acc = 0.56 | val_loss = 0.6756, val_acc = 0.58
[Task-specific] Epoch 004: loss = 0.6885, acc = 0.57 | val_loss = 0.6753, val_acc = 0.58
[Task-specific] Epoch 005: loss = 0.6880, acc = 0.57 | val_loss = 0.6746, val_acc = 0.58
[Task-specific] Epoch 006: loss = 0.6856, acc = 0.57 | val_loss = 0.6749, val_acc = 0.58
[Task-specific] Epoch 007: loss = 0.6840, acc = 0.57 | val_loss = 0.6748, val_acc = 0.58
[Task-specific] Epoch 008: loss = 0.6841, acc = 0.57 | val_loss = 0.6740, val_acc = 0.58
[Task-specific] Epoch 009: loss = 0.6820, acc = 0.58 | val_loss = 0.6739, val_acc = 0.58
[Task-specific] Epoch 010: loss = 0.6819, acc = 0.57 | val_loss = 0.6737, val_acc = 0.58
[Task-specific] Epoch 011: loss = 0.6803, acc = 0.58 | val_loss = 0.6733, val_acc = 0.58
[Task-specific] Epoch 012: loss = 0.6803, acc = 0.58 | val_loss = 0.6738, val_acc = 0.58
[Task-specific] Epoch 013: loss = 0.6796, acc = 0.58 | val_loss = 0.6738, val_acc = 0.58
[Task-specific] Epoch 014: loss = 0.6776, acc = 0.58 | val_loss = 0.6734, val_acc = 0.58
[Task-specific] Epoch 015: loss = 0.6788, acc = 0.58 | val_loss = 0.6734, val_acc = 0.58
[Task-specific] Epoch 016: loss = 0.6774, acc = 0.58 | val_loss = 0.6736, val_acc = 0.58
[Task-specific] Epoch 017: loss = 0.6769, acc = 0.58 | val_loss = 0.6733, val_acc = 0.58
[Task-specific] Epoch 018: loss = 0.6771, acc = 0.58 | val_loss = 0.6736, val_acc = 0.58
‚èπÔ∏è  Early stopping after 18 epochs (best epoch 11, best_val_loss=0.6733).
[Trial 0] Params: lr=0.00006, dropout=0.48, weight_decay=0.000847, scheduler=plateau, hidden_dims=(448, 224)
üèÖ New global best found (val_loss=0.6733) ‚Äì tracked in memory (no files written)
[I 2025-08-27 06:03:13,644] Trial 0 finished with value: 0.6732800671083307 and parameters: {'lr': 5.6115164153345e-05, 'dropout': 0.4753571532049581, 'weight_decay': 0.0008471801418819979, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 448}. Best is trial 0 with value: 0.6732800671083307.
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6945, acc = 0.55 | val_loss = 0.6781, val_acc = 0.58
[Task-specific] Epoch 002: loss = 0.6857, acc = 0.57 | val_loss = 0.6765, val_acc = 0.58
[Task-specific] Epoch 003: loss = 0.6832, acc = 0.57 | val_loss = 0.6757, val_acc = 0.57
[Task-specific] Epoch 004: loss = 0.6816, acc = 0.57 | val_loss = 0.6759, val_acc = 0.57
[Task-specific] Epoch 005: loss = 0.6794, acc = 0.58 | val_loss = 0.6751, val_acc = 0.58
[Task-specific] Epoch 006: loss = 0.6786, acc = 0.58 | val_loss = 0.6755, val_acc = 0.58
[Task-specific] Epoch 007: loss = 0.6780, acc = 0.58 | val_loss = 0.6748, val_acc = 0.58
[Task-specific] Epoch 008: loss = 0.6781, acc = 0.58 | val_loss = 0.6745, val_acc = 0.57
[Task-specific] Epoch 009: loss = 0.6767, acc = 0.58 | val_loss = 0.6745, val_acc = 0.58
[Task-specific] Epoch 010: loss = 0.6757, acc = 0.58 | val_loss = 0.6740, val_acc = 0.58
[Task-specific] Epoch 011: loss = 0.6752, acc = 0.58 | val_loss = 0.6752, val_acc = 0.57
[Task-specific] Epoch 012: loss = 0.6749, acc = 0.58 | val_loss = 0.6740, val_acc = 0.58
[Task-specific] Epoch 013: loss = 0.6748, acc = 0.58 | val_loss = 0.6745, val_acc = 0.58
[Task-specific] Epoch 014: loss = 0.6745, acc = 0.58 | val_loss = 0.6739, val_acc = 0.58
[Task-specific] Epoch 015: loss = 0.6745, acc = 0.59 | val_loss = 0.6740, val_acc = 0.58
[Task-specific] Epoch 016: loss = 0.6737, acc = 0.59 | val_loss = 0.6737, val_acc = 0.58
[Task-specific] Epoch 017: loss = 0.6735, acc = 0.59 | val_loss = 0.6740, val_acc = 0.58
[Task-specific] Epoch 018: loss = 0.6733, acc = 0.59 | val_loss = 0.6732, val_acc = 0.58
[Task-specific] Epoch 019: loss = 0.6724, acc = 0.58 | val_loss = 0.6732, val_acc = 0.58
[Task-specific] Epoch 020: loss = 0.6723, acc = 0.59 | val_loss = 0.6732, val_acc = 0.58
[Task-specific] Epoch 021: loss = 0.6720, acc = 0.59 | val_loss = 0.6731, val_acc = 0.58
[Task-specific] Epoch 022: loss = 0.6732, acc = 0.59 | val_loss = 0.6732, val_acc = 0.58
[Task-specific] Epoch 023: loss = 0.6722, acc = 0.59 | val_loss = 0.6734, val_acc = 0.58
[Task-specific] Epoch 024: loss = 0.6720, acc = 0.59 | val_loss = 0.6730, val_acc = 0.58
[Task-specific] Epoch 025: loss = 0.6722, acc = 0.59 | val_loss = 0.6728, val_acc = 0.58
[Task-specific] Epoch 026: loss = 0.6717, acc = 0.59 | val_loss = 0.6732, val_acc = 0.58
[Task-specific] Epoch 027: loss = 0.6714, acc = 0.59 | val_loss = 0.6727, val_acc = 0.58
[Task-specific] Epoch 028: loss = 0.6719, acc = 0.59 | val_loss = 0.6730, val_acc = 0.58
[Task-specific] Epoch 029: loss = 0.6716, acc = 0.59 | val_loss = 0.6727, val_acc = 0.58
[Task-specific] Epoch 030: loss = 0.6718, acc = 0.59 | val_loss = 0.6729, val_acc = 0.58
[Task-specific] Epoch 031: loss = 0.6712, acc = 0.59 | val_loss = 0.6725, val_acc = 0.58
[Task-specific] Epoch 032: loss = 0.6708, acc = 0.59 | val_loss = 0.6727, val_acc = 0.58
[Task-specific] Epoch 033: loss = 0.6709, acc = 0.59 | val_loss = 0.6728, val_acc = 0.58
[Task-specific] Epoch 034: loss = 0.6710, acc = 0.59 | val_loss = 0.6720, val_acc = 0.58
[Task-specific] Epoch 035: loss = 0.6710, acc = 0.59 | val_loss = 0.6723, val_acc = 0.58
[Task-specific] Epoch 036: loss = 0.6700, acc = 0.59 | val_loss = 0.6723, val_acc = 0.58
[Task-specific] Epoch 037: loss = 0.6707, acc = 0.59 | val_loss = 0.6726, val_acc = 0.58
[Task-specific] Epoch 038: loss = 0.6712, acc = 0.59 | val_loss = 0.6720, val_acc = 0.58
[Task-specific] Epoch 039: loss = 0.6698, acc = 0.59 | val_loss = 0.6722, val_acc = 0.58
[Task-specific] Epoch 040: loss = 0.6700, acc = 0.59 | val_loss = 0.6719, val_acc = 0.58
[Task-specific] Epoch 041: loss = 0.6695, acc = 0.59 | val_loss = 0.6717, val_acc = 0.58
[Task-specific] Epoch 042: loss = 0.6696, acc = 0.59 | val_loss = 0.6716, val_acc = 0.59
[Task-specific] Epoch 043: loss = 0.6702, acc = 0.59 | val_loss = 0.6720, val_acc = 0.58
[Task-specific] Epoch 044: loss = 0.6694, acc = 0.59 | val_loss = 0.6718, val_acc = 0.59
[Task-specific] Epoch 045: loss = 0.6700, acc = 0.59 | val_loss = 0.6723, val_acc = 0.58
[Task-specific] Epoch 046: loss = 0.6700, acc = 0.59 | val_loss = 0.6714, val_acc = 0.59
[Task-specific] Epoch 047: loss = 0.6690, acc = 0.59 | val_loss = 0.6719, val_acc = 0.59
[Task-specific] Epoch 048: loss = 0.6693, acc = 0.59 | val_loss = 0.6717, val_acc = 0.58
[Task-specific] Epoch 049: loss = 0.6698, acc = 0.59 | val_loss = 0.6713, val_acc = 0.59
[Task-specific] Epoch 050: loss = 0.6698, acc = 0.59 | val_loss = 0.6722, val_acc = 0.58
[Task-specific] Epoch 051: loss = 0.6694, acc = 0.59 | val_loss = 0.6718, val_acc = 0.59
[Task-specific] Epoch 052: loss = 0.6695, acc = 0.59 | val_loss = 0.6720, val_acc = 0.59
[Task-specific] Epoch 053: loss = 0.6693, acc = 0.59 | val_loss = 0.6717, val_acc = 0.58
[Task-specific] Epoch 054: loss = 0.6698, acc = 0.59 | val_loss = 0.6714, val_acc = 0.59
[Task-specific] Epoch 055: loss = 0.6695, acc = 0.59 | val_loss = 0.6713, val_acc = 0.59
[Task-specific] Epoch 056: loss = 0.6688, acc = 0.59 | val_loss = 0.6714, val_acc = 0.59
[Task-specific] Epoch 057: loss = 0.6687, acc = 0.59 | val_loss = 0.6713, val_acc = 0.59
[Task-specific] Epoch 058: loss = 0.6685, acc = 0.59 | val_loss = 0.6713, val_acc = 0.59
[Task-specific] Epoch 059: loss = 0.6693, acc = 0.59 | val_loss = 0.6719, val_acc = 0.58
[Task-specific] Epoch 060: loss = 0.6683, acc = 0.60 | val_loss = 0.6714, val_acc = 0.59
[Task-specific] Epoch 061: loss = 0.6691, acc = 0.59 | val_loss = 0.6716, val_acc = 0.59
[Task-specific] Epoch 062: loss = 0.6688, acc = 0.59 | val_loss = 0.6710, val_acc = 0.59
[Task-specific] Epoch 063: loss = 0.6687, acc = 0.59 | val_loss = 0.6712, val_acc = 0.59
[Task-specific] Epoch 064: loss = 0.6684, acc = 0.59 | val_loss = 0.6711, val_acc = 0.59
[Task-specific] Epoch 065: loss = 0.6687, acc = 0.59 | val_loss = 0.6715, val_acc = 0.58
[Task-specific] Epoch 066: loss = 0.6691, acc = 0.59 | val_loss = 0.6713, val_acc = 0.59
[Task-specific] Epoch 067: loss = 0.6687, acc = 0.59 | val_loss = 0.6710, val_acc = 0.59
[Task-specific] Epoch 068: loss = 0.6684, acc = 0.59 | val_loss = 0.6713, val_acc = 0.58
[Task-specific] Epoch 069: loss = 0.6687, acc = 0.59 | val_loss = 0.6711, val_acc = 0.59
[Task-specific] Epoch 070: loss = 0.6686, acc = 0.59 | val_loss = 0.6711, val_acc = 0.59
[Task-specific] Epoch 071: loss = 0.6689, acc = 0.59 | val_loss = 0.6707, val_acc = 0.59
[Task-specific] Epoch 072: loss = 0.6687, acc = 0.59 | val_loss = 0.6708, val_acc = 0.59
[Task-specific] Epoch 073: loss = 0.6692, acc = 0.59 | val_loss = 0.6708, val_acc = 0.59
[Task-specific] Epoch 074: loss = 0.6687, acc = 0.59 | val_loss = 0.6711, val_acc = 0.59
[Task-specific] Epoch 075: loss = 0.6686, acc = 0.59 | val_loss = 0.6712, val_acc = 0.59
[Task-specific] Epoch 076: loss = 0.6688, acc = 0.59 | val_loss = 0.6709, val_acc = 0.59
[Task-specific] Epoch 077: loss = 0.6680, acc = 0.59 | val_loss = 0.6707, val_acc = 0.59
[Task-specific] Epoch 078: loss = 0.6687, acc = 0.59 | val_loss = 0.6713, val_acc = 0.59
[Task-specific] Epoch 079: loss = 0.6685, acc = 0.59 | val_loss = 0.6707, val_acc = 0.59
[Task-specific] Epoch 080: loss = 0.6687, acc = 0.59 | val_loss = 0.6712, val_acc = 0.59
[Task-specific] Epoch 081: loss = 0.6679, acc = 0.60 | val_loss = 0.6710, val_acc = 0.59
[Task-specific] Epoch 082: loss = 0.6680, acc = 0.59 | val_loss = 0.6710, val_acc = 0.59
[Task-specific] Epoch 083: loss = 0.6684, acc = 0.59 | val_loss = 0.6707, val_acc = 0.59
[Task-specific] Epoch 084: loss = 0.6675, acc = 0.60 | val_loss = 0.6713, val_acc = 0.58
[Task-specific] Epoch 085: loss = 0.6689, acc = 0.59 | val_loss = 0.6712, val_acc = 0.58
[Task-specific] Epoch 086: loss = 0.6679, acc = 0.59 | val_loss = 0.6717, val_acc = 0.58
[Task-specific] Epoch 087: loss = 0.6687, acc = 0.59 | val_loss = 0.6708, val_acc = 0.59
[Task-specific] Epoch 088: loss = 0.6680, acc = 0.59 | val_loss = 0.6710, val_acc = 0.59
[Task-specific] Epoch 089: loss = 0.6677, acc = 0.59 | val_loss = 0.6706, val_acc = 0.59
[Task-specific] Epoch 090: loss = 0.6677, acc = 0.60 | val_loss = 0.6708, val_acc = 0.59
[Task-specific] Epoch 091: loss = 0.6683, acc = 0.59 | val_loss = 0.6710, val_acc = 0.59
[Task-specific] Epoch 092: loss = 0.6682, acc = 0.59 | val_loss = 0.6706, val_acc = 0.59
[Task-specific] Epoch 093: loss = 0.6687, acc = 0.59 | val_loss = 0.6712, val_acc = 0.59
[Task-specific] Epoch 094: loss = 0.6677, acc = 0.60 | val_loss = 0.6709, val_acc = 0.58
[Task-specific] Epoch 095: loss = 0.6681, acc = 0.59 | val_loss = 0.6707, val_acc = 0.59
[Task-specific] Epoch 096: loss = 0.6688, acc = 0.59 | val_loss = 0.6711, val_acc = 0.59
‚èπÔ∏è  Early stopping after 96 epochs (best epoch 89, best_val_loss=0.6706).
[Trial 1] Params: lr=0.00016, dropout=0.35, weight_decay=0.000001, scheduler=plateau, hidden_dims=(128, 64)
üèÖ New global best found (val_loss=0.6706) ‚Äì tracked in memory (no files written)
[I 2025-08-27 06:05:04,146] Trial 1 finished with value: 0.6706251592436933 and parameters: {'lr': 0.00015930522616241006, 'dropout': 0.35403628889802274, 'weight_decay': 1.2087541473056965e-06, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 128}. Best is trial 1 with value: 0.6706251592436933.
‚úÖ Optuna search finished ‚Äì best val_loss=0.6706. Best model kept in memory.
üîç Prediction counts: {'label_0': 2782, 'label_1': 2677}
Saving results ‚Ä¶
‚úÖ Pipeline completed successfully to the path Results/tuh-wong_wang_avg!

====================================
CPU Time used: 408:14:49
CPU Percent: 6247%
Memory usage: 36836868kb
Approx Power usage: 4.8988000000000005
Walltime usage: 08:09:55

====================================
