method: ctm
# Dataset corpus to use: 'tuh' or 'harvard'
data_corp: harvard

paths:
  # Path to TUH EEG training data (ignored for Harvard)
  data_train: "/rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train"
  # Path to TUH EEG evaluation data (ignored for Harvard)
  data_eval: "/rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval"
  # Path to cleaned Harvard EEG BIDS root directory (ignored for TUH)
  data_harvard: "/rds/general/user/lrh24/ephemeral/harvard-eeg/EEG/bids_age_500_clean"
  # Directory where all results will be written
  results_root: "Results"

model:
  batch_size: 16
  num_epochs: 20
  dropout: 0.3
  weight_decay: 1e-4
  scheduler: cosine  # options: none | cosine | plateau

loss_weights:
  lambda_gender: 1.0
  lambda_age: 0.2
  lambda_abn: 1.0

# Whether latent representations have already been extracted
extracted: false 
