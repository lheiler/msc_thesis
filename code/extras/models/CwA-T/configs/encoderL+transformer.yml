processing:
  frequency: 100



input_size: 6000
n_channels: 19

dataset:
  train_data_dir: '/rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train'
  val_data_dir:   '/rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval'
  classes:
    normal: 0
    abnormal: 1
  num_workers: 16
  shuffle: True
  # mean: [...]   # optional
  # std:  [...]   # optional

model:
  name: encoderSL+transformer
  d_model: 256
  n_head: 1
  n_layer: 1
  

criterion:
  name: ce

optimizer:
  name: adam
  init_lr: 0.001
  weight_decay: 0.0

scheduler:
  name: cosine
  lr_gamma: 0.99
  lr_min: 0

warmup: 0

train:
  experiment: tuh_abnormal
  warmup_steps: 200
  n_epochs: 15
  batch_size: 128
  use_cuda: 1
  gpu_id: 0
  deterministic: 1
  random_state: 42
  log_interval: 200

tensorboard:
  runs_dir: '../runs/'

checkpoint:
  checkpoint_dir: "../weights/"
  weights: "your_path.pth"
  model_comment: ""
  resume: True
  restore_checkpoint: ""

debug:
  verbose: 1
