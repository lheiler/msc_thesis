{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e8aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.types import Device, _size\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "%matplotlib notebook\n",
    "\n",
    "from models.encoder import res_encoderS\n",
    "from models.classifier import transformer_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f81b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)  # Use the current module's name\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "acc_example = 0.95  # Replace with your actual accuracy calculation\n",
    "logger.info(f\"test accuracy: {acc_example}\")  # Log as info\n",
    "# logger.debug(\"Current accuracy: %.2f\", accuracy)  # Log as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67715c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config_file\", metavar=\"FILE\", help=\"config file\")\n",
    "# parser.add_argument('--run-dir', metavar='DIR', help='run directory')\n",
    "# parser.add_argument('--pdb', action='store_true', help='pdb')\n",
    "args = parser.parse_args(args=['configs/encoderS+transformer.yml'])\n",
    "with open(args.config_file, 'r') as file:\n",
    "    Configs = yaml.safe_load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f7b066b",
   "metadata": {},
   "source": [
    "file_path = '../data/edf/normal/aaaaacby_s004_t000.edf'\n",
    "raw = mne.io.read_raw_edf(file_path)\n",
    "# raw.resample(100)    # resampling to xHz\n",
    "sfreq = raw.info['sfreq']   # 100\n",
    "#     logger.info(freq)\n",
    "raw.crop(tmin=60)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73ded710",
   "metadata": {},
   "source": [
    "raw_cp = raw.copy()\n",
    "# raw_cp.crop(tmin=0, tmax=5.0)\n",
    "raw_cp.plot(scalings=dict(eeg=30e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb913282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, data_dir:str, label_dir:str, label_dict:dict, transform=None):\n",
    "#         self.annotations = pd.read_csv(label_dir)\n",
    "        self.data_dir = data_dir   # './data/origin_csv/train'\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.files = os.listdir(self.data_dir)\n",
    "        self.annotations = pd.read_csv(self.label_dir)\n",
    "        self.label_dict = label_dict\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.data_dir, self.files[index])\n",
    "        data = pd.read_csv(data_path)\n",
    "        data = torch.tensor(data.values, dtype=torch.float32)\n",
    "        file_name = self.files[index]\n",
    "        \n",
    "        label = torch.tensor(int(self.label_dict[self.annotations.iloc[index,1]]))\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return (data.t(), label, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa31e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, input_size: int, n_channels: int, model_hyp: dict, classes: int):\n",
    "        super(model, self).__init__()\n",
    "        self.ae = res_encoderS(n_channels=n_channels, groups=n_channels, num_classes=classes, \n",
    "                               len_feature=input_size, d_model=model_hyp['d_model'])\n",
    "        self.transformer_encoder = transformer_classifier(input_size, n_channels, model_hyp, classes)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Initiate parameters in the model.\"\"\"\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "#                 logger.debug(p.shape)\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                    \n",
    "        for m in self.modules():\n",
    "#             print(m)\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        \n",
    "            elif isinstance(m, (nn.LayerNorm, nn.BatchNorm1d)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        print('Complete initiate parameters')\n",
    "\n",
    "    def forward(self, x):\n",
    "#         z = self.pe(x)\n",
    "#         z = x.transpose(-1,-2)\n",
    "        z = self.ae(x)\n",
    "#         z = torch.flatten(z, 1)\n",
    "#         y = self.mlp(z)\n",
    "        y = self.transformer_encoder(z)\n",
    "        return y\n",
    "        \n",
    "# classifier = model(input_size=Configs['input_size'],\n",
    "#                                         n_channels = Configs['n_channels'],\n",
    "#                                         model_hyp=Configs['model'],\n",
    "#                                         classes=len(Configs['dataset']['classes'])).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710de126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_dir = Configs['dataset']['train_data_dir']\n",
    "# train_label_dir = Configs['dataset']['train_label_dir']\n",
    "\n",
    "test_eval_data_dir = '../results/test_data'\n",
    "test_eval_label_dir = '../results/result_eval_12000.csv'\n",
    "\n",
    "label_dict = Configs['dataset']['classes']\n",
    "# train_dataset = customDataset(data_dir=train_data_dir,\n",
    "#                               label_dir=train_label_dir,\n",
    "#                               label_dict=label_dict)\n",
    "test_eval_dataset = customDataset(data_dir=test_eval_data_dir,\n",
    "                            label_dir=test_eval_label_dir,\n",
    "                            label_dict=label_dict)\n",
    "\n",
    "test_eval_loader = DataLoader(dataset=test_eval_dataset, pin_memory=True,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70418b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = torch.load('../weights.pth')\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4395ff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(classifier.parameters(),betas=(0.9,0.9),lr=Configs['optimizer']['init_lr'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# writer = SummaryWriter(Configs['tensorboard']['runs_dir']+'visulizer')    # Initilize tensorflow\n",
    "\n",
    "dataiter = iter(test_eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39131b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, labels,file_name = next(dataiter)\n",
    "signal, target = signal.to('cuda'), labels.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc03d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48fbee",
   "metadata": {},
   "source": [
    "### Save representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_maps = []  # Reset feature maps for the new epoch\n",
    "eval_feature_maps = []  # Reset feature maps for the new epoch\n",
    "# Define a folder to save feature maps\n",
    "output_folder = 'feature_maps'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Hook function to save feature maps\n",
    "# feature_maps = []\n",
    "\n",
    "def train_hook_fn(module, input, output):\n",
    "    train_feature_maps.append(output)\n",
    "\n",
    "def eval_hook_fn(module, input, output):\n",
    "    eval_feature_maps.append(output)\n",
    "\n",
    "# Function to save feature maps as images\n",
    "def save_feature_maps_as_images(feature_maps, epoch, output_folder):\n",
    "    for idx, fmap in enumerate(feature_maps):\n",
    "        fmap = fmap.detach().cpu().numpy()  # Convert to numpy array\n",
    "        num_channels = fmap.shape[1]\n",
    "        for channel in range(num_channels):\n",
    "            plt.imshow(fmap[0, channel], cmap='viridis')  # Display one feature map channel\n",
    "            plt.colorbar()\n",
    "            plt.title(f'Epoch {epoch}, Feature Map {idx + 1}, Channel {channel + 1}')\n",
    "            plt.savefig(os.path.join(output_folder, f'epoch_{epoch}_feature_map_{idx+1}_channel_{channel+1}.png'))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3672b3",
   "metadata": {},
   "source": [
    "#### Save similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5265fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to hook and save intermediate feature maps\n",
    "def hook_fn(module, input, output):\n",
    "    global attention_map\n",
    "    attention_map = output  # Save the attention map (19x19 for self-attention)\n",
    "    \n",
    "attention_map = None  # Global variable to store the hooked output\n",
    "hook = classifier.transformer_encoder.encoder_layer.self_attn.register_forward_hook(hook_fn)\n",
    "\n",
    "output = classifier(signal)\n",
    "\n",
    "# The attention map is now stored in the global variable `attention_map`\n",
    "# print(f\"Attention feature map shape: {attention_map.shape}\")  \n",
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c292d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hook0 = classifier.ae.avgpool_2.register_forward_hook(train_hook_fn)\n",
    "# hook1 = classifier.transformer_encoder.encoder_layer.register_forward_hook(train_hook_fn)\n",
    "\n",
    "\n",
    "out = classifier(signal)\n",
    "loss = criterion(out, target)\n",
    "probabilities = torch.softmax(out, dim=1)  # Apply softmax to get probabilities\n",
    "_, predicted = torch.max(probabilities, 1)\n",
    "\n",
    "print(out)\n",
    "print(probabilities)\n",
    "print(target)\n",
    "print(loss)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Fp1', 'Fp2', 'F3','F4', 'C3F', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8','T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32eea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_feature_maps[0][0].t().to('cpu').detach()\n",
    "df = pd.DataFrame(features.numpy(), columns=column_names)\n",
    "csv_filename = \"../results/autoencoder_data_abnormal.csv\"\n",
    "df.to_csv(csv_filename, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b740e3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2de2721",
   "metadata": {},
   "source": [
    "writer.add_graph(classifier, signal)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5961e6",
   "metadata": {},
   "source": [
    "### Plot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d20c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import argparse\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0466aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('your_path.csv')\n",
    "data2 = pd.read_csv('your_path.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8601556",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = ['F3', 'Cz', 'F4']\n",
    "data1_selected = data1[selected_channels]\n",
    "data2_selected = data2[selected_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time vectors\n",
    "time1 = np.linspace(0, 120, data1.shape[0])  # For 120 seconds\n",
    "time2 = np.linspace(0, 120, data2.shape[0])  # For 120 seconds (resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = ['F3', 'Cz', 'F4']\n",
    "data1_selected = data1[selected_channels]\n",
    "data2_selected = data2[selected_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbd81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d082f750",
   "metadata": {},
   "source": [
    "### Plot spectrums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcc06d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "# Load data\n",
    "file1 = \"../results/test_data/abnormal.csv\"  # Replace with the benign file path\n",
    "file2 = \"../results/autoencoder_data_abnormal.csv\"  # Replace with the filtered file path\n",
    "\n",
    "# Read CSV files\n",
    "data_benign = pd.read_csv(file1)  # Shape: (12000, 19)\n",
    "data_filtered = pd.read_csv(file2)  # Shape: (256, 19)\n",
    "\n",
    "# Channels to plot\n",
    "selected_channels = [\"F3\", \"Cz\", \"F4\"]  # Replace with actual channel names\n",
    "\n",
    "# Sampling frequencies\n",
    "fs_benign = 100  # Sampling frequency for benign signals\n",
    "fs_filtered = 100  # Sampling frequency for filtered signals\n",
    "\n",
    "# Plot spectrograms\n",
    "fig, axes = plt.subplots(len(selected_channels), 3, figsize=(15, 10), constrained_layout=True)\n",
    "\n",
    "for i, channel in enumerate(selected_channels):\n",
    "    # Extract channel signals\n",
    "    signal_benign = data_benign[channel].values\n",
    "    signal_filtered = data_filtered[channel].values\n",
    "\n",
    "    # Compute spectrograms\n",
    "    f_benign, t_benign, Sxx_benign = spectrogram(signal_benign, fs=fs_benign, nperseg=256, noverlap=128)\n",
    "    f_filtered, t_filtered, Sxx_filtered = spectrogram(signal_filtered, fs=fs_filtered, nperseg=256, noverlap=128)\n",
    "\n",
    "    # Adjust the time axis to match 0-120s\n",
    "    t_benign = np.linspace(0, 120, len(t_benign))  # Force time to 0-120s\n",
    "    t_filtered = np.linspace(0, 120, len(t_filtered))  # Force time to 0-120s\n",
    "    min_length = min(Sxx_benign.shape[1], Sxx_filtered.shape[1])\n",
    "    Sxx_difference = Sxx_benign[:, :min_length] - Sxx_filtered[:, :min_length]\n",
    "    t_diff = np.linspace(0, 120, min_length)  # Adjust difference time to 0-120s\n",
    "\n",
    "    # Set color limits for consistency\n",
    "    vmin, vmax = -40, 0  # Adjust these values to better match the template\n",
    "\n",
    "    # Plot benign spectrogram\n",
    "    ax = axes[i, 0]\n",
    "    pcm = ax.pcolormesh(t_benign, f_benign, 10 * np.log10(Sxx_benign), shading='gouraud', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    fig.colorbar(pcm, ax=ax, label=\"Power (dB)\")\n",
    "    ax.set_title(f\"{channel} - Benign\")\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_xlim(0, 120)\n",
    "\n",
    "    # Plot filtered spectrogram\n",
    "    ax = axes[i, 1]\n",
    "    pcm = ax.pcolormesh(t_filtered, f_filtered, 10 * np.log10(Sxx_filtered), shading='gouraud', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    fig.colorbar(pcm, ax=ax, label=\"Power (dB)\")\n",
    "    ax.set_title(f\"{channel} - Filtered\")\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_xlim(0, 120)\n",
    "\n",
    "    # Plot difference spectrogram\n",
    "    ax = axes[i, 2]\n",
    "    pcm = ax.pcolormesh(t_diff, f_benign, Sxx_difference, shading='gouraud', cmap='jet')\n",
    "    fig.colorbar(pcm, ax=ax, label=\"Difference Power\")\n",
    "    ax.set_title(f\"{channel} - Difference\")\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_xlim(0, 120)\n",
    "\n",
    "# Show the updated plots\n",
    "plt.show()\n",
    "# Uncomment below line to save the figure\n",
    "# plt.savefig('../results/spectrums_fixed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a8a0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "# Load data\n",
    "file1 = \"your_path.csv\"  # Replace with the benign file path\n",
    "\n",
    "# Read CSV file\n",
    "data_benign = pd.read_csv(file1)  # Shape: (12000, 19)\n",
    "\n",
    "# Channels to plot\n",
    "selected_channels = [\"F3\", \"Cz\", \"F4\"]  # Replace with actual channel names\n",
    "\n",
    "# Sampling frequency\n",
    "fs_benign = 100  # Sampling frequency for benign signals\n",
    "\n",
    "# Adjust figure size to make plots rectangular\n",
    "fig, axes = plt.subplots(len(selected_channels), 1, figsize=(16, 6 * len(selected_channels)), constrained_layout=True)\n",
    "\n",
    "for i, channel in enumerate(selected_channels):\n",
    "    # Extract channel signal\n",
    "    signal_benign = data_benign[channel].values\n",
    "\n",
    "    # Debug signal length\n",
    "    print(f\"{channel} - Raw signal length: {len(signal_benign)}\")\n",
    "\n",
    "    # Compute spectrogram\n",
    "    f_benign, t_benign, Sxx_benign = spectrogram(signal_benign, fs=fs_benign, nperseg=256, noverlap=128)\n",
    "\n",
    "    # Adjust the time axis to 0-120 seconds\n",
    "    t_benign = np.linspace(0, 120, len(t_benign))\n",
    "\n",
    "    # Set color limits for consistency\n",
    "    vmin, vmax = -40, 0  # Adjust these values as needed\n",
    "\n",
    "    # Plot benign spectrogram\n",
    "    ax = axes[i]\n",
    "    pcm = ax.pcolormesh(t_benign, f_benign, 10 * np.log10(Sxx_benign), shading='gouraud', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    fig.colorbar(pcm, ax=ax, label=\"Power (dB)\")\n",
    "    ax.set_title(f\"{channel} - spectrogram\")\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_xlim(0, 120)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "# Uncomment the line below to save the figure\n",
    "plt.savefig('../results/spectrograms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72682fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_benign.shape, f_benign.shape, t_benign.shape, Sxx_benign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ee8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_filtered.shape, f_filtered.shape, t_filtered.shape, Sxx_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "# Load data\n",
    "file1 = \"your_path1.csv\"  # Replace with the benign file path\n",
    "file2 = \"your_path2.csv\"  # Replace with the filtered file path\n",
    "\n",
    "# Read CSV files\n",
    "data_benign = pd.read_csv(file1)  # Shape: (12000, 19)\n",
    "data_filtered = pd.read_csv(file2)  # Shape: (256, 19)\n",
    "\n",
    "# Channels to plot\n",
    "selected_channels = [\"F3\", \"Cz\", \"F4\"]  # Replace with actual channel names\n",
    "\n",
    "# Sampling frequencies\n",
    "fs_benign = 100  # Sampling frequency for benign signals\n",
    "fs_filtered = 100  # Sampling frequency for filtered signals\n",
    "\n",
    "# Plot spectrograms\n",
    "fig, axes = plt.subplots(len(selected_channels), 1, figsize=(15, 10), constrained_layout=True)\n",
    "\n",
    "for i, channel in enumerate(selected_channels):\n",
    "    # Extract channel signals\n",
    "    signal_benign = data_benign[channel].values\n",
    "    signal_filtered = data_filtered[channel].values\n",
    "\n",
    "    # Compute spectrograms\n",
    "    f_benign, t_benign, Sxx_benign = spectrogram(signal_benign, fs=fs_benign, nperseg=256, noverlap=128)\n",
    "    f_filtered, t_filtered, Sxx_filtered = spectrogram(signal_filtered, fs=fs_filtered, nperseg=256, noverlap=128)\n",
    "\n",
    "    # Adjust the time axis to match 0-120s\n",
    "    t_benign = np.linspace(0, 120, len(t_benign))  # Force time to 0-120s\n",
    "    t_filtered = np.linspace(0, 120, len(t_filtered))  # Force time to 0-120s\n",
    "    min_length = min(Sxx_benign.shape[1], Sxx_filtered.shape[1])\n",
    "    Sxx_difference = Sxx_benign[:, :min_length] - Sxx_filtered[:, :min_length]\n",
    "    t_diff = np.linspace(0, 120, min_length)  # Adjust difference time to 0-120s\n",
    "\n",
    "    # Set color limits for consistency\n",
    "    vmin, vmax = -40, 0  # Adjust these values to better match the template\n",
    "\n",
    "    # Plot benign spectrogram\n",
    "    ax = axes[i, 0]\n",
    "    pcm = ax.pcolormesh(t_benign, f_benign, 10 * np.log10(Sxx_benign), shading='gouraud', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    fig.colorbar(pcm, ax=ax, label=\"Power (dB)\")\n",
    "    ax.set_title(f\"{channel}\")\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_xlim(0, 120)\n",
    "\n",
    "\n",
    "# Show the updated plots\n",
    "plt.show()\n",
    "# Uncomment below line to save the figure\n",
    "# plt.savefig('../results/spectrums.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": "50",
    "lenVar": "80"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
