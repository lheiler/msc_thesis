Results will be saved to: Results/tuh-hopf_pc
Loading raw EEG data ‚Ä¶
Loading train data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/train_epochs.pkl...
Loaded 53622 samples from train split
Loading eval data from /rds/general/user/lrh24/home/thesis/Datasets/tuh-eeg-ab-clean/eval_epochs.pkl...
Loaded 5459 samples from eval split
Loaded 53622 training samples and 5459 evaluation samples from tuh dataset
Extracting latent features ‚Ä¶
Evaluating latent features ‚Ä¶
Training models for each task
üîπ Task 3: hardcoded as classification ‚Üí 'abnormal'
   ‚Üí Optuna search (n_trials=2) for classification ‚Ä¶
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6171, acc = 0.66 | val_loss = 0.5684, val_acc = 0.71
[Task-specific] Epoch 002: loss = 0.5706, acc = 0.71 | val_loss = 0.5502, val_acc = 0.72
[Task-specific] Epoch 003: loss = 0.5558, acc = 0.72 | val_loss = 0.5387, val_acc = 0.73
[Task-specific] Epoch 004: loss = 0.5446, acc = 0.72 | val_loss = 0.5303, val_acc = 0.73
[Task-specific] Epoch 005: loss = 0.5384, acc = 0.73 | val_loss = 0.5248, val_acc = 0.73
[Task-specific] Epoch 006: loss = 0.5309, acc = 0.73 | val_loss = 0.5191, val_acc = 0.74
[Task-specific] Epoch 007: loss = 0.5255, acc = 0.74 | val_loss = 0.5144, val_acc = 0.74
[Task-specific] Epoch 008: loss = 0.5202, acc = 0.74 | val_loss = 0.5114, val_acc = 0.75
[Task-specific] Epoch 009: loss = 0.5166, acc = 0.74 | val_loss = 0.5076, val_acc = 0.75
[Task-specific] Epoch 010: loss = 0.5138, acc = 0.75 | val_loss = 0.5060, val_acc = 0.75
[Task-specific] Epoch 011: loss = 0.5067, acc = 0.75 | val_loss = 0.5025, val_acc = 0.75
[Task-specific] Epoch 012: loss = 0.5066, acc = 0.75 | val_loss = 0.5006, val_acc = 0.76
[Task-specific] Epoch 013: loss = 0.5024, acc = 0.76 | val_loss = 0.4977, val_acc = 0.76
[Task-specific] Epoch 014: loss = 0.4986, acc = 0.76 | val_loss = 0.4958, val_acc = 0.76
[Task-specific] Epoch 015: loss = 0.4986, acc = 0.76 | val_loss = 0.4948, val_acc = 0.76
[Task-specific] Epoch 016: loss = 0.4931, acc = 0.76 | val_loss = 0.4936, val_acc = 0.76
[Task-specific] Epoch 017: loss = 0.4932, acc = 0.76 | val_loss = 0.4915, val_acc = 0.76
[Task-specific] Epoch 018: loss = 0.4888, acc = 0.76 | val_loss = 0.4892, val_acc = 0.77
[Task-specific] Epoch 019: loss = 0.4867, acc = 0.76 | val_loss = 0.4899, val_acc = 0.76
[Task-specific] Epoch 020: loss = 0.4853, acc = 0.77 | val_loss = 0.4871, val_acc = 0.77
[Task-specific] Epoch 021: loss = 0.4840, acc = 0.77 | val_loss = 0.4862, val_acc = 0.77
[Task-specific] Epoch 022: loss = 0.4813, acc = 0.77 | val_loss = 0.4839, val_acc = 0.77
[Task-specific] Epoch 023: loss = 0.4799, acc = 0.77 | val_loss = 0.4835, val_acc = 0.77
[Task-specific] Epoch 024: loss = 0.4780, acc = 0.77 | val_loss = 0.4834, val_acc = 0.77
[Task-specific] Epoch 025: loss = 0.4763, acc = 0.77 | val_loss = 0.4825, val_acc = 0.77
[Task-specific] Epoch 026: loss = 0.4742, acc = 0.77 | val_loss = 0.4795, val_acc = 0.77
[Task-specific] Epoch 027: loss = 0.4727, acc = 0.77 | val_loss = 0.4784, val_acc = 0.77
[Task-specific] Epoch 028: loss = 0.4718, acc = 0.77 | val_loss = 0.4777, val_acc = 0.77
[Task-specific] Epoch 029: loss = 0.4706, acc = 0.78 | val_loss = 0.4768, val_acc = 0.77
[Task-specific] Epoch 030: loss = 0.4687, acc = 0.78 | val_loss = 0.4770, val_acc = 0.77
[Task-specific] Epoch 031: loss = 0.4663, acc = 0.78 | val_loss = 0.4758, val_acc = 0.77
[Task-specific] Epoch 032: loss = 0.4628, acc = 0.78 | val_loss = 0.4740, val_acc = 0.77
[Task-specific] Epoch 033: loss = 0.4613, acc = 0.78 | val_loss = 0.4728, val_acc = 0.78
[Task-specific] Epoch 034: loss = 0.4622, acc = 0.78 | val_loss = 0.4722, val_acc = 0.78
[Task-specific] Epoch 035: loss = 0.4598, acc = 0.78 | val_loss = 0.4712, val_acc = 0.78
[Task-specific] Epoch 036: loss = 0.4582, acc = 0.78 | val_loss = 0.4700, val_acc = 0.78
[Task-specific] Epoch 037: loss = 0.4558, acc = 0.78 | val_loss = 0.4706, val_acc = 0.78
[Task-specific] Epoch 038: loss = 0.4558, acc = 0.78 | val_loss = 0.4692, val_acc = 0.78
[Task-specific] Epoch 039: loss = 0.4530, acc = 0.78 | val_loss = 0.4681, val_acc = 0.78
[Task-specific] Epoch 040: loss = 0.4527, acc = 0.79 | val_loss = 0.4670, val_acc = 0.78
[Task-specific] Epoch 041: loss = 0.4522, acc = 0.79 | val_loss = 0.4659, val_acc = 0.78
[Task-specific] Epoch 042: loss = 0.4493, acc = 0.79 | val_loss = 0.4661, val_acc = 0.78
[Task-specific] Epoch 043: loss = 0.4483, acc = 0.79 | val_loss = 0.4650, val_acc = 0.78
[Task-specific] Epoch 044: loss = 0.4461, acc = 0.79 | val_loss = 0.4658, val_acc = 0.78
[Task-specific] Epoch 045: loss = 0.4452, acc = 0.79 | val_loss = 0.4633, val_acc = 0.78
[Task-specific] Epoch 046: loss = 0.4428, acc = 0.79 | val_loss = 0.4628, val_acc = 0.78
[Task-specific] Epoch 047: loss = 0.4422, acc = 0.79 | val_loss = 0.4632, val_acc = 0.78
[Task-specific] Epoch 048: loss = 0.4414, acc = 0.79 | val_loss = 0.4619, val_acc = 0.78
[Task-specific] Epoch 049: loss = 0.4385, acc = 0.79 | val_loss = 0.4609, val_acc = 0.79
[Task-specific] Epoch 050: loss = 0.4378, acc = 0.80 | val_loss = 0.4632, val_acc = 0.78
[Task-specific] Epoch 051: loss = 0.4359, acc = 0.80 | val_loss = 0.4596, val_acc = 0.79
[Task-specific] Epoch 052: loss = 0.4355, acc = 0.80 | val_loss = 0.4598, val_acc = 0.79
[Task-specific] Epoch 053: loss = 0.4360, acc = 0.80 | val_loss = 0.4603, val_acc = 0.79
[Task-specific] Epoch 054: loss = 0.4344, acc = 0.80 | val_loss = 0.4576, val_acc = 0.79
[Task-specific] Epoch 055: loss = 0.4321, acc = 0.80 | val_loss = 0.4566, val_acc = 0.79
[Task-specific] Epoch 056: loss = 0.4317, acc = 0.80 | val_loss = 0.4598, val_acc = 0.79
[Task-specific] Epoch 057: loss = 0.4283, acc = 0.80 | val_loss = 0.4554, val_acc = 0.79
[Task-specific] Epoch 058: loss = 0.4276, acc = 0.80 | val_loss = 0.4580, val_acc = 0.79
[Task-specific] Epoch 059: loss = 0.4255, acc = 0.80 | val_loss = 0.4589, val_acc = 0.79
[Task-specific] Epoch 060: loss = 0.4263, acc = 0.80 | val_loss = 0.4537, val_acc = 0.79
[Task-specific] Epoch 061: loss = 0.4221, acc = 0.80 | val_loss = 0.4538, val_acc = 0.79
[Task-specific] Epoch 062: loss = 0.4227, acc = 0.80 | val_loss = 0.4553, val_acc = 0.79
[Task-specific] Epoch 063: loss = 0.4192, acc = 0.80 | val_loss = 0.4549, val_acc = 0.79
[Task-specific] Epoch 064: loss = 0.4180, acc = 0.81 | val_loss = 0.4537, val_acc = 0.79
[Task-specific] Epoch 065: loss = 0.4183, acc = 0.81 | val_loss = 0.4524, val_acc = 0.79
[Task-specific] Epoch 066: loss = 0.4195, acc = 0.80 | val_loss = 0.4517, val_acc = 0.79
[Task-specific] Epoch 067: loss = 0.4168, acc = 0.81 | val_loss = 0.4521, val_acc = 0.79
[Task-specific] Epoch 068: loss = 0.4140, acc = 0.81 | val_loss = 0.4512, val_acc = 0.79
[Task-specific] Epoch 069: loss = 0.4133, acc = 0.81 | val_loss = 0.4511, val_acc = 0.79
[Task-specific] Epoch 070: loss = 0.4132, acc = 0.81 | val_loss = 0.4519, val_acc = 0.79
[Task-specific] Epoch 071: loss = 0.4111, acc = 0.81 | val_loss = 0.4501, val_acc = 0.79
[Task-specific] Epoch 072: loss = 0.4096, acc = 0.81 | val_loss = 0.4501, val_acc = 0.79
[Task-specific] Epoch 073: loss = 0.4077, acc = 0.81 | val_loss = 0.4492, val_acc = 0.79
[Task-specific] Epoch 074: loss = 0.4066, acc = 0.81 | val_loss = 0.4509, val_acc = 0.79
[Task-specific] Epoch 075: loss = 0.4063, acc = 0.81 | val_loss = 0.4483, val_acc = 0.79
[Task-specific] Epoch 076: loss = 0.4045, acc = 0.81 | val_loss = 0.4492, val_acc = 0.79
[Task-specific] Epoch 077: loss = 0.4057, acc = 0.81 | val_loss = 0.4481, val_acc = 0.79
[Task-specific] Epoch 078: loss = 0.4032, acc = 0.81 | val_loss = 0.4465, val_acc = 0.79
[Task-specific] Epoch 079: loss = 0.4011, acc = 0.82 | val_loss = 0.4466, val_acc = 0.79
[Task-specific] Epoch 080: loss = 0.4001, acc = 0.82 | val_loss = 0.4488, val_acc = 0.79
[Task-specific] Epoch 081: loss = 0.4006, acc = 0.82 | val_loss = 0.4461, val_acc = 0.79
[Task-specific] Epoch 082: loss = 0.3982, acc = 0.82 | val_loss = 0.4471, val_acc = 0.79
[Task-specific] Epoch 083: loss = 0.3960, acc = 0.82 | val_loss = 0.4494, val_acc = 0.79
[Task-specific] Epoch 084: loss = 0.3941, acc = 0.82 | val_loss = 0.4517, val_acc = 0.79
[Task-specific] Epoch 085: loss = 0.3953, acc = 0.82 | val_loss = 0.4462, val_acc = 0.79
[Task-specific] Epoch 086: loss = 0.3922, acc = 0.82 | val_loss = 0.4456, val_acc = 0.79
[Task-specific] Epoch 087: loss = 0.3927, acc = 0.82 | val_loss = 0.4503, val_acc = 0.79
[Task-specific] Epoch 088: loss = 0.3911, acc = 0.82 | val_loss = 0.4435, val_acc = 0.79
[Task-specific] Epoch 089: loss = 0.3893, acc = 0.82 | val_loss = 0.4446, val_acc = 0.79
[Task-specific] Epoch 090: loss = 0.3885, acc = 0.82 | val_loss = 0.4463, val_acc = 0.79
[Task-specific] Epoch 091: loss = 0.3881, acc = 0.82 | val_loss = 0.4443, val_acc = 0.79
[Task-specific] Epoch 092: loss = 0.3869, acc = 0.82 | val_loss = 0.4448, val_acc = 0.80
[Task-specific] Epoch 093: loss = 0.3867, acc = 0.82 | val_loss = 0.4486, val_acc = 0.79
[Task-specific] Epoch 094: loss = 0.3852, acc = 0.82 | val_loss = 0.4436, val_acc = 0.79
[Task-specific] Epoch 095: loss = 0.3818, acc = 0.82 | val_loss = 0.4454, val_acc = 0.79
‚èπÔ∏è  Early stopping after 95 epochs (best epoch 88, best_val_loss=0.4435).
[Trial 0] Params: lr=0.00006, dropout=0.48, weight_decay=0.000847, scheduler=plateau, hidden_dims=(448, 224)
üèÖ New global best found (val_loss=0.4435) ‚Äì tracked in memory (no files written)
[I 2025-08-26 15:23:43,349] Trial 0 finished with value: 0.44349030036644105 and parameters: {'lr': 5.6115164153345e-05, 'dropout': 0.4753571532049581, 'weight_decay': 0.0008471801418819979, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 448}. Best is trial 0 with value: 0.44349030036644105.
Training model with checkpoint path: None
[Task-specific] Epoch 001: loss = 0.6113, acc = 0.67 | val_loss = 0.5631, val_acc = 0.71
[Task-specific] Epoch 002: loss = 0.5580, acc = 0.72 | val_loss = 0.5402, val_acc = 0.73
[Task-specific] Epoch 003: loss = 0.5401, acc = 0.73 | val_loss = 0.5280, val_acc = 0.73
[Task-specific] Epoch 004: loss = 0.5270, acc = 0.74 | val_loss = 0.5178, val_acc = 0.74
[Task-specific] Epoch 005: loss = 0.5185, acc = 0.74 | val_loss = 0.5119, val_acc = 0.75
[Task-specific] Epoch 006: loss = 0.5121, acc = 0.75 | val_loss = 0.5066, val_acc = 0.75
[Task-specific] Epoch 007: loss = 0.5048, acc = 0.75 | val_loss = 0.5014, val_acc = 0.75
[Task-specific] Epoch 008: loss = 0.5008, acc = 0.76 | val_loss = 0.4982, val_acc = 0.76
[Task-specific] Epoch 009: loss = 0.4957, acc = 0.76 | val_loss = 0.4964, val_acc = 0.76
[Task-specific] Epoch 010: loss = 0.4924, acc = 0.76 | val_loss = 0.4930, val_acc = 0.76
[Task-specific] Epoch 011: loss = 0.4902, acc = 0.76 | val_loss = 0.4914, val_acc = 0.76
[Task-specific] Epoch 012: loss = 0.4856, acc = 0.77 | val_loss = 0.4914, val_acc = 0.76
[Task-specific] Epoch 013: loss = 0.4846, acc = 0.77 | val_loss = 0.4864, val_acc = 0.76
[Task-specific] Epoch 014: loss = 0.4802, acc = 0.77 | val_loss = 0.4854, val_acc = 0.77
[Task-specific] Epoch 015: loss = 0.4783, acc = 0.77 | val_loss = 0.4824, val_acc = 0.77
[Task-specific] Epoch 016: loss = 0.4763, acc = 0.77 | val_loss = 0.4817, val_acc = 0.77
[Task-specific] Epoch 017: loss = 0.4724, acc = 0.77 | val_loss = 0.4792, val_acc = 0.77
[Task-specific] Epoch 018: loss = 0.4707, acc = 0.78 | val_loss = 0.4773, val_acc = 0.77
[Task-specific] Epoch 019: loss = 0.4672, acc = 0.78 | val_loss = 0.4758, val_acc = 0.77
[Task-specific] Epoch 020: loss = 0.4671, acc = 0.78 | val_loss = 0.4759, val_acc = 0.77
[Task-specific] Epoch 021: loss = 0.4620, acc = 0.78 | val_loss = 0.4741, val_acc = 0.77
[Task-specific] Epoch 022: loss = 0.4616, acc = 0.78 | val_loss = 0.4730, val_acc = 0.77
[Task-specific] Epoch 023: loss = 0.4584, acc = 0.78 | val_loss = 0.4709, val_acc = 0.78
[Task-specific] Epoch 024: loss = 0.4561, acc = 0.79 | val_loss = 0.4699, val_acc = 0.78
[Task-specific] Epoch 025: loss = 0.4566, acc = 0.78 | val_loss = 0.4696, val_acc = 0.78
[Task-specific] Epoch 026: loss = 0.4517, acc = 0.79 | val_loss = 0.4669, val_acc = 0.78
[Task-specific] Epoch 027: loss = 0.4506, acc = 0.79 | val_loss = 0.4660, val_acc = 0.78
[Task-specific] Epoch 028: loss = 0.4492, acc = 0.79 | val_loss = 0.4675, val_acc = 0.78
[Task-specific] Epoch 029: loss = 0.4469, acc = 0.79 | val_loss = 0.4660, val_acc = 0.78
[Task-specific] Epoch 030: loss = 0.4442, acc = 0.79 | val_loss = 0.4642, val_acc = 0.78
[Task-specific] Epoch 031: loss = 0.4428, acc = 0.79 | val_loss = 0.4655, val_acc = 0.78
[Task-specific] Epoch 032: loss = 0.4418, acc = 0.79 | val_loss = 0.4613, val_acc = 0.78
[Task-specific] Epoch 033: loss = 0.4392, acc = 0.80 | val_loss = 0.4616, val_acc = 0.78
[Task-specific] Epoch 034: loss = 0.4373, acc = 0.79 | val_loss = 0.4619, val_acc = 0.78
[Task-specific] Epoch 035: loss = 0.4343, acc = 0.80 | val_loss = 0.4588, val_acc = 0.79
[Task-specific] Epoch 036: loss = 0.4345, acc = 0.80 | val_loss = 0.4599, val_acc = 0.78
[Task-specific] Epoch 037: loss = 0.4319, acc = 0.80 | val_loss = 0.4566, val_acc = 0.79
[Task-specific] Epoch 038: loss = 0.4302, acc = 0.80 | val_loss = 0.4572, val_acc = 0.79
[Task-specific] Epoch 039: loss = 0.4290, acc = 0.80 | val_loss = 0.4600, val_acc = 0.78
[Task-specific] Epoch 040: loss = 0.4285, acc = 0.80 | val_loss = 0.4579, val_acc = 0.79
[Task-specific] Epoch 041: loss = 0.4288, acc = 0.80 | val_loss = 0.4571, val_acc = 0.79
[Task-specific] Epoch 042: loss = 0.4234, acc = 0.80 | val_loss = 0.4574, val_acc = 0.79
[Task-specific] Epoch 043: loss = 0.4232, acc = 0.80 | val_loss = 0.4573, val_acc = 0.79
[Task-specific] Epoch 044: loss = 0.4220, acc = 0.80 | val_loss = 0.4577, val_acc = 0.79
‚èπÔ∏è  Early stopping after 44 epochs (best epoch 37, best_val_loss=0.4566).
[Trial 1] Params: lr=0.00016, dropout=0.35, weight_decay=0.000001, scheduler=plateau, hidden_dims=(128, 64)
[I 2025-08-26 15:24:39,954] Trial 1 finished with value: 0.456627200990693 and parameters: {'lr': 0.00015930522616241006, 'dropout': 0.35403628889802274, 'weight_decay': 1.2087541473056965e-06, 'scheduler': 'plateau', 'n_layers': 2, 'base_width': 128}. Best is trial 0 with value: 0.44349030036644105.
‚úÖ Optuna search finished ‚Äì best val_loss=0.4435. Best model kept in memory.
üîç Prediction counts: {'label_0': 3008, 'label_1': 2451}
Saving results ‚Ä¶
‚úÖ Pipeline completed successfully to the path Results/tuh-hopf_pc!

====================================
CPU Time used: 112:05:11
CPU Percent: 6301%
Memory usage: 32129632kb
Approx Power usage: 1.345
Walltime usage: 01:55:14

====================================
